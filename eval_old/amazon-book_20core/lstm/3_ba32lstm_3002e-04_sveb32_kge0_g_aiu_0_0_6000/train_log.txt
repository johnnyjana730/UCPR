[INFO]  self.embeds = load_embed(load_embed_dim
[INFO]   name = kg_emb True name = state_lstm True name = transfor_state True name = state_tr_query True name = l1 True name = l2 True name = actor True name = critic True
[INFO]  Namespace(KGE_pretrained=True, act_dropout=0.5, add_products=False, att_core=0, att_evaluation=False, batch_size=32, best_model_epoch=0, best_save_model_dir='', core_user_list='', dataset='amazon-book_20core', device=device(type='cuda', index=0), embed_size=32, ent_weight=0.001, env_old=False, envir='p2', epochs=300, eva_epochs=0, gamma=0.99, gp_setting='6000_800_15_500_50', gpu='0', grad_check=False, gradient_plot='gradient_plot/', h0_embbed=0, hidden=[64, 32], item_core=0, kg_emb_grad=False, kg_fre_dict='', kg_fre_lower=15, kg_fre_upper=500, kg_no_grad=False, kg_old=False, l2_lambda=0, l2_weight=1e-06, lambda_num=0.3, load_pretrain_model=False, load_pt_emb_size=False, log_dir='../eval/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000', logger=<Logger ../eval/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/train_log.txt (DEBUG)>, lr=0.0002, max_acts=50, max_path_len=3, model='lstm', mv_test=False, n_memory=64, name='3_ba32lstm_3002e-04_sveb32_kge0', non_sampling=True, p_hop=2, pretest=False, pretrained_dir='../eva_pre/amazon-book_20core/pretrained/g_aiu_0_0_6000', pretrained_st_epoch=0, reasoning_step=3, reward_hybrid=False, reward_rh='', run_eval=True, run_path=True, sam_type='alet', save_model_dir='../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000', save_pretrain_model=False, seed=52, sort_by='prob', sp_user_filter='', state_history=1, state_rg=False, sub_batch_size=1, test_lstm_up=True, topk=[8, 2, 6], topk_list=[1, 8, 16, 96], topk_string='8, 2, 6', training=True, tri_pro_rm=False, tri_wd_rm=False, user_core=6000, user_core_th=6, user_o=False)
[INFO]  valid user = 
[INFO]  6000
[INFO]  Parameters:['kg_emb.11', 'kg_emb.34', 'kg_emb.6', 'kg_emb.17', 'kg_emb.36', 'kg_emb.22', 'kg_emb.29', 'kg_emb.24', 'kg_emb.9', 'kg_emb.32', 'kg_emb.1', 'kg_emb.3', 'kg_emb.26', 'kg_emb.30', 'kg_emb.8', 'kg_emb.purchase', 'kg_emb.padding', 'kg_emb.13', 'kg_emb.37', 'kg_emb.23', 'kg_emb.5', 'kg_emb.7', 'kg_emb.19', 'kg_emb.12', 'kg_emb.4', 'kg_emb.28', 'kg_emb.2', 'kg_emb.10', 'kg_emb.0', 'kg_emb.15', 'kg_emb.33', 'kg_emb.27', 'kg_emb.14', 'kg_emb.21', 'kg_emb.25', 'kg_emb.31', 'kg_emb.18', 'kg_emb.self_loop', 'kg_emb.35', 'kg_emb.20', 'kg_emb.38', 'kg_emb.16', 'kg_emb.user.weight', 'kg_emb.product.weight', 'kg_emb.attribute.weight', 'kg_emb.11_bias.weight', 'kg_emb.34_bias.weight', 'kg_emb.6_bias.weight', 'kg_emb.17_bias.weight', 'kg_emb.36_bias.weight', 'kg_emb.22_bias.weight', 'kg_emb.29_bias.weight', 'kg_emb.24_bias.weight', 'kg_emb.9_bias.weight', 'kg_emb.32_bias.weight', 'kg_emb.1_bias.weight', 'kg_emb.3_bias.weight', 'kg_emb.26_bias.weight', 'kg_emb.30_bias.weight', 'kg_emb.8_bias.weight', 'kg_emb.purchase_bias.weight', 'kg_emb.padding_bias.weight', 'kg_emb.13_bias.weight', 'kg_emb.37_bias.weight', 'kg_emb.23_bias.weight', 'kg_emb.5_bias.weight', 'kg_emb.7_bias.weight', 'kg_emb.19_bias.weight', 'kg_emb.12_bias.weight', 'kg_emb.4_bias.weight', 'kg_emb.28_bias.weight', 'kg_emb.2_bias.weight', 'kg_emb.10_bias.weight', 'kg_emb.0_bias.weight', 'kg_emb.15_bias.weight', 'kg_emb.33_bias.weight', 'kg_emb.27_bias.weight', 'kg_emb.14_bias.weight', 'kg_emb.21_bias.weight', 'kg_emb.25_bias.weight', 'kg_emb.31_bias.weight', 'kg_emb.18_bias.weight', 'kg_emb.self_loop_bias.weight', 'kg_emb.35_bias.weight', 'kg_emb.20_bias.weight', 'kg_emb.38_bias.weight', 'kg_emb.16_bias.weight', 'state_lstm.policy_lstm.lstm.weight_ih_l0', 'state_lstm.policy_lstm.lstm.weight_hh_l0', 'state_lstm.policy_lstm.lstm.bias_ih_l0', 'state_lstm.policy_lstm.lstm.bias_hh_l0', 'transfor_state.weight', 'transfor_state.bias', 'state_tr_query.weight', 'state_tr_query.bias', 'l1.weight', 'l1.bias', 'l2.weight', 'l2.bias', 'actor.weight', 'actor.bias', 'critic.weight', 'critic.bias']
[INFO]  epoch/step=0/100 | loss=0.20605 | ploss=0.14062 | vloss=0.07298 | entropy=-8.26895 | reward=0.02250
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_0.ckpt
[INFO]  epoch/step=1/200 | loss=0.09812 | ploss=0.03051 | vloss=0.07512 | entropy=-8.22064 | reward=0.02500
[INFO]  epoch/step=1/300 | loss=0.11904 | ploss=0.02781 | vloss=0.09861 | entropy=-8.08586 | reward=0.03406
[INFO]  epoch/step=2/400 | loss=0.11556 | ploss=0.03847 | vloss=0.08435 | entropy=-7.96432 | reward=0.02875
[INFO]  epoch/step=2/500 | loss=0.09465 | ploss=0.01769 | vloss=0.08417 | entropy=-7.92109 | reward=0.02937
[INFO]  epoch/step=3/600 | loss=0.08497 | ploss=0.01719 | vloss=0.07498 | entropy=-7.90148 | reward=0.02625
[INFO]  epoch/step=3/700 | loss=0.09825 | ploss=0.02695 | vloss=0.07847 | entropy=-7.87534 | reward=0.02719
[INFO]  epoch/step=4/800 | loss=0.13745 | ploss=0.04067 | vloss=0.10400 | entropy=-7.92444 | reward=0.03656
[INFO]  epoch/step=4/900 | loss=0.11615 | ploss=0.02579 | vloss=0.09759 | entropy=-7.92673 | reward=0.03500
[INFO]  epoch/step=5/1000 | loss=0.09342 | ploss=0.00048 | vloss=0.10004 | entropy=-7.80531 | reward=0.03500
[INFO]  epoch/step=5/1100 | loss=0.10326 | ploss=0.01318 | vloss=0.09710 | entropy=-7.71911 | reward=0.03438
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_5.ckpt
[INFO]  epoch/step=6/1200 | loss=0.11180 | ploss=0.02911 | vloss=0.08970 | entropy=-7.70407 | reward=0.03094
[INFO]  epoch/step=6/1300 | loss=0.11047 | ploss=0.01429 | vloss=0.10319 | entropy=-7.71488 | reward=0.03687
[INFO]  epoch/step=7/1400 | loss=0.11932 | ploss=0.02666 | vloss=0.09969 | entropy=-7.73550 | reward=0.03500
[INFO]  epoch/step=7/1500 | loss=0.12088 | ploss=0.01914 | vloss=0.10873 | entropy=-7.69100 | reward=0.03906
[INFO]  epoch/step=8/1600 | loss=0.10095 | ploss=0.00228 | vloss=0.10562 | entropy=-7.64945 | reward=0.03781
[INFO]  epoch/step=9/1700 | loss=0.13453 | ploss=0.03570 | vloss=0.10581 | entropy=-7.67945 | reward=0.03719
[INFO]  epoch/step=9/1800 | loss=0.10290 | ploss=-0.00358 | vloss=0.11349 | entropy=-7.70665 | reward=0.04063
[INFO]  epoch/step=10/1900 | loss=0.13064 | ploss=0.01773 | vloss=0.11990 | entropy=-7.68798 | reward=0.04344
[INFO]  epoch/step=10/2000 | loss=0.13338 | ploss=0.02347 | vloss=0.11683 | entropy=-7.61891 | reward=0.04219
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_10.ckpt
[INFO]  epoch/step=11/2100 | loss=0.09846 | ploss=-0.01298 | vloss=0.11829 | entropy=-7.55252 | reward=0.04188
[INFO]  epoch/step=11/2200 | loss=0.11473 | ploss=0.01043 | vloss=0.11104 | entropy=-7.44539 | reward=0.04031
[INFO]  epoch/step=12/2300 | loss=0.12104 | ploss=-0.01379 | vloss=0.14146 | entropy=-7.33056 | reward=0.05000
[INFO]  epoch/step=12/2400 | loss=0.13721 | ploss=0.01944 | vloss=0.12438 | entropy=-7.30606 | reward=0.04469
[INFO]  epoch/step=13/2500 | loss=0.10839 | ploss=0.00045 | vloss=0.11454 | entropy=-7.30757 | reward=0.04063
[INFO]  epoch/step=13/2600 | loss=0.13465 | ploss=0.01093 | vloss=0.13031 | entropy=-7.29247 | reward=0.04719
[INFO]  epoch/step=14/2700 | loss=0.08846 | ploss=-0.02048 | vloss=0.11549 | entropy=-7.25105 | reward=0.04094
[INFO]  epoch/step=14/2800 | loss=0.13059 | ploss=0.02294 | vloss=0.11416 | entropy=-7.21935 | reward=0.04125
[INFO]  epoch/step=15/2900 | loss=0.14972 | ploss=0.01823 | vloss=0.13803 | entropy=-7.25459 | reward=0.05031
[INFO]  epoch/step=15/3000 | loss=0.11440 | ploss=-0.00596 | vloss=0.12689 | entropy=-7.23012 | reward=0.04562
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_15.ckpt
[INFO]  epoch/step=16/3100 | loss=0.11809 | ploss=-0.01003 | vloss=0.13457 | entropy=-7.14705 | reward=0.04813
[INFO]  epoch/step=17/3200 | loss=0.14831 | ploss=0.00929 | vloss=0.14530 | entropy=-6.99271 | reward=0.05344
[INFO]  epoch/step=17/3300 | loss=0.12817 | ploss=-0.00223 | vloss=0.13672 | entropy=-7.01766 | reward=0.05031
[INFO]  epoch/step=18/3400 | loss=0.15713 | ploss=0.00855 | vloss=0.15497 | entropy=-7.09383 | reward=0.05750
[INFO]  epoch/step=18/3500 | loss=0.15284 | ploss=0.00743 | vloss=0.15188 | entropy=-7.16976 | reward=0.05563
[INFO]  epoch/step=19/3600 | loss=0.16397 | ploss=0.00131 | vloss=0.16910 | entropy=-7.14815 | reward=0.06187
[INFO]  epoch/step=19/3700 | loss=0.13677 | ploss=-0.02058 | vloss=0.16356 | entropy=-6.92033 | reward=0.06000
[INFO]  epoch/step=20/3800 | loss=0.14321 | ploss=-0.00146 | vloss=0.15088 | entropy=-6.90993 | reward=0.05563
[INFO]  epoch/step=20/3900 | loss=0.16787 | ploss=0.00191 | vloss=0.17222 | entropy=-6.95377 | reward=0.06469
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_20.ckpt
[INFO]  epoch/step=21/4000 | loss=0.14867 | ploss=-0.01175 | vloss=0.16654 | entropy=-6.83425 | reward=0.06250
[INFO]  epoch/step=21/4100 | loss=0.16963 | ploss=0.01677 | vloss=0.15896 | entropy=-6.80127 | reward=0.05781
[INFO]  epoch/step=22/4200 | loss=0.13453 | ploss=-0.02814 | vloss=0.16900 | entropy=-7.03151 | reward=0.06375
[INFO]  epoch/step=22/4300 | loss=0.15861 | ploss=0.00287 | vloss=0.16201 | entropy=-6.97278 | reward=0.05969
[INFO]  epoch/step=23/4400 | loss=0.14031 | ploss=-0.02396 | vloss=0.17045 | entropy=-6.88893 | reward=0.06250
[INFO]  epoch/step=23/4500 | loss=0.17343 | ploss=-0.00122 | vloss=0.18074 | entropy=-6.79778 | reward=0.06750
[INFO]  epoch/step=24/4600 | loss=0.15073 | ploss=-0.02007 | vloss=0.17691 | entropy=-6.81906 | reward=0.06531
[INFO]  epoch/step=24/4700 | loss=0.19605 | ploss=0.01874 | vloss=0.18345 | entropy=-6.84122 | reward=0.06844
[INFO]  epoch/step=25/4800 | loss=0.13145 | ploss=-0.03809 | vloss=0.17562 | entropy=-6.79381 | reward=0.06625
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_25.ckpt
[INFO]  epoch/step=26/4900 | loss=0.16469 | ploss=-0.01515 | vloss=0.18590 | entropy=-6.76902 | reward=0.06969
[INFO]  epoch/step=26/5000 | loss=0.20357 | ploss=0.01680 | vloss=0.19278 | entropy=-6.72457 | reward=0.07250
[INFO]  epoch/step=27/5100 | loss=0.18341 | ploss=-0.01430 | vloss=0.20371 | entropy=-6.69812 | reward=0.07687
[INFO]  epoch/step=27/5200 | loss=0.16334 | ploss=-0.02721 | vloss=0.19651 | entropy=-6.66279 | reward=0.07469
[INFO]  epoch/step=28/5300 | loss=0.15704 | ploss=-0.02296 | vloss=0.18599 | entropy=-6.69162 | reward=0.06969
[INFO]  epoch/step=28/5400 | loss=0.18225 | ploss=-0.01163 | vloss=0.19978 | entropy=-6.60900 | reward=0.07531
[INFO]  epoch/step=29/5500 | loss=0.18488 | ploss=-0.00028 | vloss=0.19103 | entropy=-6.57617 | reward=0.07125
[INFO]  epoch/step=29/5600 | loss=0.18528 | ploss=-0.01598 | vloss=0.20713 | entropy=-6.57358 | reward=0.07844
[INFO]  epoch/step=30/5700 | loss=0.20232 | ploss=-0.01589 | vloss=0.22402 | entropy=-6.51043 | reward=0.08500
[INFO]  epoch/step=30/5800 | loss=0.19015 | ploss=0.00525 | vloss=0.19066 | entropy=-6.46538 | reward=0.07156
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_30.ckpt
[INFO]  epoch/step=31/5900 | loss=0.17788 | ploss=-0.02993 | vloss=0.21357 | entropy=-6.45859 | reward=0.08063
[INFO]  epoch/step=31/6000 | loss=0.21036 | ploss=-0.01021 | vloss=0.22636 | entropy=-6.49305 | reward=0.08687
[INFO]  epoch/step=32/6100 | loss=0.20652 | ploss=-0.00984 | vloss=0.22211 | entropy=-6.45643 | reward=0.08594
[INFO]  epoch/step=32/6200 | loss=0.16833 | ploss=-0.04344 | vloss=0.21751 | entropy=-6.44133 | reward=0.08313
[INFO]  epoch/step=33/6300 | loss=0.23062 | ploss=0.01128 | vloss=0.22509 | entropy=-6.45795 | reward=0.08719
[INFO]  epoch/step=34/6400 | loss=0.18456 | ploss=-0.01787 | vloss=0.20817 | entropy=-6.44903 | reward=0.07969
[INFO]  epoch/step=34/6500 | loss=0.21569 | ploss=-0.00720 | vloss=0.22864 | entropy=-6.45327 | reward=0.08719
[INFO]  epoch/step=35/6600 | loss=0.17749 | ploss=-0.01799 | vloss=0.20119 | entropy=-6.41182 | reward=0.07594
[INFO]  epoch/step=35/6700 | loss=0.21381 | ploss=-0.02361 | vloss=0.24308 | entropy=-6.37368 | reward=0.09406
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_35.ckpt
[INFO]  epoch/step=36/6800 | loss=0.23475 | ploss=-0.00925 | vloss=0.24964 | entropy=-6.34545 | reward=0.09656
[INFO]  epoch/step=36/6900 | loss=0.17912 | ploss=-0.05871 | vloss=0.24347 | entropy=-6.34708 | reward=0.09438
[INFO]  epoch/step=37/7000 | loss=0.20695 | ploss=-0.02680 | vloss=0.23937 | entropy=-6.33395 | reward=0.09125
[INFO]  epoch/step=37/7100 | loss=0.20429 | ploss=-0.02994 | vloss=0.23982 | entropy=-6.28855 | reward=0.09250
[INFO]  epoch/step=38/7200 | loss=0.18354 | ploss=-0.02761 | vloss=0.21676 | entropy=-6.31598 | reward=0.08094
[INFO]  epoch/step=38/7300 | loss=0.24577 | ploss=-0.01311 | vloss=0.26446 | entropy=-6.29003 | reward=0.10437
[INFO]  epoch/step=39/7400 | loss=0.21648 | ploss=-0.02653 | vloss=0.24854 | entropy=-6.24145 | reward=0.09750
[INFO]  epoch/step=39/7500 | loss=0.20626 | ploss=-0.02693 | vloss=0.23869 | entropy=-6.20950 | reward=0.09250
[INFO]  epoch/step=40/7600 | loss=0.23497 | ploss=-0.01454 | vloss=0.25498 | entropy=-6.18190 | reward=0.10063
[INFO]  epoch/step=40/7700 | loss=0.20694 | ploss=-0.02837 | vloss=0.24078 | entropy=-6.18053 | reward=0.09281
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_40.ckpt
[INFO]  epoch/step=41/7800 | loss=0.20529 | ploss=-0.03754 | vloss=0.24837 | entropy=-6.24102 | reward=0.09625
[INFO]  epoch/step=42/7900 | loss=0.23710 | ploss=-0.00223 | vloss=0.24482 | entropy=-6.19641 | reward=0.09656
[INFO]  epoch/step=42/8000 | loss=0.20378 | ploss=-0.03014 | vloss=0.23937 | entropy=-6.16098 | reward=0.09438
[INFO]  epoch/step=43/8100 | loss=0.24114 | ploss=-0.01241 | vloss=0.25902 | entropy=-6.18561 | reward=0.10094
[INFO]  epoch/step=43/8200 | loss=0.21704 | ploss=-0.02588 | vloss=0.24837 | entropy=-6.16618 | reward=0.09750
[INFO]  epoch/step=44/8300 | loss=0.22087 | ploss=-0.01829 | vloss=0.24460 | entropy=-6.14591 | reward=0.09563
[INFO]  epoch/step=44/8400 | loss=0.22849 | ploss=-0.01365 | vloss=0.24756 | entropy=-6.13097 | reward=0.09656
[INFO]  epoch/step=45/8500 | loss=0.22802 | ploss=-0.02824 | vloss=0.26162 | entropy=-6.06592 | reward=0.10219
[INFO]  epoch/step=45/8600 | loss=0.23226 | ploss=-0.01432 | vloss=0.25192 | entropy=-6.04536 | reward=0.10094
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_45.ckpt
[INFO]  epoch/step=46/8700 | loss=0.18651 | ploss=-0.04059 | vloss=0.23242 | entropy=-6.02653 | reward=0.09094
[INFO]  epoch/step=46/8800 | loss=0.24568 | ploss=-0.01634 | vloss=0.26730 | entropy=-5.98713 | reward=0.10687
[INFO]  epoch/step=47/8900 | loss=0.20492 | ploss=-0.03774 | vloss=0.24797 | entropy=-6.00674 | reward=0.09656
[INFO]  epoch/step=47/9000 | loss=0.23401 | ploss=-0.00862 | vloss=0.24789 | entropy=-5.97491 | reward=0.09750
[INFO]  epoch/step=48/9100 | loss=0.24043 | ploss=-0.03310 | vloss=0.27882 | entropy=-5.99186 | reward=0.11063
[INFO]  epoch/step=48/9200 | loss=0.20542 | ploss=-0.02683 | vloss=0.23753 | entropy=-5.99405 | reward=0.09187
[INFO]  epoch/step=49/9300 | loss=0.24091 | ploss=-0.02143 | vloss=0.26762 | entropy=-5.99374 | reward=0.10500
[INFO]  epoch/step=49/9400 | loss=0.25769 | ploss=-0.01496 | vloss=0.27792 | entropy=-5.98377 | reward=0.10875
[INFO]  epoch/step=50/9500 | loss=0.19947 | ploss=-0.04432 | vloss=0.24906 | entropy=-5.97661 | reward=0.09719
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_50.ckpt
[INFO]  epoch/step=51/9600 | loss=0.22514 | ploss=-0.04008 | vloss=0.27043 | entropy=-5.92163 | reward=0.10812
[INFO]  epoch/step=51/9700 | loss=0.26950 | ploss=0.00130 | vloss=0.27338 | entropy=-5.89540 | reward=0.10844
[INFO]  epoch/step=52/9800 | loss=0.22465 | ploss=-0.04005 | vloss=0.26991 | entropy=-5.91737 | reward=0.10719
[INFO]  epoch/step=52/9900 | loss=0.21337 | ploss=-0.04692 | vloss=0.26549 | entropy=-5.91186 | reward=0.10562
[INFO]  epoch/step=53/10000 | loss=0.21468 | ploss=-0.04945 | vloss=0.26934 | entropy=-5.91826 | reward=0.10875
[INFO]  epoch/step=53/10100 | loss=0.23176 | ploss=-0.03004 | vloss=0.26700 | entropy=-5.91319 | reward=0.10531
[INFO]  epoch/step=54/10200 | loss=0.24843 | ploss=-0.01575 | vloss=0.26932 | entropy=-5.84552 | reward=0.10875
[INFO]  epoch/step=54/10300 | loss=0.23953 | ploss=-0.03042 | vloss=0.27510 | entropy=-5.85819 | reward=0.11063
[INFO]  epoch/step=55/10400 | loss=0.26969 | ploss=-0.00671 | vloss=0.28153 | entropy=-5.84955 | reward=0.11313
[INFO]  epoch/step=55/10500 | loss=0.24045 | ploss=-0.03442 | vloss=0.28001 | entropy=-5.86267 | reward=0.11281
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_55.ckpt
[INFO]  epoch/step=56/10600 | loss=0.23445 | ploss=-0.04400 | vloss=0.28354 | entropy=-5.79992 | reward=0.11406
[INFO]  epoch/step=56/10700 | loss=0.24595 | ploss=-0.04516 | vloss=0.29620 | entropy=-5.79266 | reward=0.11875
[INFO]  epoch/step=57/10800 | loss=0.22172 | ploss=-0.04584 | vloss=0.27259 | entropy=-5.74177 | reward=0.10906
[INFO]  epoch/step=57/10900 | loss=0.24537 | ploss=-0.01858 | vloss=0.26897 | entropy=-5.73141 | reward=0.10625
[INFO]  epoch/step=58/11000 | loss=0.21553 | ploss=-0.05295 | vloss=0.27346 | entropy=-5.68675 | reward=0.10750
[INFO]  epoch/step=59/11100 | loss=0.25347 | ploss=-0.03319 | vloss=0.29162 | entropy=-5.67741 | reward=0.11781
[INFO]  epoch/step=59/11200 | loss=0.25540 | ploss=-0.02850 | vloss=0.28887 | entropy=-5.69264 | reward=0.11594
[INFO]  epoch/step=60/11300 | loss=0.25187 | ploss=-0.02395 | vloss=0.28079 | entropy=-5.68741 | reward=0.11406
[INFO]  epoch/step=60/11400 | loss=0.28846 | ploss=-0.01095 | vloss=0.30437 | entropy=-5.66921 | reward=0.12437
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_60.ckpt
[INFO]  epoch/step=61/11500 | loss=0.24081 | ploss=-0.04460 | vloss=0.29036 | entropy=-5.66355 | reward=0.11719
[INFO]  epoch/step=61/11600 | loss=0.26357 | ploss=-0.03208 | vloss=0.30059 | entropy=-5.64406 | reward=0.12219
[INFO]  epoch/step=62/11700 | loss=0.21140 | ploss=-0.07456 | vloss=0.29089 | entropy=-5.64951 | reward=0.11563
[INFO]  epoch/step=62/11800 | loss=0.24645 | ploss=-0.03951 | vloss=0.29084 | entropy=-5.58594 | reward=0.11750
[INFO]  epoch/step=63/11900 | loss=0.25545 | ploss=-0.04333 | vloss=0.30363 | entropy=-5.56933 | reward=0.12312
[INFO]  epoch/step=63/12000 | loss=0.26201 | ploss=-0.03647 | vloss=0.30334 | entropy=-5.56813 | reward=0.12156
[INFO]  epoch/step=64/12100 | loss=0.23465 | ploss=-0.06150 | vloss=0.30094 | entropy=-5.49870 | reward=0.12031
[INFO]  epoch/step=64/12200 | loss=0.27609 | ploss=-0.03072 | vloss=0.31157 | entropy=-5.46947 | reward=0.12812
[INFO]  epoch/step=65/12300 | loss=0.22495 | ploss=-0.05958 | vloss=0.28929 | entropy=-5.47750 | reward=0.11500
[INFO]  epoch/step=65/12400 | loss=0.29443 | ploss=-0.02778 | vloss=0.32695 | entropy=-5.44775 | reward=0.13344
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_65.ckpt
[INFO]  epoch/step=66/12500 | loss=0.24838 | ploss=-0.07208 | vloss=0.32520 | entropy=-5.45610 | reward=0.13250
[INFO]  epoch/step=67/12600 | loss=0.26630 | ploss=-0.02710 | vloss=0.29814 | entropy=-5.45406 | reward=0.11906
[INFO]  epoch/step=67/12700 | loss=0.20602 | ploss=-0.06896 | vloss=0.27972 | entropy=-5.44683 | reward=0.11188
[INFO]  epoch/step=68/12800 | loss=0.27135 | ploss=-0.03524 | vloss=0.31129 | entropy=-5.40961 | reward=0.12687
[INFO]  epoch/step=68/12900 | loss=0.24060 | ploss=-0.05695 | vloss=0.30220 | entropy=-5.35913 | reward=0.12250
[INFO]  epoch/step=69/13000 | loss=0.22203 | ploss=-0.06913 | vloss=0.29583 | entropy=-5.38163 | reward=0.11906
[INFO]  epoch/step=69/13100 | loss=0.26284 | ploss=-0.03497 | vloss=0.30244 | entropy=-5.34363 | reward=0.12156
[INFO]  epoch/step=70/13200 | loss=0.23684 | ploss=-0.04894 | vloss=0.29042 | entropy=-5.35388 | reward=0.11781
[INFO]  epoch/step=70/13300 | loss=0.28701 | ploss=-0.02373 | vloss=0.31538 | entropy=-5.34376 | reward=0.12812
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_70.ckpt
[INFO]  epoch/step=71/13400 | loss=0.29194 | ploss=-0.03253 | vloss=0.32909 | entropy=-5.32624 | reward=0.13625
[INFO]  epoch/step=71/13500 | loss=0.25218 | ploss=-0.05679 | vloss=0.31356 | entropy=-5.30643 | reward=0.12781
[INFO]  epoch/step=72/13600 | loss=0.23545 | ploss=-0.06042 | vloss=0.30049 | entropy=-5.32566 | reward=0.11844
[INFO]  epoch/step=72/13700 | loss=0.23718 | ploss=-0.06464 | vloss=0.30642 | entropy=-5.31142 | reward=0.12469
[INFO]  epoch/step=73/13800 | loss=0.26097 | ploss=-0.05245 | vloss=0.31799 | entropy=-5.27765 | reward=0.12812
[INFO]  epoch/step=73/13900 | loss=0.27266 | ploss=-0.04312 | vloss=0.32035 | entropy=-5.27677 | reward=0.13031
[INFO]  epoch/step=74/14000 | loss=0.24272 | ploss=-0.06602 | vloss=0.31326 | entropy=-5.22743 | reward=0.12781
[INFO]  epoch/step=74/14100 | loss=0.24786 | ploss=-0.05146 | vloss=0.30382 | entropy=-5.19973 | reward=0.12344
[INFO]  epoch/step=75/14200 | loss=0.22371 | ploss=-0.07029 | vloss=0.29846 | entropy=-5.16753 | reward=0.11812
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_75.ckpt
[INFO]  epoch/step=76/14300 | loss=0.21974 | ploss=-0.08090 | vloss=0.30514 | entropy=-5.21057 | reward=0.12437
[INFO]  epoch/step=76/14400 | loss=0.25759 | ploss=-0.04780 | vloss=0.30984 | entropy=-5.16595 | reward=0.12469
[INFO]  epoch/step=77/14500 | loss=0.26314 | ploss=-0.06908 | vloss=0.33667 | entropy=-5.16097 | reward=0.13812
[INFO]  epoch/step=77/14600 | loss=0.23568 | ploss=-0.07827 | vloss=0.31834 | entropy=-5.10843 | reward=0.12937
[INFO]  epoch/step=78/14700 | loss=0.27237 | ploss=-0.05731 | vloss=0.33409 | entropy=-5.12232 | reward=0.13719
[INFO]  epoch/step=78/14800 | loss=0.23055 | ploss=-0.07569 | vloss=0.31059 | entropy=-5.07287 | reward=0.12656
[INFO]  epoch/step=79/14900 | loss=0.25323 | ploss=-0.06734 | vloss=0.32497 | entropy=-5.10868 | reward=0.13187
[INFO]  epoch/step=79/15000 | loss=0.27694 | ploss=-0.04223 | vloss=0.32356 | entropy=-5.10214 | reward=0.13312
[INFO]  epoch/step=80/15100 | loss=0.26492 | ploss=-0.04562 | vloss=0.31492 | entropy=-5.09210 | reward=0.12750
[INFO]  epoch/step=80/15200 | loss=0.23955 | ploss=-0.06794 | vloss=0.31188 | entropy=-5.09908 | reward=0.12594
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_80.ckpt
[INFO]  epoch/step=81/15300 | loss=0.24029 | ploss=-0.07016 | vloss=0.31479 | entropy=-5.04981 | reward=0.12937
[INFO]  epoch/step=81/15400 | loss=0.26499 | ploss=-0.04777 | vloss=0.31711 | entropy=-5.05411 | reward=0.12969
[INFO]  epoch/step=82/15500 | loss=0.30591 | ploss=-0.02147 | vloss=0.33175 | entropy=-5.07703 | reward=0.13437
[INFO]  epoch/step=82/15600 | loss=0.26155 | ploss=-0.05676 | vloss=0.32272 | entropy=-5.12265 | reward=0.13031
[INFO]  epoch/step=83/15700 | loss=0.28808 | ploss=-0.04009 | vloss=0.33252 | entropy=-5.06463 | reward=0.13656
[INFO]  epoch/step=84/15800 | loss=0.28417 | ploss=-0.05498 | vloss=0.34349 | entropy=-5.05747 | reward=0.14281
[INFO]  epoch/step=84/15900 | loss=0.27502 | ploss=-0.04767 | vloss=0.32704 | entropy=-5.05608 | reward=0.13500
[INFO]  epoch/step=85/16000 | loss=0.24324 | ploss=-0.07344 | vloss=0.32101 | entropy=-5.04993 | reward=0.13094
[INFO]  epoch/step=85/16100 | loss=0.25097 | ploss=-0.06312 | vloss=0.31844 | entropy=-5.05936 | reward=0.12844
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_85.ckpt
[INFO]  epoch/step=86/16200 | loss=0.30055 | ploss=-0.03107 | vloss=0.33595 | entropy=-5.04296 | reward=0.13781
[INFO]  epoch/step=86/16300 | loss=0.24917 | ploss=-0.06025 | vloss=0.31378 | entropy=-5.06365 | reward=0.13000
[INFO]  epoch/step=87/16400 | loss=0.26484 | ploss=-0.07276 | vloss=0.34191 | entropy=-5.02517 | reward=0.13781
[INFO]  epoch/step=87/16500 | loss=0.24643 | ploss=-0.07193 | vloss=0.32267 | entropy=-5.02784 | reward=0.13406
[INFO]  epoch/step=88/16600 | loss=0.28891 | ploss=-0.04264 | vloss=0.33587 | entropy=-5.02866 | reward=0.13875
[INFO]  epoch/step=88/16700 | loss=0.25969 | ploss=-0.06215 | vloss=0.32616 | entropy=-5.03542 | reward=0.13500
[INFO]  epoch/step=89/16800 | loss=0.28570 | ploss=-0.04479 | vloss=0.33480 | entropy=-5.02535 | reward=0.13687
[INFO]  epoch/step=89/16900 | loss=0.24270 | ploss=-0.08087 | vloss=0.32788 | entropy=-5.02134 | reward=0.13719
[INFO]  epoch/step=90/17000 | loss=0.28397 | ploss=-0.03565 | vloss=0.32393 | entropy=-5.01746 | reward=0.13250
[INFO]  epoch/step=90/17100 | loss=0.22169 | ploss=-0.07484 | vloss=0.30087 | entropy=-5.04988 | reward=0.12219
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_90.ckpt
[INFO]  epoch/step=91/17200 | loss=0.30135 | ploss=-0.01856 | vloss=0.32421 | entropy=-5.01505 | reward=0.13125
[INFO]  epoch/step=92/17300 | loss=0.25230 | ploss=-0.07168 | vloss=0.32831 | entropy=-5.05156 | reward=0.13562
[INFO]  epoch/step=92/17400 | loss=0.23160 | ploss=-0.08337 | vloss=0.31928 | entropy=-5.02476 | reward=0.12937
[INFO]  epoch/step=93/17500 | loss=0.26146 | ploss=-0.07498 | vloss=0.34073 | entropy=-5.00606 | reward=0.14094
[INFO]  epoch/step=93/17600 | loss=0.26821 | ploss=-0.04826 | vloss=0.32078 | entropy=-5.02467 | reward=0.13062
[INFO]  epoch/step=94/17700 | loss=0.26116 | ploss=-0.07335 | vloss=0.33883 | entropy=-5.02519 | reward=0.13906
[INFO]  epoch/step=94/17800 | loss=0.28803 | ploss=-0.04988 | vloss=0.34216 | entropy=-4.95478 | reward=0.13906
[INFO]  epoch/step=95/17900 | loss=0.28643 | ploss=-0.06020 | vloss=0.35089 | entropy=-4.97711 | reward=0.14594
[INFO]  epoch/step=95/18000 | loss=0.25414 | ploss=-0.06274 | vloss=0.32116 | entropy=-4.98950 | reward=0.13187
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_95.ckpt
[INFO]  epoch/step=96/18100 | loss=0.25989 | ploss=-0.06788 | vloss=0.33204 | entropy=-4.98916 | reward=0.13937
[INFO]  epoch/step=96/18200 | loss=0.27765 | ploss=-0.04984 | vloss=0.33176 | entropy=-4.98770 | reward=0.13875
[INFO]  epoch/step=97/18300 | loss=0.23634 | ploss=-0.08512 | vloss=0.32571 | entropy=-4.96613 | reward=0.13187
[INFO]  epoch/step=97/18400 | loss=0.26028 | ploss=-0.04721 | vloss=0.31173 | entropy=-4.94880 | reward=0.12656
[INFO]  epoch/step=98/18500 | loss=0.26895 | ploss=-0.06237 | vloss=0.33555 | entropy=-4.94327 | reward=0.13812
[INFO]  epoch/step=98/18600 | loss=0.28736 | ploss=-0.06005 | vloss=0.35162 | entropy=-4.92402 | reward=0.14500
[INFO]  epoch/step=99/18700 | loss=0.25955 | ploss=-0.07001 | vloss=0.33380 | entropy=-4.95299 | reward=0.13687
[INFO]  epoch/step=99/18800 | loss=0.25971 | ploss=-0.07887 | vloss=0.34281 | entropy=-4.94308 | reward=0.14125
[INFO]  epoch/step=100/18900 | loss=0.25469 | ploss=-0.08331 | vloss=0.34220 | entropy=-4.91825 | reward=0.14344
[INFO]  Save model to ../sv_model/amazon-book_20core/lstm/3_ba32lstm_3002e-04_sveb32_kge0_g_aiu_0_0_6000/policy_model_epoch_100.ckpt
[INFO]  epoch/step=101/19000 | loss=0.26112 | ploss=-0.08124 | vloss=0.34657 | entropy=-4.92364 | reward=0.14375
[INFO]  epoch/step=101/19100 | loss=0.31567 | ploss=-0.02959 | vloss=0.34947 | entropy=-4.93137 | reward=0.14531
[INFO]  epoch/step=102/19200 | loss=0.25977 | ploss=-0.08479 | vloss=0.34879 | entropy=-4.93740 | reward=0.14250
[INFO]  epoch/step=102/19300 | loss=0.27614 | ploss=-0.04891 | vloss=0.32925 | entropy=-4.91681 | reward=0.13562
[INFO]  epoch/step=103/19400 | loss=0.22828 | ploss=-0.07729 | vloss=0.30977 | entropy=-4.91585 | reward=0.12656
[INFO]  epoch/step=103/19500 | loss=0.27205 | ploss=-0.06581 | vloss=0.34205 | entropy=-4.89990 | reward=0.14188
[INFO]  epoch/step=104/19600 | loss=0.28154 | ploss=-0.05362 | vloss=0.33933 | entropy=-4.88582 | reward=0.13844
[INFO]  epoch/step=104/19700 | loss=0.25811 | ploss=-0.06615 | vloss=0.32845 | entropy=-4.90893 | reward=0.13594
[INFO]  epoch/step=105/19800 | loss=0.24219 | ploss=-0.08420 | vloss=0.33058 | entropy=-4.90698 | reward=0.13625
