{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "previous-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running UCPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mighty-faith",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/johnnyjana730/github/UCPR/', '/home/johnnyjana730/github/UCPR/bash', '/home/johnnyjana730/anaconda3_tmp/lib/python38.zip', '/home/johnnyjana730/anaconda3_tmp/lib/python3.8', '/home/johnnyjana730/anaconda3_tmp/lib/python3.8/lib-dynload', '', '/home/johnnyjana730/anaconda3_tmp/lib/python3.8/site-packages', '/home/johnnyjana730/anaconda3_tmp/lib/python3.8/site-packages/locket-0.2.1-py3.8.egg', '/home/johnnyjana730/anaconda3_tmp/lib/python3.8/site-packages/IPython/extensions', '/home/johnnyjana730/.ipython']\n",
      "dataset =  MovieLens-1M_core\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'/home/johnnyjana730/github/UCPR/')\n",
    "print(sys.path)\n",
    "\n",
    "from config import get_hparams\n",
    "\n",
    "!export PYTHONPATH=\"./\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from config import get_hparams\n",
    "\n",
    "# cell_core, beauty_core, cloth_core, MovieLens-1M_core, amazon-book_20core\n",
    "\n",
    "DATASET = \"MovieLens-1M_core\"\n",
    "\n",
    "locals().update(get_hparams(DATASET))\n",
    "\n",
    "epochs=400\n",
    "KGE_pretrained=1\n",
    "kg_emb_grad=1\n",
    "load_pretrain_model=0\n",
    "batch_size=32\n",
    "train_file=\"train.py\"\n",
    "test_file=\"test.py\"\n",
    "\n",
    "exp_name= f\"note_ld{lambda_num}_rn{reasoning_step}_h1{p_hop}_nmem{n_memory}_em{embed_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brief-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-secretariat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Command:\n",
      "python3 ../src/train.py --reasoning_step 4 --batch_size 32 --name note_ld2.0_rn4_h12_nmem64_em32 --lr 0.0001 --embed_size 32 --n_memory 64 --load_pretrain_model 0 --gp_setting 6000_800_15_500_50 --epochs 400 --KGE_pretrained 1 --lambda_num 2.0 --kg_emb_grad 1 --p_hop 2 --reasoning_step 4 --model lstm --dataset MovieLens-1M_core\n",
      "args.gp_setting =  6000_800_15_500_50 args.att_core =  0 args.item_core =  0 args.user_core =  6000 args.kg_fre_upper =  500 args.max_acts =  50\n",
      "len(self.core_user_list) =  6000\n",
      "self.args.core_user_list =  6000\n",
      "self.user_triplet_list =  6000\n",
      "Load embedding: ../data/MovieLens-1M_Core/transe_embed.pkl\n",
      "env.output_valid_user() =  6000\n",
      "args.batch_size =  32\n",
      "Load embedding: ../data/MovieLens-1M_Core/transe_embed.pkl\n",
      "et =  user 6036\n",
      "et =  product 8481\n",
      "et =  attribute 188047\n",
      "key =  user\n",
      "self.embeds[key] =  torch.Size([6037, 32])\n",
      "vocab_size + 1 =  6037\n",
      "embed =  torch.Size([6037, 32])\n",
      "embed.requires_grad =  True\n",
      "key =  product\n",
      "self.embeds[key] =  torch.Size([8482, 32])\n",
      "vocab_size + 1 =  8482\n",
      "embed =  torch.Size([8482, 32])\n",
      "embed.requires_grad =  True\n",
      "key =  attribute\n",
      "self.embeds[key] =  torch.Size([188048, 32])\n",
      "vocab_size + 1 =  188048\n",
      "embed =  torch.Size([188048, 32])\n",
      "embed.requires_grad =  True\n",
      "5 embed =  torch.Size([1, 32])\n",
      "11 embed =  torch.Size([1, 32])\n",
      "8 embed =  torch.Size([1, 32])\n",
      "self_loop embed =  torch.Size([1, 32])\n",
      "purchase embed =  torch.Size([1, 32])\n",
      "7 embed =  torch.Size([1, 32])\n",
      "1 embed =  torch.Size([1, 32])\n",
      "0 embed =  torch.Size([1, 32])\n",
      "9 embed =  torch.Size([1, 32])\n",
      "6 embed =  torch.Size([1, 32])\n",
      "2 embed =  torch.Size([1, 32])\n",
      "10 embed =  torch.Size([1, 32])\n",
      "padding embed =  torch.Size([1, 32])\n",
      "3 embed =  torch.Size([1, 32])\n",
      "4 embed =  torch.Size([1, 32])\n",
      "[INFO]  Namespace(KGE_pretrained=True, act_dropout=0.5, add_products=False, att_core=0, att_evaluation=False, batch_size=32, best_model_epoch=0, best_save_model_dir='', core_user_list='', dataset='MovieLens-1M_core', device=device(type='cuda', index=0), embed_size=32, ent_weight=0.001, envir='p2', epochs=400, eva_epochs=0, gamma=0.99, gp_setting='6000_800_15_500_50', gpu='0', gradient_plot='gradient_plot/', h0_embbed=0, hidden=[64, 32], item_core=0, kg_emb_grad=True, kg_fre_dict='', kg_fre_lower=15, kg_fre_upper=500, kg_no_grad=False, l2_lambda=0, l2_weight=1e-06, lambda_num=2.0, load_pretrain_model=False, load_pt_emb_size=False, log_dir='../eva/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000', logger=<Logger ../eva/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/train_log.txt (DEBUG)>, lr=0.0001, max_acts=50, max_path_len=3, model='lstm', n_memory=64, name='note_ld2.0_rn4_h12_nmem64_em32', non_sampling=True, p_hop=2, pretest=False, pretrained_dir='../eva/MovieLens-1M_Core/pretrained/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000', pretrained_st_epoch=0, reasoning_step=4, reward_hybrid=False, reward_rh='', run_eval=True, run_path=True, sam_type='alet', save_model_dir='../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000', seed=52, sort_by='prob', state_history=1, state_rg=False, sub_batch_size=1, test_lstm_up=True, topk=[8, 3, 4], topk_list=[1, 8, 24, 96], topk_string='8, 3, 4', training=True, tri_pro_rm=False, tri_wd_rm=False, user_core=6000)\n",
      "[INFO]  Parameters:['kg_emb.5', 'kg_emb.11', 'kg_emb.8', 'kg_emb.self_loop', 'kg_emb.purchase', 'kg_emb.7', 'kg_emb.1', 'kg_emb.0', 'kg_emb.9', 'kg_emb.6', 'kg_emb.2', 'kg_emb.10', 'kg_emb.padding', 'kg_emb.3', 'kg_emb.4', 'kg_emb.user.weight', 'kg_emb.product.weight', 'kg_emb.attribute.weight', 'kg_emb.5_bias.weight', 'kg_emb.11_bias.weight', 'kg_emb.8_bias.weight', 'kg_emb.self_loop_bias.weight', 'kg_emb.purchase_bias.weight', 'kg_emb.7_bias.weight', 'kg_emb.1_bias.weight', 'kg_emb.0_bias.weight', 'kg_emb.9_bias.weight', 'kg_emb.6_bias.weight', 'kg_emb.2_bias.weight', 'kg_emb.10_bias.weight', 'kg_emb.padding_bias.weight', 'kg_emb.3_bias.weight', 'kg_emb.4_bias.weight', 'state_lstm.policy_lstm.lstm.weight_ih_l0', 'state_lstm.policy_lstm.lstm.weight_hh_l0', 'state_lstm.policy_lstm.lstm.bias_ih_l0', 'state_lstm.policy_lstm.lstm.bias_hh_l0', 'transfor_state.weight', 'transfor_state.bias', 'state_tr_query.weight', 'state_tr_query.bias', 'l1.weight', 'l1.bias', 'l2.weight', 'l2.bias', 'actor.weight', 'actor.bias', 'critic.weight', 'critic.bias']\n",
      "[INFO]  epoch/step=0/100 | loss=0.98736 | ploss=0.73407 | vloss=0.26099 | entropy=-7.85742 | reward=0.08875\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_0.ckpt\n",
      "[INFO]  epoch/step=1/200 | loss=1.05214 | ploss=0.78322 | vloss=0.27661 | entropy=-7.84036 | reward=0.09375\n",
      "[INFO]  epoch/step=1/300 | loss=0.92702 | ploss=0.69027 | vloss=0.24445 | entropy=-7.84233 | reward=0.08313\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_1.ckpt\n",
      "[INFO]  epoch/step=2/400 | loss=0.91138 | ploss=0.67828 | vloss=0.24077 | entropy=-7.81482 | reward=0.08188\n",
      "[INFO]  epoch/step=2/500 | loss=1.08797 | ploss=0.80710 | vloss=0.28856 | entropy=-7.82358 | reward=0.09813\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_2.ckpt\n",
      "[INFO]  epoch/step=3/600 | loss=1.02981 | ploss=0.76087 | vloss=0.27661 | entropy=-7.81509 | reward=0.09344\n",
      "[INFO]  epoch/step=3/700 | loss=1.11336 | ploss=0.82232 | vloss=0.29866 | entropy=-7.76226 | reward=0.10156\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_3.ckpt\n",
      "[INFO]  epoch/step=4/800 | loss=1.15854 | ploss=0.85742 | vloss=0.30877 | entropy=-7.79006 | reward=0.10406\n",
      "[INFO]  epoch/step=4/900 | loss=1.04877 | ploss=0.77243 | vloss=0.28396 | entropy=-7.76248 | reward=0.09656\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_4.ckpt\n",
      "[INFO]  epoch/step=5/1000 | loss=1.19034 | ploss=0.87818 | vloss=0.31980 | entropy=-7.77658 | reward=0.10875\n",
      "[INFO]  epoch/step=5/1100 | loss=1.14572 | ploss=0.84457 | vloss=0.30877 | entropy=-7.75901 | reward=0.10500\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_5.ckpt\n",
      "[INFO]  epoch/step=6/1200 | loss=1.32188 | ploss=0.97476 | vloss=0.35472 | entropy=-7.72556 | reward=0.12000\n",
      "[INFO]  epoch/step=6/1300 | loss=1.18807 | ploss=0.87216 | vloss=0.32348 | entropy=-7.69073 | reward=0.11000\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_6.ckpt\n",
      "[INFO]  epoch/step=7/1400 | loss=1.23831 | ploss=0.90680 | vloss=0.33910 | entropy=-7.71334 | reward=0.11469\n",
      "[INFO]  epoch/step=7/1500 | loss=1.30387 | ploss=0.95577 | vloss=0.35564 | entropy=-7.66588 | reward=0.12094\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_7.ckpt\n",
      "[INFO]  epoch/step=8/1600 | loss=1.38964 | ploss=1.01766 | vloss=0.37953 | entropy=-7.68266 | reward=0.12906\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_8.ckpt\n",
      "[INFO]  epoch/step=9/1700 | loss=1.21486 | ploss=0.88510 | vloss=0.33726 | entropy=-7.62389 | reward=0.11469\n",
      "[INFO]  epoch/step=9/1800 | loss=1.42373 | ploss=1.04069 | vloss=0.39056 | entropy=-7.64045 | reward=0.13281\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_9.ckpt\n",
      "[INFO]  epoch/step=10/1900 | loss=1.24445 | ploss=0.90915 | vloss=0.34277 | entropy=-7.60355 | reward=0.11563\n",
      "[INFO]  epoch/step=10/2000 | loss=1.40597 | ploss=1.02378 | vloss=0.38964 | entropy=-7.57555 | reward=0.13250\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_10.ckpt\n",
      "[INFO]  epoch/step=11/2100 | loss=1.34668 | ploss=0.98476 | vloss=0.36942 | entropy=-7.62244 | reward=0.12500\n",
      "[INFO]  epoch/step=11/2200 | loss=1.36685 | ploss=0.99480 | vloss=0.37953 | entropy=-7.59454 | reward=0.12906\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_11.ckpt\n",
      "[INFO]  epoch/step=12/2300 | loss=1.32130 | ploss=0.96113 | vloss=0.36759 | entropy=-7.53682 | reward=0.12469\n",
      "[INFO]  epoch/step=12/2400 | loss=1.43968 | ploss=1.04827 | vloss=0.39883 | entropy=-7.54164 | reward=0.13562\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_12.ckpt\n",
      "[INFO]  epoch/step=13/2500 | loss=1.43378 | ploss=1.04327 | vloss=0.39791 | entropy=-7.51063 | reward=0.13406\n",
      "[INFO]  epoch/step=13/2600 | loss=1.46163 | ploss=1.05823 | vloss=0.41078 | entropy=-7.49853 | reward=0.13969\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_13.ckpt\n",
      "[INFO]  epoch/step=14/2700 | loss=1.52517 | ploss=1.10150 | vloss=0.43100 | entropy=-7.43558 | reward=0.14594\n",
      "[INFO]  epoch/step=14/2800 | loss=1.44807 | ploss=1.04740 | vloss=0.40802 | entropy=-7.46837 | reward=0.13875\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_14.ckpt\n",
      "[INFO]  epoch/step=15/2900 | loss=1.51282 | ploss=1.08817 | vloss=0.43191 | entropy=-7.38363 | reward=0.14531\n",
      "[INFO]  epoch/step=15/3000 | loss=1.61200 | ploss=1.16440 | vloss=0.45489 | entropy=-7.40752 | reward=0.15469\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_15.ckpt\n",
      "[INFO]  epoch/step=16/3100 | loss=1.46757 | ploss=1.05392 | vloss=0.42089 | entropy=-7.35117 | reward=0.14250\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_16.ckpt\n",
      "[INFO]  epoch/step=17/3200 | loss=1.46569 | ploss=1.05387 | vloss=0.41905 | entropy=-7.33638 | reward=0.14188\n",
      "[INFO]  epoch/step=17/3300 | loss=1.48709 | ploss=1.06789 | vloss=0.42640 | entropy=-7.31041 | reward=0.14500\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_17.ckpt\n",
      "[INFO]  epoch/step=18/3400 | loss=1.47530 | ploss=1.05702 | vloss=0.42548 | entropy=-7.31494 | reward=0.14375\n",
      "[INFO]  epoch/step=18/3500 | loss=1.48789 | ploss=1.06314 | vloss=0.43191 | entropy=-7.27498 | reward=0.14688\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_18.ckpt\n",
      "[INFO]  epoch/step=19/3600 | loss=1.56314 | ploss=1.11540 | vloss=0.45489 | entropy=-7.25149 | reward=0.15438\n",
      "[INFO]  epoch/step=19/3700 | loss=1.56206 | ploss=1.11704 | vloss=0.45213 | entropy=-7.21488 | reward=0.15375\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_19.ckpt\n",
      "[INFO]  epoch/step=20/3800 | loss=1.48150 | ploss=1.05666 | vloss=0.43191 | entropy=-7.18159 | reward=0.14656\n",
      "[INFO]  epoch/step=20/3900 | loss=1.53553 | ploss=1.09231 | vloss=0.45029 | entropy=-7.18163 | reward=0.15313\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_20.ckpt\n",
      "[INFO]  epoch/step=21/4000 | loss=1.62220 | ploss=1.15598 | vloss=0.47327 | entropy=-7.15186 | reward=0.16094\n",
      "[INFO]  epoch/step=21/4100 | loss=1.65088 | ploss=1.17083 | vloss=0.48705 | entropy=-7.10583 | reward=0.16562\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_21.ckpt\n",
      "[INFO]  epoch/step=22/4200 | loss=1.69017 | ploss=1.19266 | vloss=0.50451 | entropy=-7.11380 | reward=0.17094\n",
      "[INFO]  epoch/step=22/4300 | loss=1.66608 | ploss=1.18322 | vloss=0.48981 | entropy=-7.05951 | reward=0.16656\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_22.ckpt\n",
      "[INFO]  epoch/step=23/4400 | loss=1.58176 | ploss=1.11821 | vloss=0.47051 | entropy=-7.06895 | reward=0.15937\n",
      "[INFO]  epoch/step=23/4500 | loss=1.45812 | ploss=1.02851 | vloss=0.43651 | entropy=-7.00002 | reward=0.14844\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_23.ckpt\n",
      "[INFO]  epoch/step=24/4600 | loss=1.69532 | ploss=1.19678 | vloss=0.50543 | entropy=-6.99195 | reward=0.17062\n",
      "[INFO]  epoch/step=24/4700 | loss=1.64356 | ploss=1.15602 | vloss=0.49440 | entropy=-6.97072 | reward=0.16781\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_24.ckpt\n",
      "[INFO]  epoch/step=25/4800 | loss=1.64196 | ploss=1.15163 | vloss=0.49716 | entropy=-6.93513 | reward=0.16906\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_25.ckpt\n",
      "[INFO]  epoch/step=26/4900 | loss=1.73607 | ploss=1.22091 | vloss=0.52197 | entropy=-6.92124 | reward=0.17625\n",
      "[INFO]  epoch/step=26/5000 | loss=1.59727 | ploss=1.12345 | vloss=0.48062 | entropy=-6.89302 | reward=0.16344\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_26.ckpt\n",
      "[INFO]  epoch/step=27/5100 | loss=1.54007 | ploss=1.07907 | vloss=0.46775 | entropy=-6.84638 | reward=0.15844\n",
      "[INFO]  epoch/step=27/5200 | loss=1.68136 | ploss=1.16978 | vloss=0.51830 | entropy=-6.81380 | reward=0.17625\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_27.ckpt\n",
      "[INFO]  epoch/step=28/5300 | loss=1.65323 | ploss=1.15451 | vloss=0.50543 | entropy=-6.81020 | reward=0.17094\n",
      "[INFO]  epoch/step=28/5400 | loss=1.68289 | ploss=1.17864 | vloss=0.51095 | entropy=-6.79117 | reward=0.17375\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_28.ckpt\n",
      "[INFO]  epoch/step=29/5500 | loss=1.57070 | ploss=1.10406 | vloss=0.47327 | entropy=-6.72487 | reward=0.16031\n",
      "[INFO]  epoch/step=29/5600 | loss=1.68097 | ploss=1.17026 | vloss=0.51738 | entropy=-6.76400 | reward=0.17594\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_29.ckpt\n",
      "[INFO]  epoch/step=30/5700 | loss=1.59657 | ploss=1.10604 | vloss=0.49716 | entropy=-6.73009 | reward=0.16812\n",
      "[INFO]  epoch/step=30/5800 | loss=1.65245 | ploss=1.14720 | vloss=0.51186 | entropy=-6.70904 | reward=0.17406\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_30.ckpt\n",
      "[INFO]  epoch/step=31/5900 | loss=1.76844 | ploss=1.23013 | vloss=0.54495 | entropy=-6.73021 | reward=0.18469\n",
      "[INFO]  epoch/step=31/6000 | loss=1.61813 | ploss=1.12938 | vloss=0.49532 | entropy=-6.66185 | reward=0.16844\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_31.ckpt\n",
      "[INFO]  epoch/step=32/6100 | loss=1.72935 | ploss=1.20470 | vloss=0.53116 | entropy=-6.61038 | reward=0.18000\n",
      "[INFO]  epoch/step=32/6200 | loss=1.81253 | ploss=1.25670 | vloss=0.56241 | entropy=-6.67194 | reward=0.19125\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_32.ckpt\n",
      "[INFO]  epoch/step=33/6300 | loss=1.67918 | ploss=1.16742 | vloss=0.51830 | entropy=-6.63475 | reward=0.17500\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_33.ckpt\n",
      "[INFO]  epoch/step=34/6400 | loss=1.72637 | ploss=1.19807 | vloss=0.53484 | entropy=-6.62712 | reward=0.18125\n",
      "[INFO]  epoch/step=34/6500 | loss=1.69997 | ploss=1.17440 | vloss=0.53208 | entropy=-6.60588 | reward=0.18094\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_34.ckpt\n",
      "[INFO]  epoch/step=35/6600 | loss=1.75890 | ploss=1.22229 | vloss=0.54311 | entropy=-6.59061 | reward=0.18313\n",
      "[INFO]  epoch/step=35/6700 | loss=1.74073 | ploss=1.20684 | vloss=0.54035 | entropy=-6.55802 | reward=0.18375\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_35.ckpt\n",
      "[INFO]  epoch/step=36/6800 | loss=1.71521 | ploss=1.18592 | vloss=0.53576 | entropy=-6.56152 | reward=0.18031\n",
      "[INFO]  epoch/step=36/6900 | loss=1.85138 | ploss=1.27700 | vloss=0.58079 | entropy=-6.50086 | reward=0.19750\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_36.ckpt\n",
      "[INFO]  epoch/step=37/7000 | loss=1.76717 | ploss=1.21301 | vloss=0.56057 | entropy=-6.50285 | reward=0.18875\n",
      "[INFO]  epoch/step=37/7100 | loss=1.60895 | ploss=1.10529 | vloss=0.51003 | entropy=-6.45974 | reward=0.17344\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_37.ckpt\n",
      "[INFO]  epoch/step=38/7200 | loss=1.76002 | ploss=1.21139 | vloss=0.55506 | entropy=-6.51738 | reward=0.18812\n",
      "[INFO]  epoch/step=38/7300 | loss=1.68253 | ploss=1.15773 | vloss=0.53116 | entropy=-6.46047 | reward=0.18063\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_38.ckpt\n",
      "[INFO]  epoch/step=39/7400 | loss=1.63848 | ploss=1.12192 | vloss=0.52289 | entropy=-6.41680 | reward=0.17719\n",
      "[INFO]  epoch/step=39/7500 | loss=1.71209 | ploss=1.17627 | vloss=0.54219 | entropy=-6.46327 | reward=0.18438\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_39.ckpt\n",
      "[INFO]  epoch/step=40/7600 | loss=1.72715 | ploss=1.18669 | vloss=0.54679 | entropy=-6.41453 | reward=0.18531\n",
      "[INFO]  epoch/step=40/7700 | loss=1.79188 | ploss=1.22841 | vloss=0.56976 | entropy=-6.37920 | reward=0.19375\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_40.ckpt\n",
      "[INFO]  epoch/step=41/7800 | loss=1.74458 | ploss=1.19486 | vloss=0.55598 | entropy=-6.33771 | reward=0.18844\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_41.ckpt\n",
      "[INFO]  epoch/step=42/7900 | loss=1.81660 | ploss=1.24853 | vloss=0.57435 | entropy=-6.37065 | reward=0.19375\n",
      "[INFO]  epoch/step=42/8000 | loss=1.70483 | ploss=1.16981 | vloss=0.54127 | entropy=-6.33707 | reward=0.18406\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_42.ckpt\n",
      "[INFO]  epoch/step=43/8100 | loss=1.71929 | ploss=1.18057 | vloss=0.54495 | entropy=-6.32199 | reward=0.18438\n",
      "[INFO]  epoch/step=43/8200 | loss=1.67844 | ploss=1.14985 | vloss=0.53484 | entropy=-6.33020 | reward=0.18188\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_43.ckpt\n",
      "[INFO]  epoch/step=44/8300 | loss=1.74102 | ploss=1.18853 | vloss=0.55873 | entropy=-6.32519 | reward=0.18875\n",
      "[INFO]  epoch/step=44/8400 | loss=1.72784 | ploss=1.17531 | vloss=0.55873 | entropy=-6.28823 | reward=0.19000\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_44.ckpt\n",
      "[INFO]  epoch/step=45/8500 | loss=1.76240 | ploss=1.21172 | vloss=0.55689 | entropy=-6.29829 | reward=0.18844\n",
      "[INFO]  epoch/step=45/8600 | loss=1.77955 | ploss=1.21970 | vloss=0.56608 | entropy=-6.31415 | reward=0.19250\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_45.ckpt\n",
      "[INFO]  epoch/step=46/8700 | loss=1.79494 | ploss=1.22404 | vloss=0.57711 | entropy=-6.30075 | reward=0.19625\n",
      "[INFO]  epoch/step=46/8800 | loss=1.67041 | ploss=1.13990 | vloss=0.53668 | entropy=-6.25832 | reward=0.18250\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_46.ckpt\n",
      "[INFO]  epoch/step=47/8900 | loss=1.78821 | ploss=1.21449 | vloss=0.57987 | entropy=-6.23918 | reward=0.19562\n",
      "[INFO]  epoch/step=47/9000 | loss=1.75251 | ploss=1.19352 | vloss=0.56517 | entropy=-6.25987 | reward=0.19219\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_47.ckpt\n",
      "[INFO]  epoch/step=48/9100 | loss=1.69947 | ploss=1.15697 | vloss=0.54862 | entropy=-6.20253 | reward=0.18531\n",
      "[INFO]  epoch/step=48/9200 | loss=1.74930 | ploss=1.18933 | vloss=0.56608 | entropy=-6.19747 | reward=0.19250\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_48.ckpt\n",
      "[INFO]  epoch/step=49/9300 | loss=1.79256 | ploss=1.21790 | vloss=0.58079 | entropy=-6.21182 | reward=0.19656\n",
      "[INFO]  epoch/step=49/9400 | loss=1.77987 | ploss=1.21898 | vloss=0.56700 | entropy=-6.19416 | reward=0.19187\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_49.ckpt\n",
      "[INFO]  epoch/step=50/9500 | loss=1.70643 | ploss=1.15561 | vloss=0.55689 | entropy=-6.15778 | reward=0.18937\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_50.ckpt\n",
      "[INFO]  epoch/step=51/9600 | loss=1.76104 | ploss=1.19367 | vloss=0.57344 | entropy=-6.14753 | reward=0.19500\n",
      "[INFO]  epoch/step=51/9700 | loss=1.78536 | ploss=1.21525 | vloss=0.57619 | entropy=-6.15396 | reward=0.19594\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_51.ckpt\n",
      "[INFO]  epoch/step=52/9800 | loss=1.89834 | ploss=1.28686 | vloss=0.61755 | entropy=-6.14576 | reward=0.20906\n",
      "[INFO]  epoch/step=52/9900 | loss=1.77553 | ploss=1.20172 | vloss=0.57987 | entropy=-6.13295 | reward=0.19719\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_52.ckpt\n",
      "[INFO]  epoch/step=53/10000 | loss=1.78665 | ploss=1.21281 | vloss=0.57987 | entropy=-6.11348 | reward=0.19625\n",
      "[INFO]  epoch/step=53/10100 | loss=1.81412 | ploss=1.23848 | vloss=0.58171 | entropy=-6.15341 | reward=0.19781\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_53.ckpt\n",
      "[INFO]  epoch/step=54/10200 | loss=1.72764 | ploss=1.16852 | vloss=0.56517 | entropy=-6.11727 | reward=0.19187\n",
      "[INFO]  epoch/step=54/10300 | loss=1.82918 | ploss=1.24244 | vloss=0.59273 | entropy=-6.07262 | reward=0.20156\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_54.ckpt\n",
      "[INFO]  epoch/step=55/10400 | loss=1.76061 | ploss=1.19314 | vloss=0.57344 | entropy=-6.05106 | reward=0.19375\n",
      "[INFO]  epoch/step=55/10500 | loss=1.77047 | ploss=1.19566 | vloss=0.58079 | entropy=-6.05654 | reward=0.19750\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_55.ckpt\n",
      "[INFO]  epoch/step=56/10600 | loss=1.85343 | ploss=1.25107 | vloss=0.60836 | entropy=-6.07405 | reward=0.20594\n",
      "[INFO]  epoch/step=56/10700 | loss=1.78378 | ploss=1.20435 | vloss=0.58538 | entropy=-6.03743 | reward=0.19906\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_56.ckpt\n",
      "[INFO]  epoch/step=57/10800 | loss=1.78188 | ploss=1.20426 | vloss=0.58354 | entropy=-5.99437 | reward=0.19750\n",
      "[INFO]  epoch/step=57/10900 | loss=1.73593 | ploss=1.17769 | vloss=0.56425 | entropy=-6.07446 | reward=0.19187\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_57.ckpt\n",
      "[INFO]  epoch/step=58/11000 | loss=1.81104 | ploss=1.22518 | vloss=0.59182 | entropy=-6.03142 | reward=0.20000\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_58.ckpt\n",
      "[INFO]  epoch/step=59/11100 | loss=1.73880 | ploss=1.17680 | vloss=0.56792 | entropy=-5.99874 | reward=0.19250\n",
      "[INFO]  epoch/step=59/11200 | loss=1.74981 | ploss=1.17678 | vloss=0.57895 | entropy=-6.00144 | reward=0.19687\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_59.ckpt\n",
      "[INFO]  epoch/step=60/11300 | loss=1.92231 | ploss=1.29694 | vloss=0.63133 | entropy=-6.03328 | reward=0.21438\n",
      "[INFO]  epoch/step=60/11400 | loss=1.72648 | ploss=1.16353 | vloss=0.56884 | entropy=-5.96665 | reward=0.19344\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_60.ckpt\n",
      "[INFO]  epoch/step=61/11500 | loss=1.84396 | ploss=1.24426 | vloss=0.60560 | entropy=-5.97355 | reward=0.20531\n",
      "[INFO]  epoch/step=61/11600 | loss=1.81669 | ploss=1.22436 | vloss=0.59825 | entropy=-5.98491 | reward=0.20344\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_61.ckpt\n",
      "[INFO]  epoch/step=62/11700 | loss=1.80110 | ploss=1.21424 | vloss=0.59273 | entropy=-5.95047 | reward=0.20062\n",
      "[INFO]  epoch/step=62/11800 | loss=1.81755 | ploss=1.22889 | vloss=0.59457 | entropy=-5.98559 | reward=0.20219\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_62.ckpt\n",
      "[INFO]  epoch/step=63/11900 | loss=1.86706 | ploss=1.25909 | vloss=0.61387 | entropy=-5.96768 | reward=0.20844\n",
      "[INFO]  epoch/step=63/12000 | loss=1.68524 | ploss=1.13699 | vloss=0.55414 | entropy=-5.97051 | reward=0.18844\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_63.ckpt\n",
      "[INFO]  epoch/step=64/12100 | loss=1.86605 | ploss=1.25711 | vloss=0.61479 | entropy=-5.92393 | reward=0.20844\n",
      "[INFO]  epoch/step=64/12200 | loss=1.80154 | ploss=1.20911 | vloss=0.59825 | entropy=-5.89820 | reward=0.20344\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_64.ckpt\n",
      "[INFO]  epoch/step=65/12300 | loss=1.86000 | ploss=1.24830 | vloss=0.61755 | entropy=-5.92224 | reward=0.20844\n",
      "[INFO]  epoch/step=65/12400 | loss=1.79416 | ploss=1.20542 | vloss=0.59457 | entropy=-5.90497 | reward=0.20219\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_65.ckpt\n",
      "[INFO]  epoch/step=66/12500 | loss=1.74142 | ploss=1.17383 | vloss=0.57344 | entropy=-5.91601 | reward=0.19469\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_66.ckpt\n",
      "[INFO]  epoch/step=67/12600 | loss=1.89860 | ploss=1.27401 | vloss=0.63041 | entropy=-5.88962 | reward=0.21344\n",
      "[INFO]  epoch/step=67/12700 | loss=1.78183 | ploss=1.19309 | vloss=0.59457 | entropy=-5.90574 | reward=0.20219\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_67.ckpt\n",
      "[INFO]  epoch/step=68/12800 | loss=1.79142 | ploss=1.20358 | vloss=0.59365 | entropy=-5.88651 | reward=0.20062\n",
      "[INFO]  epoch/step=68/12900 | loss=1.81530 | ploss=1.20908 | vloss=0.61203 | entropy=-5.88765 | reward=0.20813\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_68.ckpt\n",
      "[INFO]  epoch/step=69/13000 | loss=1.79795 | ploss=1.20824 | vloss=0.59549 | entropy=-5.85389 | reward=0.20125\n",
      "[INFO]  epoch/step=69/13100 | loss=1.89281 | ploss=1.26820 | vloss=0.63041 | entropy=-5.87215 | reward=0.21438\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_69.ckpt\n",
      "[INFO]  epoch/step=70/13200 | loss=1.71924 | ploss=1.15066 | vloss=0.57435 | entropy=-5.84376 | reward=0.19500\n",
      "[INFO]  epoch/step=70/13300 | loss=1.92518 | ploss=1.28767 | vloss=0.64328 | entropy=-5.83619 | reward=0.21875\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_70.ckpt\n",
      "[INFO]  epoch/step=71/13400 | loss=1.72902 | ploss=1.15951 | vloss=0.57527 | entropy=-5.83677 | reward=0.19469\n",
      "[INFO]  epoch/step=71/13500 | loss=1.84010 | ploss=1.23108 | vloss=0.61479 | entropy=-5.84066 | reward=0.20906\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_71.ckpt\n",
      "[INFO]  epoch/step=72/13600 | loss=1.78576 | ploss=1.18778 | vloss=0.60376 | entropy=-5.85253 | reward=0.20438\n",
      "[INFO]  epoch/step=72/13700 | loss=1.79096 | ploss=1.19383 | vloss=0.60284 | entropy=-5.78976 | reward=0.20500\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_72.ckpt\n",
      "[INFO]  epoch/step=73/13800 | loss=1.81592 | ploss=1.21697 | vloss=0.60468 | entropy=-5.80312 | reward=0.20344\n",
      "[INFO]  epoch/step=73/13900 | loss=1.88183 | ploss=1.25529 | vloss=0.63225 | entropy=-5.78321 | reward=0.21500\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_73.ckpt\n",
      "[INFO]  epoch/step=74/14000 | loss=1.76517 | ploss=1.17260 | vloss=0.59825 | entropy=-5.74578 | reward=0.20219\n",
      "[INFO]  epoch/step=74/14100 | loss=1.91813 | ploss=1.28517 | vloss=0.63868 | entropy=-5.79436 | reward=0.21656\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_74.ckpt\n",
      "[INFO]  epoch/step=75/14200 | loss=1.75330 | ploss=1.16628 | vloss=0.59273 | entropy=-5.79187 | reward=0.20156\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_75.ckpt\n",
      "[INFO]  epoch/step=76/14300 | loss=1.80107 | ploss=1.19840 | vloss=0.60836 | entropy=-5.77029 | reward=0.20563\n",
      "[INFO]  epoch/step=76/14400 | loss=1.93352 | ploss=1.29591 | vloss=0.64328 | entropy=-5.74518 | reward=0.21875\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_76.ckpt\n",
      "[INFO]  epoch/step=77/14500 | loss=1.76667 | ploss=1.17500 | vloss=0.59733 | entropy=-5.73614 | reward=0.20250\n",
      "[INFO]  epoch/step=77/14600 | loss=1.76498 | ploss=1.17420 | vloss=0.59641 | entropy=-5.70216 | reward=0.20281\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_77.ckpt\n",
      "[INFO]  epoch/step=78/14700 | loss=1.86506 | ploss=1.24406 | vloss=0.62674 | entropy=-5.81811 | reward=0.21188\n",
      "[INFO]  epoch/step=78/14800 | loss=1.80886 | ploss=1.20706 | vloss=0.60744 | entropy=-5.71414 | reward=0.20656\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_78.ckpt\n",
      "[INFO]  epoch/step=79/14900 | loss=1.79068 | ploss=1.18982 | vloss=0.60652 | entropy=-5.73234 | reward=0.20563\n",
      "[INFO]  epoch/step=79/15000 | loss=1.84206 | ploss=1.21178 | vloss=0.63593 | entropy=-5.71554 | reward=0.21625\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_79.ckpt\n",
      "[INFO]  epoch/step=80/15100 | loss=1.81399 | ploss=1.20298 | vloss=0.61663 | entropy=-5.68987 | reward=0.20906\n",
      "[INFO]  epoch/step=80/15200 | loss=1.82324 | ploss=1.20762 | vloss=0.62122 | entropy=-5.67134 | reward=0.21125\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_80.ckpt\n",
      "[INFO]  epoch/step=81/15300 | loss=1.81818 | ploss=1.20811 | vloss=0.61571 | entropy=-5.71054 | reward=0.20813\n",
      "[INFO]  epoch/step=81/15400 | loss=1.74698 | ploss=1.15431 | vloss=0.59825 | entropy=-5.64726 | reward=0.20344\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_81.ckpt\n",
      "[INFO]  epoch/step=82/15500 | loss=1.75864 | ploss=1.16509 | vloss=0.59917 | entropy=-5.69062 | reward=0.20281\n",
      "[INFO]  epoch/step=82/15600 | loss=1.82771 | ploss=1.20473 | vloss=0.62857 | entropy=-5.66994 | reward=0.21375\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_82.ckpt\n",
      "[INFO]  epoch/step=83/15700 | loss=1.74090 | ploss=1.15558 | vloss=0.59090 | entropy=-5.65418 | reward=0.19969\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_83.ckpt\n",
      "[INFO]  epoch/step=84/15800 | loss=1.78843 | ploss=1.18288 | vloss=0.61111 | entropy=-5.63227 | reward=0.20656\n",
      "[INFO]  epoch/step=84/15900 | loss=1.77650 | ploss=1.17644 | vloss=0.60560 | entropy=-5.61486 | reward=0.20594\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_84.ckpt\n",
      "[INFO]  epoch/step=85/16000 | loss=1.76781 | ploss=1.16959 | vloss=0.60376 | entropy=-5.61534 | reward=0.20406\n",
      "[INFO]  epoch/step=85/16100 | loss=1.78952 | ploss=1.18305 | vloss=0.61203 | entropy=-5.64610 | reward=0.20813\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_85.ckpt\n",
      "[INFO]  epoch/step=86/16200 | loss=1.94687 | ploss=1.28247 | vloss=0.66993 | entropy=-5.61176 | reward=0.22719\n",
      "[INFO]  epoch/step=86/16300 | loss=1.83681 | ploss=1.21653 | vloss=0.62582 | entropy=-5.60827 | reward=0.21281\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_86.ckpt\n",
      "[INFO]  epoch/step=87/16400 | loss=1.81523 | ploss=1.20324 | vloss=0.61755 | entropy=-5.62893 | reward=0.20875\n",
      "[INFO]  epoch/step=87/16500 | loss=1.78036 | ploss=1.18674 | vloss=0.59917 | entropy=-5.62237 | reward=0.20375\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_87.ckpt\n",
      "[INFO]  epoch/step=88/16600 | loss=1.68163 | ploss=1.10726 | vloss=0.57987 | entropy=-5.57808 | reward=0.19625\n",
      "[INFO]  epoch/step=88/16700 | loss=1.76441 | ploss=1.16433 | vloss=0.60560 | entropy=-5.59139 | reward=0.20594\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_88.ckpt\n",
      "[INFO]  epoch/step=89/16800 | loss=1.75782 | ploss=1.15961 | vloss=0.60376 | entropy=-5.62751 | reward=0.20406\n",
      "[INFO]  epoch/step=89/16900 | loss=1.74752 | ploss=1.14923 | vloss=0.60376 | entropy=-5.55689 | reward=0.20531\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_89.ckpt\n",
      "[INFO]  epoch/step=90/17000 | loss=1.88919 | ploss=1.24405 | vloss=0.65063 | entropy=-5.56709 | reward=0.22094\n",
      "[INFO]  epoch/step=90/17100 | loss=1.86875 | ploss=1.23645 | vloss=0.63776 | entropy=-5.54350 | reward=0.21688\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_90.ckpt\n",
      "[INFO]  epoch/step=91/17200 | loss=1.93151 | ploss=1.27164 | vloss=0.66533 | entropy=-5.53999 | reward=0.22531\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_91.ckpt\n",
      "[INFO]  epoch/step=92/17300 | loss=1.87778 | ploss=1.23999 | vloss=0.64328 | entropy=-5.56213 | reward=0.21750\n",
      "[INFO]  epoch/step=92/17400 | loss=1.92368 | ploss=1.26750 | vloss=0.66166 | entropy=-5.54861 | reward=0.22500\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_92.ckpt\n",
      "[INFO]  epoch/step=93/17500 | loss=1.78634 | ploss=1.17978 | vloss=0.61203 | entropy=-5.55367 | reward=0.20719\n",
      "[INFO]  epoch/step=93/17600 | loss=1.80016 | ploss=1.18441 | vloss=0.62122 | entropy=-5.54544 | reward=0.21125\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_93.ckpt\n",
      "[INFO]  epoch/step=94/17700 | loss=1.89415 | ploss=1.25174 | vloss=0.64787 | entropy=-5.53650 | reward=0.21937\n",
      "[INFO]  epoch/step=94/17800 | loss=1.81279 | ploss=1.19521 | vloss=0.62306 | entropy=-5.56044 | reward=0.21188\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_94.ckpt\n",
      "[INFO]  epoch/step=95/17900 | loss=1.77161 | ploss=1.16407 | vloss=0.61295 | entropy=-5.48500 | reward=0.20719\n",
      "[INFO]  epoch/step=95/18000 | loss=1.88998 | ploss=1.24296 | vloss=0.65247 | entropy=-5.53220 | reward=0.22187\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_95.ckpt\n",
      "[INFO]  epoch/step=96/18100 | loss=1.89157 | ploss=1.24544 | vloss=0.65155 | entropy=-5.49568 | reward=0.22062\n",
      "[INFO]  epoch/step=96/18200 | loss=1.75369 | ploss=1.14799 | vloss=0.61111 | entropy=-5.48883 | reward=0.20781\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_96.ckpt\n",
      "[INFO]  epoch/step=97/18300 | loss=1.71142 | ploss=1.12320 | vloss=0.59365 | entropy=-5.51824 | reward=0.20094\n",
      "[INFO]  epoch/step=97/18400 | loss=1.91139 | ploss=1.25514 | vloss=0.66166 | entropy=-5.48891 | reward=0.22500\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_97.ckpt\n",
      "[INFO]  epoch/step=98/18500 | loss=1.78182 | ploss=1.17609 | vloss=0.61111 | entropy=-5.45950 | reward=0.20656\n",
      "[INFO]  epoch/step=98/18600 | loss=1.89425 | ploss=1.24258 | vloss=0.65706 | entropy=-5.47711 | reward=0.22344\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_98.ckpt\n",
      "[INFO]  epoch/step=99/18700 | loss=1.80765 | ploss=1.19365 | vloss=0.61938 | entropy=-5.46250 | reward=0.20969\n",
      "[INFO]  epoch/step=99/18800 | loss=1.72652 | ploss=1.13825 | vloss=0.59365 | entropy=-5.46371 | reward=0.20062\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_99.ckpt\n",
      "[INFO]  epoch/step=100/18900 | loss=1.81012 | ploss=1.18786 | vloss=0.62765 | entropy=-5.47845 | reward=0.21344\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_100.ckpt\n",
      "[INFO]  epoch/step=101/19000 | loss=1.83229 | ploss=1.19713 | vloss=0.64052 | entropy=-5.43981 | reward=0.21750\n",
      "[INFO]  epoch/step=101/19100 | loss=1.79222 | ploss=1.17361 | vloss=0.62398 | entropy=-5.44671 | reward=0.21219\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_101.ckpt\n",
      "[INFO]  epoch/step=102/19200 | loss=1.80922 | ploss=1.18876 | vloss=0.62582 | entropy=-5.43735 | reward=0.21250\n",
      "[INFO]  epoch/step=102/19300 | loss=1.79725 | ploss=1.18322 | vloss=0.61938 | entropy=-5.43911 | reward=0.21063\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_102.ckpt\n",
      "[INFO]  epoch/step=103/19400 | loss=1.82252 | ploss=1.19287 | vloss=0.63501 | entropy=-5.44444 | reward=0.21469\n",
      "[INFO]  epoch/step=103/19500 | loss=1.70139 | ploss=1.11123 | vloss=0.59549 | entropy=-5.41695 | reward=0.20250\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_103.ckpt\n",
      "[INFO]  epoch/step=104/19600 | loss=1.84145 | ploss=1.20258 | vloss=0.64420 | entropy=-5.40526 | reward=0.21656\n",
      "[INFO]  epoch/step=104/19700 | loss=1.90571 | ploss=1.24572 | vloss=0.66533 | entropy=-5.42797 | reward=0.22625\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_104.ckpt\n",
      "[INFO]  epoch/step=105/19800 | loss=1.84050 | ploss=1.20713 | vloss=0.63868 | entropy=-5.38914 | reward=0.21563\n",
      "[INFO]  epoch/step=105/19900 | loss=1.80643 | ploss=1.18596 | vloss=0.62582 | entropy=-5.42047 | reward=0.21281\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_105.ckpt\n",
      "[INFO]  epoch/step=106/20000 | loss=1.83769 | ploss=1.21078 | vloss=0.63225 | entropy=-5.41525 | reward=0.21375\n",
      "[INFO]  epoch/step=106/20100 | loss=1.74810 | ploss=1.14600 | vloss=0.60744 | entropy=-5.41948 | reward=0.20656\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_106.ckpt\n",
      "[INFO]  epoch/step=107/20200 | loss=1.86029 | ploss=1.21315 | vloss=0.65247 | entropy=-5.41022 | reward=0.22125\n",
      "[INFO]  epoch/step=107/20300 | loss=1.68449 | ploss=1.09706 | vloss=0.59273 | entropy=-5.38968 | reward=0.20156\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_107.ckpt\n",
      "[INFO]  epoch/step=108/20400 | loss=1.84943 | ploss=1.20963 | vloss=0.64512 | entropy=-5.40489 | reward=0.21813\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_108.ckpt\n",
      "[INFO]  epoch/step=109/20500 | loss=1.77054 | ploss=1.15923 | vloss=0.61663 | entropy=-5.39629 | reward=0.20906\n",
      "[INFO]  epoch/step=109/20600 | loss=1.80548 | ploss=1.17760 | vloss=0.63317 | entropy=-5.37296 | reward=0.21531\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_109.ckpt\n",
      "[INFO]  epoch/step=110/20700 | loss=1.91945 | ploss=1.25665 | vloss=0.66809 | entropy=-5.36671 | reward=0.22625\n",
      "[INFO]  epoch/step=110/20800 | loss=1.85725 | ploss=1.21926 | vloss=0.64328 | entropy=-5.36800 | reward=0.21875\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_110.ckpt\n",
      "[INFO]  epoch/step=111/20900 | loss=1.94980 | ploss=1.27597 | vloss=0.67912 | entropy=-5.37249 | reward=0.23000\n",
      "[INFO]  epoch/step=111/21000 | loss=1.82775 | ploss=1.18973 | vloss=0.64328 | entropy=-5.34603 | reward=0.21875\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_111.ckpt\n",
      "[INFO]  epoch/step=112/21100 | loss=1.76298 | ploss=1.15345 | vloss=0.61479 | entropy=-5.34876 | reward=0.20750\n",
      "[INFO]  epoch/step=112/21200 | loss=1.81733 | ploss=1.19400 | vloss=0.62857 | entropy=-5.32720 | reward=0.21375\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_112.ckpt\n",
      "[INFO]  epoch/step=113/21300 | loss=1.75122 | ploss=1.15272 | vloss=0.60376 | entropy=-5.34338 | reward=0.20469\n",
      "[INFO]  epoch/step=113/21400 | loss=1.90660 | ploss=1.24468 | vloss=0.66717 | entropy=-5.33781 | reward=0.22687\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_113.ckpt\n",
      "[INFO]  epoch/step=114/21500 | loss=1.82803 | ploss=1.18815 | vloss=0.64512 | entropy=-5.31663 | reward=0.21750\n",
      "[INFO]  epoch/step=114/21600 | loss=1.94866 | ploss=1.27112 | vloss=0.68279 | entropy=-5.33368 | reward=0.23219\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_114.ckpt\n",
      "[INFO]  epoch/step=115/21700 | loss=1.81860 | ploss=1.18518 | vloss=0.63868 | entropy=-5.35543 | reward=0.21531\n",
      "[INFO]  epoch/step=115/21800 | loss=1.90147 | ploss=1.23492 | vloss=0.67177 | entropy=-5.29817 | reward=0.22844\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_115.ckpt\n",
      "[INFO]  epoch/step=116/21900 | loss=1.82623 | ploss=1.19007 | vloss=0.64144 | entropy=-5.35611 | reward=0.21781\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_116.ckpt\n",
      "[INFO]  epoch/step=117/22000 | loss=1.70815 | ploss=1.10869 | vloss=0.60468 | entropy=-5.30031 | reward=0.20406\n",
      "[INFO]  epoch/step=117/22100 | loss=1.81123 | ploss=1.18699 | vloss=0.62949 | entropy=-5.33098 | reward=0.21406\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_117.ckpt\n",
      "[INFO]  epoch/step=118/22200 | loss=1.79851 | ploss=1.16870 | vloss=0.63501 | entropy=-5.28399 | reward=0.21438\n",
      "[INFO]  epoch/step=118/22300 | loss=1.77920 | ploss=1.15305 | vloss=0.63133 | entropy=-5.25948 | reward=0.21469\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_118.ckpt\n",
      "[INFO]  epoch/step=119/22400 | loss=1.80336 | ploss=1.17451 | vloss=0.63409 | entropy=-5.31714 | reward=0.21406\n",
      "[INFO]  epoch/step=119/22500 | loss=1.87832 | ploss=1.22464 | vloss=0.65890 | entropy=-5.30529 | reward=0.22406\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_119.ckpt\n",
      "[INFO]  epoch/step=120/22600 | loss=1.88040 | ploss=1.22762 | vloss=0.65798 | entropy=-5.28630 | reward=0.22281\n",
      "[INFO]  epoch/step=120/22700 | loss=1.82308 | ploss=1.18409 | vloss=0.64420 | entropy=-5.28635 | reward=0.21906\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_120.ckpt\n",
      "[INFO]  epoch/step=121/22800 | loss=1.80347 | ploss=1.16996 | vloss=0.63868 | entropy=-5.25042 | reward=0.21563\n",
      "[INFO]  epoch/step=121/22900 | loss=1.87085 | ploss=1.21162 | vloss=0.66441 | entropy=-5.27528 | reward=0.22594\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_121.ckpt\n",
      "[INFO]  epoch/step=122/23000 | loss=1.90570 | ploss=1.24464 | vloss=0.66625 | entropy=-5.27712 | reward=0.22500\n",
      "[INFO]  epoch/step=122/23100 | loss=1.87362 | ploss=1.21069 | vloss=0.66809 | entropy=-5.24824 | reward=0.22719\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_122.ckpt\n",
      "[INFO]  epoch/step=123/23200 | loss=1.72735 | ploss=1.11680 | vloss=0.61571 | entropy=-5.24379 | reward=0.20750\n",
      "[INFO]  epoch/step=123/23300 | loss=1.93874 | ploss=1.26016 | vloss=0.68371 | entropy=-5.22348 | reward=0.23250\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_123.ckpt\n",
      "[INFO]  epoch/step=124/23400 | loss=1.83306 | ploss=1.18945 | vloss=0.64879 | entropy=-5.27122 | reward=0.21906\n",
      "[INFO]  epoch/step=124/23500 | loss=1.81969 | ploss=1.18247 | vloss=0.64236 | entropy=-5.22466 | reward=0.21781\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_124.ckpt\n",
      "[INFO]  epoch/step=125/23600 | loss=1.75944 | ploss=1.14615 | vloss=0.61847 | entropy=-5.25913 | reward=0.21031\n",
      "[INFO]  Save model to ../save_model/MovieLens-1M_Core/lstm/note_ld2.0_rn4_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_125.ckpt\n",
      "[INFO]  epoch/step=126/23700 | loss=1.98437 | ploss=1.27730 | vloss=0.71220 | entropy=-5.22382 | reward=0.24063\n"
     ]
    }
   ],
   "source": [
    "command = f\"python3 ../src/{train_file} --reasoning_step {reasoning_step} \\\n",
    "                                         --batch_size {batch_size} \\\n",
    "                                         --name {exp_name} \\\n",
    "                                         --lr {lr} \\\n",
    "                                         --embed_size {embed_size} \\\n",
    "                                         --n_memory {n_memory} \\\n",
    "                                         --load_pretrain_model {load_pretrain_model}  \\\n",
    "                                         --gp_setting {gp_setting} \\\n",
    "                                         --epochs {epochs} \\\n",
    "                                         --KGE_pretrained {KGE_pretrained} \\\n",
    "                                         --lambda_num {lambda_num}  \\\n",
    "                                         --kg_emb_grad {kg_emb_grad} \\\n",
    "                                         --p_hop {p_hop}  \\\n",
    "                                         --reasoning_step {reasoning_step}  \\\n",
    "                                         --model lstm \\\n",
    "                                         --dataset {DATASET}\"\n",
    "print(\"Running Command:\")\n",
    "print(' '.join(command.split()))\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f\"python3 ../src/{test_file} --name {exp_name} \\\n",
    "                                        --batch_size {batch_size} \\\n",
    "                                        --gp_setting {gp_setting} \\\n",
    "                                        --model lstm \\\n",
    "                                        --dataset {DATASET} \\\n",
    "                                        --lambda_num {lambda_num} \\\n",
    "                                        --kg_emb_grad {kg_emb_grad} \\\n",
    "                                        --lr {lr} \\\n",
    "                                        --p_hop {p_hop} \\\n",
    "                                        --reasoning_step {reasoning_step} \\\n",
    "                                        --embed_size {embed_size} \\\n",
    "                                        --n_memory {n_memory}\"\n",
    "\n",
    "print(' '.join(command.split()))\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-grammar",
   "metadata": {},
   "source": [
    "# train UCPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pretrain_model=1\n",
    "\n",
    "command = f\"python3 ../src/{train_file} --reasoning_step {reasoning_step} \\\n",
    "                                    --batch_size {batch_size} \\\n",
    "                                    --name {exp_name} \\\n",
    "                                    --lr {lr} \\\n",
    "                                    --embed_size {embed_size} \\\n",
    "                                    --n_memory {n_memory} \\\n",
    "                                    --load_pretrain_model {load_pretrain_model} \\\n",
    "                                    --gp_setting {gp_setting} \\\n",
    "                                    --epochs {epochs} \\\n",
    "                                    --lambda_num {lambda_num} \\\n",
    "                                    --kg_emb_grad {kg_emb_grad}  \\\n",
    "                                    --p_hop {p_hop} \\\n",
    "                                    --reasoning_step {reasoning_step} \\\n",
    "                                    --model {model} \\\n",
    "                                    --dataset {DATASET}\"\n",
    "print(' '.join(command.split()))\n",
    "!{command}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f\"python3 ../src/${test_file} --name{exp_name} \\\n",
    "                                --batch_size{batch_size}\\\n",
    "                                --gp_setting{gp_setting}  \\\n",
    "                                --model{model} \\\n",
    "                                --dataset{DATASET} \\\n",
    "                                --lambda_num{lambda_num}   \\\n",
    "                                --kg_emb_grad{kg_emb_grad} \\\n",
    "                                --lr{lr} \\\n",
    "                                --p_hop{p_hop}  \\\n",
    "                                --reasoning_step{reasoning_step} \\\n",
    "                                --embed_size{embed_size} \\\n",
    "                                --n_memory{n_memory}\"\n",
    "\n",
    "\n",
    "print(' '.join(command.split()))\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-telescope",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
