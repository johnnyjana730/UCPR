{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "coordinated-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running UCPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-perth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/johnnyjana730/github/UCPR/', '/home/johnnyjana730/github/UCPR/bash', '/home/johnnyjana730/anaconda3_tmp/lib/python38.zip', '/home/johnnyjana730/anaconda3_tmp/lib/python3.8', '/home/johnnyjana730/anaconda3_tmp/lib/python3.8/lib-dynload', '', '/home/johnnyjana730/anaconda3_tmp/lib/python3.8/site-packages', '/home/johnnyjana730/anaconda3_tmp/lib/python3.8/site-packages/locket-0.2.1-py3.8.egg', '/home/johnnyjana730/anaconda3_tmp/lib/python3.8/site-packages/IPython/extensions', '/home/johnnyjana730/.ipython']\n",
      "dataset =  amazon-book_20core\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'/home/johnnyjana730/github/UCPR/')\n",
    "print(sys.path)\n",
    "\n",
    "from config import get_hparams\n",
    "\n",
    "!export PYTHONPATH=\"./\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from config import get_hparams\n",
    "\n",
    "# cell_core, beauty_core, cloth_core, MovieLens-1M_core, amazon-book_20core\n",
    "\n",
    "DATASET = \"amazon-book_20core\"\n",
    "\n",
    "locals().update(get_hparams(DATASET))\n",
    "\n",
    "epochs=400\n",
    "KGE_pretrained=1\n",
    "kg_emb_grad=1\n",
    "load_pretrain_model=0\n",
    "batch_size=32\n",
    "train_file=\"train.py\"\n",
    "test_file=\"test.py\"\n",
    "\n",
    "exp_name= f\"note_ld{lambda_num}_rn{reasoning_step}_h1{p_hop}_nmem{n_memory}_em{embed_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "digital-visit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Command:\n",
      "python3 ../src/train.py --reasoning_step 3 --batch_size 32 --name note_ld0.2_rn3_h12_nmem64_em32 --lr 0.0001 --embed_size 32 --n_memory 64 --load_pretrain_model 0 --gp_setting 6000_800_15_500_50 --epochs 400 --KGE_pretrained 1 --lambda_num 0.2 --kg_emb_grad 1 --p_hop 2 --reasoning_step 3 --model lstm --dataset amazon-book_20core\n",
      "args.gp_setting =  6000_800_15_500_50 args.att_core =  0 args.item_core =  0 args.user_core =  6000 args.kg_fre_upper =  500 args.max_acts =  50\n",
      "len(self.core_user_list) =  6000\n",
      "self.args.core_user_list =  6000\n",
      "self.user_triplet_list =  6000\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "env.output_valid_user() =  6000\n",
      "args.batch_size =  32\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "et =  user 70585\n",
      "et =  product 95500\n",
      "et =  attribute 184072\n",
      "key =  user\n",
      "self.embeds[key] =  torch.Size([70586, 32])\n",
      "vocab_size + 1 =  70586\n",
      "embed =  torch.Size([70586, 32])\n",
      "embed.requires_grad =  True\n",
      "key =  product\n",
      "self.embeds[key] =  torch.Size([95501, 32])\n",
      "vocab_size + 1 =  95501\n",
      "embed =  torch.Size([95501, 32])\n",
      "embed.requires_grad =  True\n",
      "key =  attribute\n",
      "self.embeds[key] =  torch.Size([184073, 32])\n",
      "vocab_size + 1 =  184073\n",
      "embed =  torch.Size([184073, 32])\n",
      "embed.requires_grad =  True\n",
      "21 embed =  torch.Size([1, 32])\n",
      "10 embed =  torch.Size([1, 32])\n",
      "14 embed =  torch.Size([1, 32])\n",
      "4 embed =  torch.Size([1, 32])\n",
      "18 embed =  torch.Size([1, 32])\n",
      "31 embed =  torch.Size([1, 32])\n",
      "2 embed =  torch.Size([1, 32])\n",
      "3 embed =  torch.Size([1, 32])\n",
      "30 embed =  torch.Size([1, 32])\n",
      "34 embed =  torch.Size([1, 32])\n",
      "37 embed =  torch.Size([1, 32])\n",
      "1 embed =  torch.Size([1, 32])\n",
      "13 embed =  torch.Size([1, 32])\n",
      "23 embed =  torch.Size([1, 32])\n",
      "24 embed =  torch.Size([1, 32])\n",
      "32 embed =  torch.Size([1, 32])\n",
      "16 embed =  torch.Size([1, 32])\n",
      "7 embed =  torch.Size([1, 32])\n",
      "0 embed =  torch.Size([1, 32])\n",
      "33 embed =  torch.Size([1, 32])\n",
      "6 embed =  torch.Size([1, 32])\n",
      "17 embed =  torch.Size([1, 32])\n",
      "15 embed =  torch.Size([1, 32])\n",
      "29 embed =  torch.Size([1, 32])\n",
      "8 embed =  torch.Size([1, 32])\n",
      "28 embed =  torch.Size([1, 32])\n",
      "5 embed =  torch.Size([1, 32])\n",
      "25 embed =  torch.Size([1, 32])\n",
      "11 embed =  torch.Size([1, 32])\n",
      "self_loop embed =  torch.Size([1, 32])\n",
      "36 embed =  torch.Size([1, 32])\n",
      "9 embed =  torch.Size([1, 32])\n",
      "19 embed =  torch.Size([1, 32])\n",
      "20 embed =  torch.Size([1, 32])\n",
      "12 embed =  torch.Size([1, 32])\n",
      "22 embed =  torch.Size([1, 32])\n",
      "35 embed =  torch.Size([1, 32])\n",
      "padding embed =  torch.Size([1, 32])\n",
      "38 embed =  torch.Size([1, 32])\n",
      "purchase embed =  torch.Size([1, 32])\n",
      "27 embed =  torch.Size([1, 32])\n",
      "26 embed =  torch.Size([1, 32])\n",
      "[INFO]  Namespace(KGE_pretrained=True, act_dropout=0.5, add_products=False, att_core=0, att_evaluation=False, batch_size=32, best_model_epoch=0, best_save_model_dir='', core_user_list='', dataset='amazon-book_20core', device=device(type='cuda', index=0), embed_size=32, ent_weight=0.001, envir='p2', epochs=400, eva_epochs=0, gamma=0.99, gp_setting='6000_800_15_500_50', gpu='0', gradient_plot='gradient_plot/', h0_embbed=0, hidden=[64, 32], item_core=0, kg_emb_grad=True, kg_fre_dict='', kg_fre_lower=15, kg_fre_upper=500, kg_no_grad=False, l2_lambda=0, l2_weight=1e-06, lambda_num=0.2, load_pretrain_model=False, load_pt_emb_size=False, log_dir='../eva/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000', logger=<Logger ../eva/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/train_log.txt (DEBUG)>, lr=0.0001, max_acts=50, max_path_len=3, model='lstm', n_memory=64, name='note_ld0.2_rn3_h12_nmem64_em32', non_sampling=True, p_hop=2, pretest=False, pretrained_dir='../eva/amazon-book_20core/pretrained/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000', pretrained_st_epoch=0, reasoning_step=3, reward_hybrid=False, reward_rh='', run_eval=True, run_path=True, sam_type='alet', save_model_dir='../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000', seed=52, sort_by='prob', state_history=1, state_rg=False, sub_batch_size=1, test_lstm_up=True, topk=[8, 2, 6], topk_list=[1, 8, 16, 96], topk_string='8, 2, 6', training=True, tri_pro_rm=False, tri_wd_rm=False, user_core=6000)\n",
      "[INFO]  Parameters:['kg_emb.21', 'kg_emb.10', 'kg_emb.14', 'kg_emb.4', 'kg_emb.18', 'kg_emb.31', 'kg_emb.2', 'kg_emb.3', 'kg_emb.30', 'kg_emb.34', 'kg_emb.37', 'kg_emb.1', 'kg_emb.13', 'kg_emb.23', 'kg_emb.24', 'kg_emb.32', 'kg_emb.16', 'kg_emb.7', 'kg_emb.0', 'kg_emb.33', 'kg_emb.6', 'kg_emb.17', 'kg_emb.15', 'kg_emb.29', 'kg_emb.8', 'kg_emb.28', 'kg_emb.5', 'kg_emb.25', 'kg_emb.11', 'kg_emb.self_loop', 'kg_emb.36', 'kg_emb.9', 'kg_emb.19', 'kg_emb.20', 'kg_emb.12', 'kg_emb.22', 'kg_emb.35', 'kg_emb.padding', 'kg_emb.38', 'kg_emb.purchase', 'kg_emb.27', 'kg_emb.26', 'kg_emb.user.weight', 'kg_emb.product.weight', 'kg_emb.attribute.weight', 'kg_emb.21_bias.weight', 'kg_emb.10_bias.weight', 'kg_emb.14_bias.weight', 'kg_emb.4_bias.weight', 'kg_emb.18_bias.weight', 'kg_emb.31_bias.weight', 'kg_emb.2_bias.weight', 'kg_emb.3_bias.weight', 'kg_emb.30_bias.weight', 'kg_emb.34_bias.weight', 'kg_emb.37_bias.weight', 'kg_emb.1_bias.weight', 'kg_emb.13_bias.weight', 'kg_emb.23_bias.weight', 'kg_emb.24_bias.weight', 'kg_emb.32_bias.weight', 'kg_emb.16_bias.weight', 'kg_emb.7_bias.weight', 'kg_emb.0_bias.weight', 'kg_emb.33_bias.weight', 'kg_emb.6_bias.weight', 'kg_emb.17_bias.weight', 'kg_emb.15_bias.weight', 'kg_emb.29_bias.weight', 'kg_emb.8_bias.weight', 'kg_emb.28_bias.weight', 'kg_emb.5_bias.weight', 'kg_emb.25_bias.weight', 'kg_emb.11_bias.weight', 'kg_emb.self_loop_bias.weight', 'kg_emb.36_bias.weight', 'kg_emb.9_bias.weight', 'kg_emb.19_bias.weight', 'kg_emb.20_bias.weight', 'kg_emb.12_bias.weight', 'kg_emb.22_bias.weight', 'kg_emb.35_bias.weight', 'kg_emb.padding_bias.weight', 'kg_emb.38_bias.weight', 'kg_emb.purchase_bias.weight', 'kg_emb.27_bias.weight', 'kg_emb.26_bias.weight', 'state_lstm.policy_lstm.lstm.weight_ih_l0', 'state_lstm.policy_lstm.lstm.weight_hh_l0', 'state_lstm.policy_lstm.lstm.bias_ih_l0', 'state_lstm.policy_lstm.lstm.bias_hh_l0', 'transfor_state.weight', 'transfor_state.bias', 'state_tr_query.weight', 'state_tr_query.bias', 'l1.weight', 'l1.bias', 'l2.weight', 'l2.bias', 'actor.weight', 'actor.bias', 'critic.weight', 'critic.bias']\n",
      "[INFO]  epoch/step=0/100 | loss=0.28352 | ploss=0.21011 | vloss=0.08087 | entropy=-7.58464 | reward=0.02750\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_0.ckpt\n",
      "[INFO]  epoch/step=1/200 | loss=0.28538 | ploss=0.20916 | vloss=0.08363 | entropy=-7.52424 | reward=0.02844\n",
      "[INFO]  epoch/step=1/300 | loss=0.32628 | ploss=0.23809 | vloss=0.09557 | entropy=-7.50291 | reward=0.03250\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_1.ckpt\n",
      "[INFO]  epoch/step=2/400 | loss=0.33009 | ploss=0.24086 | vloss=0.09649 | entropy=-7.37057 | reward=0.03281\n",
      "[INFO]  epoch/step=2/500 | loss=0.37148 | ploss=0.26936 | vloss=0.10936 | entropy=-7.35069 | reward=0.03719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_2.ckpt\n",
      "[INFO]  epoch/step=3/600 | loss=0.31560 | ploss=0.22908 | vloss=0.09373 | entropy=-7.31892 | reward=0.03188\n",
      "[INFO]  epoch/step=3/700 | loss=0.31204 | ploss=0.22454 | vloss=0.09465 | entropy=-7.25358 | reward=0.03219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_3.ckpt\n",
      "[INFO]  epoch/step=4/800 | loss=0.38478 | ploss=0.27422 | vloss=0.11763 | entropy=-7.17452 | reward=0.04000\n",
      "[INFO]  epoch/step=4/900 | loss=0.42409 | ploss=0.29951 | vloss=0.13141 | entropy=-6.92311 | reward=0.04469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_4.ckpt\n",
      "[INFO]  epoch/step=5/1000 | loss=0.45095 | ploss=0.31241 | vloss=0.14520 | entropy=-6.75118 | reward=0.04906\n",
      "[INFO]  epoch/step=5/1100 | loss=0.38921 | ploss=0.26799 | vloss=0.12774 | entropy=-6.60415 | reward=0.04344\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_5.ckpt\n",
      "[INFO]  epoch/step=6/1200 | loss=0.43526 | ploss=0.29920 | vloss=0.14244 | entropy=-6.47298 | reward=0.04844\n",
      "[INFO]  epoch/step=6/1300 | loss=0.43159 | ploss=0.29350 | vloss=0.14428 | entropy=-6.28526 | reward=0.04906\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_6.ckpt\n",
      "[INFO]  epoch/step=7/1400 | loss=0.43143 | ploss=0.29145 | vloss=0.14612 | entropy=-6.21878 | reward=0.04969\n",
      "[INFO]  epoch/step=7/1500 | loss=0.44594 | ploss=0.30042 | vloss=0.15163 | entropy=-6.19479 | reward=0.05156\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_7.ckpt\n",
      "[INFO]  epoch/step=8/1600 | loss=0.46444 | ploss=0.30966 | vloss=0.16082 | entropy=-6.11588 | reward=0.05469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_8.ckpt\n",
      "[INFO]  epoch/step=9/1700 | loss=0.42890 | ploss=0.28875 | vloss=0.14612 | entropy=-6.05805 | reward=0.04969\n",
      "[INFO]  epoch/step=9/1800 | loss=0.46512 | ploss=0.31483 | vloss=0.15622 | entropy=-6.02108 | reward=0.05312\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_9.ckpt\n",
      "[INFO]  epoch/step=10/1900 | loss=0.43868 | ploss=0.29299 | vloss=0.15163 | entropy=-6.01678 | reward=0.05156\n",
      "[INFO]  epoch/step=10/2000 | loss=0.39225 | ploss=0.25848 | vloss=0.13968 | entropy=-6.00110 | reward=0.04750\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_10.ckpt\n",
      "[INFO]  epoch/step=11/2100 | loss=0.48207 | ploss=0.32625 | vloss=0.16174 | entropy=-6.00100 | reward=0.05500\n",
      "[INFO]  epoch/step=11/2200 | loss=0.46256 | ploss=0.30670 | vloss=0.16174 | entropy=-5.95249 | reward=0.05500\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_11.ckpt\n",
      "[INFO]  epoch/step=12/2300 | loss=0.47209 | ploss=0.31350 | vloss=0.16450 | entropy=-5.98209 | reward=0.05563\n",
      "[INFO]  epoch/step=12/2400 | loss=0.47189 | ploss=0.31511 | vloss=0.16266 | entropy=-5.95740 | reward=0.05531\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_12.ckpt\n",
      "[INFO]  epoch/step=13/2500 | loss=0.40091 | ploss=0.26526 | vloss=0.14152 | entropy=-5.94653 | reward=0.04719\n",
      "[INFO]  epoch/step=13/2600 | loss=0.43221 | ploss=0.28368 | vloss=0.15439 | entropy=-5.93539 | reward=0.05250\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_13.ckpt\n",
      "[INFO]  epoch/step=14/2700 | loss=0.43792 | ploss=0.28661 | vloss=0.15714 | entropy=-5.91709 | reward=0.05281\n",
      "[INFO]  epoch/step=14/2800 | loss=0.46136 | ploss=0.30729 | vloss=0.15990 | entropy=-5.91585 | reward=0.05437\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_14.ckpt\n",
      "[INFO]  epoch/step=15/2900 | loss=0.50595 | ploss=0.33627 | vloss=0.17552 | entropy=-5.91853 | reward=0.05906\n",
      "[INFO]  epoch/step=15/3000 | loss=0.42808 | ploss=0.28135 | vloss=0.15255 | entropy=-5.89385 | reward=0.05187\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_15.ckpt\n",
      "[INFO]  epoch/step=16/3100 | loss=0.47565 | ploss=0.31051 | vloss=0.17093 | entropy=-5.86398 | reward=0.05781\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_16.ckpt\n",
      "[INFO]  epoch/step=17/3200 | loss=0.48536 | ploss=0.31834 | vloss=0.17277 | entropy=-5.82543 | reward=0.05813\n",
      "[INFO]  epoch/step=17/3300 | loss=0.46694 | ploss=0.30268 | vloss=0.17001 | entropy=-5.82700 | reward=0.05781\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_17.ckpt\n",
      "[INFO]  epoch/step=18/3400 | loss=0.42833 | ploss=0.28153 | vloss=0.15255 | entropy=-5.82179 | reward=0.05156\n",
      "[INFO]  epoch/step=18/3500 | loss=0.46065 | ploss=0.29915 | vloss=0.16725 | entropy=-5.81711 | reward=0.05688\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_18.ckpt\n",
      "[INFO]  epoch/step=19/3600 | loss=0.41730 | ploss=0.27234 | vloss=0.15071 | entropy=-5.82243 | reward=0.05125\n",
      "[INFO]  epoch/step=19/3700 | loss=0.39933 | ploss=0.25988 | vloss=0.14520 | entropy=-5.81952 | reward=0.04938\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_19.ckpt\n",
      "[INFO]  epoch/step=20/3800 | loss=0.49788 | ploss=0.32254 | vloss=0.18104 | entropy=-5.77520 | reward=0.06156\n",
      "[INFO]  epoch/step=20/3900 | loss=0.44208 | ploss=0.28793 | vloss=0.15990 | entropy=-5.82015 | reward=0.05437\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_20.ckpt\n",
      "[INFO]  epoch/step=21/4000 | loss=0.50015 | ploss=0.32664 | vloss=0.17920 | entropy=-5.76719 | reward=0.06094\n",
      "[INFO]  epoch/step=21/4100 | loss=0.48167 | ploss=0.31463 | vloss=0.17277 | entropy=-5.79034 | reward=0.05875\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_21.ckpt\n",
      "[INFO]  epoch/step=22/4200 | loss=0.53496 | ploss=0.34948 | vloss=0.19115 | entropy=-5.72988 | reward=0.06438\n",
      "[INFO]  epoch/step=22/4300 | loss=0.49562 | ploss=0.32396 | vloss=0.17736 | entropy=-5.76751 | reward=0.06031\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_22.ckpt\n",
      "[INFO]  epoch/step=23/4400 | loss=0.42497 | ploss=0.27163 | vloss=0.15898 | entropy=-5.71231 | reward=0.05406\n",
      "[INFO]  epoch/step=23/4500 | loss=0.43754 | ploss=0.28239 | vloss=0.16082 | entropy=-5.73164 | reward=0.05469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_23.ckpt\n",
      "[INFO]  epoch/step=24/4600 | loss=0.51682 | ploss=0.33592 | vloss=0.18655 | entropy=-5.72453 | reward=0.06281\n",
      "[INFO]  epoch/step=24/4700 | loss=0.49073 | ploss=0.31995 | vloss=0.17644 | entropy=-5.72951 | reward=0.05937\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_24.ckpt\n",
      "[INFO]  epoch/step=25/4800 | loss=0.43580 | ploss=0.28527 | vloss=0.15622 | entropy=-5.75788 | reward=0.05312\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_25.ckpt\n",
      "[INFO]  epoch/step=26/4900 | loss=0.53653 | ploss=0.34554 | vloss=0.19666 | entropy=-5.74146 | reward=0.06625\n",
      "[INFO]  epoch/step=26/5000 | loss=0.48370 | ploss=0.31564 | vloss=0.17368 | entropy=-5.69477 | reward=0.05906\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_26.ckpt\n",
      "[INFO]  epoch/step=27/5100 | loss=0.45111 | ploss=0.29410 | vloss=0.16266 | entropy=-5.71596 | reward=0.05500\n",
      "[INFO]  epoch/step=27/5200 | loss=0.46390 | ploss=0.30046 | vloss=0.16909 | entropy=-5.71329 | reward=0.05750\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_27.ckpt\n",
      "[INFO]  epoch/step=28/5300 | loss=0.46337 | ploss=0.29625 | vloss=0.17277 | entropy=-5.71846 | reward=0.05813\n",
      "[INFO]  epoch/step=28/5400 | loss=0.47192 | ploss=0.30195 | vloss=0.17552 | entropy=-5.62419 | reward=0.05969\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_28.ckpt\n",
      "[INFO]  epoch/step=29/5500 | loss=0.46428 | ploss=0.29710 | vloss=0.17277 | entropy=-5.65615 | reward=0.05875\n",
      "[INFO]  epoch/step=29/5600 | loss=0.54647 | ploss=0.34986 | vloss=0.20217 | entropy=-5.63605 | reward=0.06875\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_29.ckpt\n",
      "[INFO]  epoch/step=30/5700 | loss=0.46859 | ploss=0.30236 | vloss=0.17185 | entropy=-5.68268 | reward=0.05813\n",
      "[INFO]  epoch/step=30/5800 | loss=0.52771 | ploss=0.33571 | vloss=0.19758 | entropy=-5.64364 | reward=0.06719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_30.ckpt\n",
      "[INFO]  epoch/step=31/5900 | loss=0.53221 | ploss=0.34484 | vloss=0.19298 | entropy=-5.67809 | reward=0.06500\n",
      "[INFO]  epoch/step=31/6000 | loss=0.51732 | ploss=0.33079 | vloss=0.19206 | entropy=-5.60192 | reward=0.06531\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_31.ckpt\n",
      "[INFO]  epoch/step=32/6100 | loss=0.51451 | ploss=0.32710 | vloss=0.19298 | entropy=-5.62968 | reward=0.06469\n",
      "[INFO]  epoch/step=32/6200 | loss=0.63037 | ploss=0.40618 | vloss=0.22974 | entropy=-5.61816 | reward=0.07812\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_32.ckpt\n",
      "[INFO]  epoch/step=33/6300 | loss=0.50758 | ploss=0.32658 | vloss=0.18655 | entropy=-5.61637 | reward=0.06313\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_33.ckpt\n",
      "[INFO]  epoch/step=34/6400 | loss=0.50699 | ploss=0.32231 | vloss=0.19023 | entropy=-5.60742 | reward=0.06438\n",
      "[INFO]  epoch/step=34/6500 | loss=0.50764 | ploss=0.32300 | vloss=0.19023 | entropy=-5.65618 | reward=0.06469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_34.ckpt\n",
      "[INFO]  epoch/step=35/6600 | loss=0.52452 | ploss=0.33336 | vloss=0.19666 | entropy=-5.56516 | reward=0.06688\n",
      "[INFO]  epoch/step=35/6700 | loss=0.47018 | ploss=0.29465 | vloss=0.18104 | entropy=-5.57727 | reward=0.06156\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_35.ckpt\n",
      "[INFO]  epoch/step=36/6800 | loss=0.56759 | ploss=0.35811 | vloss=0.21504 | entropy=-5.61832 | reward=0.07281\n",
      "[INFO]  epoch/step=36/6900 | loss=0.48022 | ploss=0.30563 | vloss=0.18012 | entropy=-5.58998 | reward=0.06125\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_36.ckpt\n",
      "[INFO]  epoch/step=37/7000 | loss=0.49710 | ploss=0.31882 | vloss=0.18379 | entropy=-5.58754 | reward=0.06250\n",
      "[INFO]  epoch/step=37/7100 | loss=0.57520 | ploss=0.36656 | vloss=0.21412 | entropy=-5.54557 | reward=0.07281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_37.ckpt\n",
      "[INFO]  epoch/step=38/7200 | loss=0.52831 | ploss=0.33441 | vloss=0.19942 | entropy=-5.58761 | reward=0.06781\n",
      "[INFO]  epoch/step=38/7300 | loss=0.54714 | ploss=0.34862 | vloss=0.20401 | entropy=-5.55012 | reward=0.06938\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_38.ckpt\n",
      "[INFO]  epoch/step=39/7400 | loss=0.55408 | ploss=0.35191 | vloss=0.20769 | entropy=-5.57808 | reward=0.07062\n",
      "[INFO]  epoch/step=39/7500 | loss=0.58465 | ploss=0.36961 | vloss=0.22055 | entropy=-5.57430 | reward=0.07500\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_39.ckpt\n",
      "[INFO]  epoch/step=40/7600 | loss=0.52965 | ploss=0.33568 | vloss=0.19942 | entropy=-5.51327 | reward=0.06781\n",
      "[INFO]  epoch/step=40/7700 | loss=0.59023 | ploss=0.37606 | vloss=0.21963 | entropy=-5.52724 | reward=0.07469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_40.ckpt\n",
      "[INFO]  epoch/step=41/7800 | loss=0.51080 | ploss=0.32236 | vloss=0.19390 | entropy=-5.53235 | reward=0.06563\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_41.ckpt\n",
      "[INFO]  epoch/step=42/7900 | loss=0.52744 | ploss=0.32885 | vloss=0.20401 | entropy=-5.48631 | reward=0.06938\n",
      "[INFO]  epoch/step=42/8000 | loss=0.57205 | ploss=0.36065 | vloss=0.21688 | entropy=-5.53723 | reward=0.07375\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_42.ckpt\n",
      "[INFO]  epoch/step=43/8100 | loss=0.50827 | ploss=0.32352 | vloss=0.19023 | entropy=-5.54169 | reward=0.06469\n",
      "[INFO]  epoch/step=43/8200 | loss=0.50545 | ploss=0.31699 | vloss=0.19390 | entropy=-5.50432 | reward=0.06594\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_43.ckpt\n",
      "[INFO]  epoch/step=44/8300 | loss=0.53495 | ploss=0.33639 | vloss=0.20401 | entropy=-5.51038 | reward=0.06938\n",
      "[INFO]  epoch/step=44/8400 | loss=0.53545 | ploss=0.33594 | vloss=0.20493 | entropy=-5.49282 | reward=0.06969\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_44.ckpt\n",
      "[INFO]  epoch/step=45/8500 | loss=0.49039 | ploss=0.31112 | vloss=0.18471 | entropy=-5.50382 | reward=0.06281\n",
      "[INFO]  epoch/step=45/8600 | loss=0.56987 | ploss=0.36113 | vloss=0.21412 | entropy=-5.43762 | reward=0.07281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_45.ckpt\n",
      "[INFO]  epoch/step=46/8700 | loss=0.52394 | ploss=0.32723 | vloss=0.20217 | entropy=-5.52969 | reward=0.06875\n",
      "[INFO]  epoch/step=46/8800 | loss=0.58087 | ploss=0.36112 | vloss=0.22515 | entropy=-5.45843 | reward=0.07656\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_46.ckpt\n",
      "[INFO]  epoch/step=47/8900 | loss=0.50594 | ploss=0.31836 | vloss=0.19298 | entropy=-5.46859 | reward=0.06563\n",
      "[INFO]  epoch/step=47/9000 | loss=0.52633 | ploss=0.32495 | vloss=0.20677 | entropy=-5.45098 | reward=0.07031\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_47.ckpt\n",
      "[INFO]  epoch/step=48/9100 | loss=0.59819 | ploss=0.37568 | vloss=0.22790 | entropy=-5.46532 | reward=0.07687\n",
      "[INFO]  epoch/step=48/9200 | loss=0.61990 | ploss=0.38637 | vloss=0.23893 | entropy=-5.47679 | reward=0.08125\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_48.ckpt\n",
      "[INFO]  epoch/step=49/9300 | loss=0.63945 | ploss=0.40405 | vloss=0.24077 | entropy=-5.43651 | reward=0.08094\n",
      "[INFO]  epoch/step=49/9400 | loss=0.55600 | ploss=0.34910 | vloss=0.21228 | entropy=-5.44021 | reward=0.07219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_49.ckpt\n",
      "[INFO]  epoch/step=50/9500 | loss=0.58702 | ploss=0.36909 | vloss=0.22331 | entropy=-5.44017 | reward=0.07594\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_50.ckpt\n",
      "[INFO]  epoch/step=51/9600 | loss=0.52060 | ploss=0.32657 | vloss=0.19942 | entropy=-5.44534 | reward=0.06750\n",
      "[INFO]  epoch/step=51/9700 | loss=0.57116 | ploss=0.35689 | vloss=0.21963 | entropy=-5.42472 | reward=0.07469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_51.ckpt\n",
      "[INFO]  epoch/step=52/9800 | loss=0.58223 | ploss=0.35964 | vloss=0.22790 | entropy=-5.38234 | reward=0.07687\n",
      "[INFO]  epoch/step=52/9900 | loss=0.59790 | ploss=0.36799 | vloss=0.23526 | entropy=-5.41879 | reward=0.08000\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_52.ckpt\n",
      "[INFO]  epoch/step=53/10000 | loss=0.53796 | ploss=0.33652 | vloss=0.20677 | entropy=-5.39430 | reward=0.07000\n",
      "[INFO]  epoch/step=53/10100 | loss=0.59340 | ploss=0.36993 | vloss=0.22882 | entropy=-5.42037 | reward=0.07781\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_53.ckpt\n",
      "[INFO]  epoch/step=54/10200 | loss=0.62362 | ploss=0.38360 | vloss=0.24536 | entropy=-5.41582 | reward=0.08281\n",
      "[INFO]  epoch/step=54/10300 | loss=0.60583 | ploss=0.37314 | vloss=0.23801 | entropy=-5.39825 | reward=0.08094\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_54.ckpt\n",
      "[INFO]  epoch/step=55/10400 | loss=0.55830 | ploss=0.34402 | vloss=0.21963 | entropy=-5.42700 | reward=0.07469\n",
      "[INFO]  epoch/step=55/10500 | loss=0.61517 | ploss=0.38158 | vloss=0.23893 | entropy=-5.41283 | reward=0.08125\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_55.ckpt\n",
      "[INFO]  epoch/step=56/10600 | loss=0.54652 | ploss=0.33859 | vloss=0.21320 | entropy=-5.34427 | reward=0.07250\n",
      "[INFO]  epoch/step=56/10700 | loss=0.58629 | ploss=0.36280 | vloss=0.22882 | entropy=-5.40349 | reward=0.07781\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_56.ckpt\n",
      "[INFO]  epoch/step=57/10800 | loss=0.55747 | ploss=0.34681 | vloss=0.21596 | entropy=-5.36406 | reward=0.07344\n",
      "[INFO]  epoch/step=57/10900 | loss=0.51434 | ploss=0.31563 | vloss=0.20401 | entropy=-5.36932 | reward=0.06938\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_57.ckpt\n",
      "[INFO]  epoch/step=58/11000 | loss=0.55069 | ploss=0.34284 | vloss=0.21320 | entropy=-5.42227 | reward=0.07219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_58.ckpt\n",
      "[INFO]  epoch/step=59/11100 | loss=0.65739 | ploss=0.40812 | vloss=0.25455 | entropy=-5.35390 | reward=0.08656\n",
      "[INFO]  epoch/step=59/11200 | loss=0.56671 | ploss=0.34680 | vloss=0.22515 | entropy=-5.31532 | reward=0.07656\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_59.ckpt\n",
      "[INFO]  epoch/step=60/11300 | loss=0.56458 | ploss=0.34843 | vloss=0.22147 | entropy=-5.39063 | reward=0.07469\n",
      "[INFO]  epoch/step=60/11400 | loss=0.54870 | ploss=0.34167 | vloss=0.21228 | entropy=-5.32519 | reward=0.07219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_60.ckpt\n",
      "[INFO]  epoch/step=61/11500 | loss=0.54535 | ploss=0.33926 | vloss=0.21136 | entropy=-5.34211 | reward=0.07156\n",
      "[INFO]  epoch/step=61/11600 | loss=0.56058 | ploss=0.34713 | vloss=0.21871 | entropy=-5.33991 | reward=0.07437\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_61.ckpt\n",
      "[INFO]  epoch/step=62/11700 | loss=0.57663 | ploss=0.35030 | vloss=0.23158 | entropy=-5.33220 | reward=0.07875\n",
      "[INFO]  epoch/step=62/11800 | loss=0.57739 | ploss=0.35289 | vloss=0.22974 | entropy=-5.31610 | reward=0.07812\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_62.ckpt\n",
      "[INFO]  epoch/step=63/11900 | loss=0.59792 | ploss=0.36514 | vloss=0.23801 | entropy=-5.30726 | reward=0.08063\n",
      "[INFO]  epoch/step=63/12000 | loss=0.58895 | ploss=0.36446 | vloss=0.22974 | entropy=-5.32195 | reward=0.07812\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_63.ckpt\n",
      "[INFO]  epoch/step=64/12100 | loss=0.68964 | ploss=0.42288 | vloss=0.27201 | entropy=-5.32702 | reward=0.09187\n",
      "[INFO]  epoch/step=64/12200 | loss=0.58500 | ploss=0.36051 | vloss=0.22974 | entropy=-5.32674 | reward=0.07812\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_64.ckpt\n",
      "[INFO]  epoch/step=65/12300 | loss=0.63051 | ploss=0.38669 | vloss=0.24904 | entropy=-5.28890 | reward=0.08438\n",
      "[INFO]  epoch/step=65/12400 | loss=0.59436 | ploss=0.36619 | vloss=0.23342 | entropy=-5.32177 | reward=0.07938\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_65.ckpt\n",
      "[INFO]  epoch/step=66/12500 | loss=0.57573 | ploss=0.35212 | vloss=0.22882 | entropy=-5.28004 | reward=0.07781\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_66.ckpt\n",
      "[INFO]  epoch/step=67/12600 | loss=0.65131 | ploss=0.39464 | vloss=0.26191 | entropy=-5.31626 | reward=0.08812\n",
      "[INFO]  epoch/step=67/12700 | loss=0.61614 | ploss=0.37412 | vloss=0.24720 | entropy=-5.25858 | reward=0.08406\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_67.ckpt\n",
      "[INFO]  epoch/step=68/12800 | loss=0.63247 | ploss=0.39049 | vloss=0.24720 | entropy=-5.30253 | reward=0.08375\n",
      "[INFO]  epoch/step=68/12900 | loss=0.54916 | ploss=0.33656 | vloss=0.21780 | entropy=-5.27748 | reward=0.07406\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_68.ckpt\n",
      "[INFO]  epoch/step=69/13000 | loss=0.59668 | ploss=0.36204 | vloss=0.23985 | entropy=-5.28762 | reward=0.08156\n",
      "[INFO]  epoch/step=69/13100 | loss=0.60327 | ploss=0.36678 | vloss=0.24169 | entropy=-5.27286 | reward=0.08219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_69.ckpt\n",
      "[INFO]  epoch/step=70/13200 | loss=0.60829 | ploss=0.36442 | vloss=0.24904 | entropy=-5.25096 | reward=0.08469\n",
      "[INFO]  epoch/step=70/13300 | loss=0.64901 | ploss=0.39869 | vloss=0.25547 | entropy=-5.23840 | reward=0.08687\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_70.ckpt\n",
      "[INFO]  epoch/step=71/13400 | loss=0.64656 | ploss=0.39532 | vloss=0.25639 | entropy=-5.23243 | reward=0.08625\n",
      "[INFO]  epoch/step=71/13500 | loss=0.59143 | ploss=0.35950 | vloss=0.23709 | entropy=-5.24288 | reward=0.08063\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_71.ckpt\n",
      "[INFO]  epoch/step=72/13600 | loss=0.59935 | ploss=0.36006 | vloss=0.24445 | entropy=-5.23672 | reward=0.08281\n",
      "[INFO]  epoch/step=72/13700 | loss=0.64718 | ploss=0.38863 | vloss=0.26374 | entropy=-5.26671 | reward=0.08969\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_72.ckpt\n",
      "[INFO]  epoch/step=73/13800 | loss=0.65758 | ploss=0.40174 | vloss=0.26099 | entropy=-5.22882 | reward=0.08812\n",
      "[INFO]  epoch/step=73/13900 | loss=0.57052 | ploss=0.33949 | vloss=0.23617 | entropy=-5.21834 | reward=0.08031\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_73.ckpt\n",
      "[INFO]  epoch/step=74/14000 | loss=0.67606 | ploss=0.40825 | vloss=0.27293 | entropy=-5.19794 | reward=0.09125\n",
      "[INFO]  epoch/step=74/14100 | loss=0.62672 | ploss=0.37362 | vloss=0.25823 | entropy=-5.21580 | reward=0.08750\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_74.ckpt\n",
      "[INFO]  epoch/step=75/14200 | loss=0.57811 | ploss=0.34798 | vloss=0.23526 | entropy=-5.20883 | reward=0.08000\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_75.ckpt\n",
      "[INFO]  epoch/step=76/14300 | loss=0.71598 | ploss=0.43899 | vloss=0.28212 | entropy=-5.21434 | reward=0.09500\n",
      "[INFO]  epoch/step=76/14400 | loss=0.60215 | ploss=0.36374 | vloss=0.24353 | entropy=-5.20094 | reward=0.08281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_76.ckpt\n",
      "[INFO]  epoch/step=77/14500 | loss=0.64072 | ploss=0.38853 | vloss=0.25731 | entropy=-5.20480 | reward=0.08750\n",
      "[INFO]  epoch/step=77/14600 | loss=0.65989 | ploss=0.40034 | vloss=0.26466 | entropy=-5.18985 | reward=0.09000\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_77.ckpt\n",
      "[INFO]  epoch/step=78/14700 | loss=0.63149 | ploss=0.37653 | vloss=0.26007 | entropy=-5.18956 | reward=0.08844\n",
      "[INFO]  epoch/step=78/14800 | loss=0.59304 | ploss=0.35552 | vloss=0.24261 | entropy=-5.16553 | reward=0.08250\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_78.ckpt\n",
      "[INFO]  epoch/step=79/14900 | loss=0.67582 | ploss=0.41079 | vloss=0.27018 | entropy=-5.22687 | reward=0.09187\n",
      "[INFO]  epoch/step=79/15000 | loss=0.61969 | ploss=0.36836 | vloss=0.25639 | entropy=-5.14312 | reward=0.08719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_79.ckpt\n",
      "[INFO]  epoch/step=80/15100 | loss=0.61927 | ploss=0.36609 | vloss=0.25823 | entropy=-5.13666 | reward=0.08750\n",
      "[INFO]  epoch/step=80/15200 | loss=0.59012 | ploss=0.35533 | vloss=0.23985 | entropy=-5.14707 | reward=0.08156\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_80.ckpt\n",
      "[INFO]  epoch/step=81/15300 | loss=0.61809 | ploss=0.36675 | vloss=0.25639 | entropy=-5.13742 | reward=0.08719\n",
      "[INFO]  epoch/step=81/15400 | loss=0.65032 | ploss=0.39531 | vloss=0.26007 | entropy=-5.13763 | reward=0.08844\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_81.ckpt\n",
      "[INFO]  epoch/step=82/15500 | loss=0.60554 | ploss=0.36706 | vloss=0.24353 | entropy=-5.13258 | reward=0.08281\n",
      "[INFO]  epoch/step=82/15600 | loss=0.66608 | ploss=0.39732 | vloss=0.27385 | entropy=-5.17108 | reward=0.09312\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_82.ckpt\n",
      "[INFO]  epoch/step=83/15700 | loss=0.60044 | ploss=0.36104 | vloss=0.24445 | entropy=-5.13099 | reward=0.08281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_83.ckpt\n",
      "[INFO]  epoch/step=84/15800 | loss=0.66612 | ploss=0.39550 | vloss=0.27569 | entropy=-5.15522 | reward=0.09281\n",
      "[INFO]  epoch/step=84/15900 | loss=0.58779 | ploss=0.34930 | vloss=0.24353 | entropy=-5.12546 | reward=0.08281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_84.ckpt\n",
      "[INFO]  epoch/step=85/16000 | loss=0.61948 | ploss=0.36903 | vloss=0.25547 | entropy=-5.10120 | reward=0.08625\n",
      "[INFO]  epoch/step=85/16100 | loss=0.62847 | ploss=0.37434 | vloss=0.25915 | entropy=-5.09985 | reward=0.08812\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_85.ckpt\n",
      "[INFO]  epoch/step=86/16200 | loss=0.60500 | ploss=0.36375 | vloss=0.24628 | entropy=-5.12192 | reward=0.08344\n",
      "[INFO]  epoch/step=86/16300 | loss=0.67191 | ploss=0.39387 | vloss=0.28304 | entropy=-5.08391 | reward=0.09625\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_86.ckpt\n",
      "[INFO]  epoch/step=87/16400 | loss=0.68424 | ploss=0.40345 | vloss=0.28580 | entropy=-5.09509 | reward=0.09656\n",
      "[INFO]  epoch/step=87/16500 | loss=0.59119 | ploss=0.35451 | vloss=0.24169 | entropy=-5.08983 | reward=0.08219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_87.ckpt\n",
      "[INFO]  epoch/step=88/16600 | loss=0.72008 | ploss=0.42733 | vloss=0.29775 | entropy=-5.08326 | reward=0.10031\n",
      "[INFO]  epoch/step=88/16700 | loss=0.68040 | ploss=0.40600 | vloss=0.27937 | entropy=-5.05370 | reward=0.09500\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_88.ckpt\n",
      "[INFO]  epoch/step=89/16800 | loss=0.65499 | ploss=0.39441 | vloss=0.26558 | entropy=-5.08543 | reward=0.08969\n",
      "[INFO]  epoch/step=89/16900 | loss=0.62094 | ploss=0.36954 | vloss=0.25639 | entropy=-5.07570 | reward=0.08719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_89.ckpt\n",
      "[INFO]  epoch/step=90/17000 | loss=0.64398 | ploss=0.37507 | vloss=0.27385 | entropy=-5.03180 | reward=0.09281\n",
      "[INFO]  epoch/step=90/17100 | loss=0.65767 | ploss=0.38876 | vloss=0.27385 | entropy=-5.03561 | reward=0.09312\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_90.ckpt\n",
      "[INFO]  epoch/step=91/17200 | loss=0.66315 | ploss=0.39425 | vloss=0.27385 | entropy=-5.04419 | reward=0.09281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_91.ckpt\n",
      "[INFO]  epoch/step=92/17300 | loss=0.67716 | ploss=0.39908 | vloss=0.28304 | entropy=-5.05348 | reward=0.09594\n",
      "[INFO]  epoch/step=92/17400 | loss=0.64664 | ploss=0.37960 | vloss=0.27201 | entropy=-5.06529 | reward=0.09250\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_92.ckpt\n",
      "[INFO]  epoch/step=93/17500 | loss=0.71968 | ploss=0.42229 | vloss=0.30234 | entropy=-5.03287 | reward=0.10219\n",
      "[INFO]  epoch/step=93/17600 | loss=0.66248 | ploss=0.39359 | vloss=0.27385 | entropy=-5.05719 | reward=0.09312\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_93.ckpt\n",
      "[INFO]  epoch/step=94/17700 | loss=0.66701 | ploss=0.39165 | vloss=0.28029 | entropy=-5.01636 | reward=0.09469\n",
      "[INFO]  epoch/step=94/17800 | loss=0.64115 | ploss=0.37866 | vloss=0.26742 | entropy=-5.02107 | reward=0.09094\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_94.ckpt\n",
      "[INFO]  epoch/step=95/17900 | loss=0.63394 | ploss=0.36961 | vloss=0.26926 | entropy=-5.01648 | reward=0.09125\n",
      "[INFO]  epoch/step=95/18000 | loss=0.63717 | ploss=0.37101 | vloss=0.27110 | entropy=-5.02895 | reward=0.09219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_95.ckpt\n",
      "[INFO]  epoch/step=96/18100 | loss=0.65541 | ploss=0.38187 | vloss=0.27845 | entropy=-5.00050 | reward=0.09375\n",
      "[INFO]  epoch/step=96/18200 | loss=0.68292 | ploss=0.40205 | vloss=0.28580 | entropy=-5.01300 | reward=0.09719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_96.ckpt\n",
      "[INFO]  epoch/step=97/18300 | loss=0.65907 | ploss=0.38829 | vloss=0.27569 | entropy=-5.01027 | reward=0.09375\n",
      "[INFO]  epoch/step=97/18400 | loss=0.75222 | ploss=0.43914 | vloss=0.31796 | entropy=-4.97237 | reward=0.10812\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_97.ckpt\n",
      "[INFO]  epoch/step=98/18500 | loss=0.71117 | ploss=0.41461 | vloss=0.30142 | entropy=-4.95596 | reward=0.10219\n",
      "[INFO]  epoch/step=98/18600 | loss=0.63704 | ploss=0.37634 | vloss=0.26558 | entropy=-4.97428 | reward=0.09031\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_98.ckpt\n",
      "[INFO]  epoch/step=99/18700 | loss=0.74751 | ploss=0.43716 | vloss=0.31521 | entropy=-4.95100 | reward=0.10625\n",
      "[INFO]  epoch/step=99/18800 | loss=0.67578 | ploss=0.39949 | vloss=0.28120 | entropy=-5.00989 | reward=0.09438\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_99.ckpt\n",
      "[INFO]  epoch/step=100/18900 | loss=0.69189 | ploss=0.41093 | vloss=0.28580 | entropy=-4.92613 | reward=0.09719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_100.ckpt\n",
      "[INFO]  epoch/step=101/19000 | loss=0.67452 | ploss=0.39169 | vloss=0.28764 | entropy=-4.89856 | reward=0.09781\n",
      "[INFO]  epoch/step=101/19100 | loss=0.68683 | ploss=0.40402 | vloss=0.28764 | entropy=-4.92382 | reward=0.09781\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_101.ckpt\n",
      "[INFO]  epoch/step=102/19200 | loss=0.63630 | ploss=0.36914 | vloss=0.27201 | entropy=-4.94720 | reward=0.09187\n",
      "[INFO]  epoch/step=102/19300 | loss=0.71175 | ploss=0.41149 | vloss=0.30510 | entropy=-4.92992 | reward=0.10375\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_102.ckpt\n",
      "[INFO]  epoch/step=103/19400 | loss=0.72232 | ploss=0.41833 | vloss=0.30877 | entropy=-4.88244 | reward=0.10469\n",
      "[INFO]  epoch/step=103/19500 | loss=0.64591 | ploss=0.37227 | vloss=0.27845 | entropy=-4.90058 | reward=0.09469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_103.ckpt\n",
      "[INFO]  epoch/step=104/19600 | loss=0.75050 | ploss=0.43552 | vloss=0.31980 | entropy=-4.91643 | reward=0.10844\n",
      "[INFO]  epoch/step=104/19700 | loss=0.69061 | ploss=0.40406 | vloss=0.29131 | entropy=-4.86264 | reward=0.09906\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_104.ckpt\n",
      "[INFO]  epoch/step=105/19800 | loss=0.71537 | ploss=0.41136 | vloss=0.30877 | entropy=-4.86609 | reward=0.10375\n",
      "[INFO]  epoch/step=105/19900 | loss=0.73247 | ploss=0.43402 | vloss=0.30326 | entropy=-4.90398 | reward=0.10312\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_105.ckpt\n",
      "[INFO]  epoch/step=106/20000 | loss=0.66414 | ploss=0.38039 | vloss=0.28856 | entropy=-4.89720 | reward=0.09781\n",
      "[INFO]  epoch/step=106/20100 | loss=0.69128 | ploss=0.39647 | vloss=0.29958 | entropy=-4.87416 | reward=0.10187\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_106.ckpt\n",
      "[INFO]  epoch/step=107/20200 | loss=0.67152 | ploss=0.38685 | vloss=0.28947 | entropy=-4.89931 | reward=0.09844\n",
      "[INFO]  epoch/step=107/20300 | loss=0.71909 | ploss=0.41879 | vloss=0.30510 | entropy=-4.89390 | reward=0.10375\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_107.ckpt\n",
      "[INFO]  epoch/step=108/20400 | loss=0.70547 | ploss=0.40511 | vloss=0.30510 | entropy=-4.83359 | reward=0.10312\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_108.ckpt\n",
      "[INFO]  epoch/step=109/20500 | loss=0.68339 | ploss=0.39495 | vloss=0.29315 | entropy=-4.81424 | reward=0.09938\n",
      "[INFO]  epoch/step=109/20600 | loss=0.76134 | ploss=0.43712 | vloss=0.32899 | entropy=-4.86957 | reward=0.11188\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_109.ckpt\n",
      "[INFO]  epoch/step=110/20700 | loss=0.59858 | ploss=0.34144 | vloss=0.26191 | entropy=-4.86107 | reward=0.08906\n",
      "[INFO]  epoch/step=110/20800 | loss=0.77337 | ploss=0.43809 | vloss=0.34002 | entropy=-4.83593 | reward=0.11563\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_110.ckpt\n",
      "[INFO]  epoch/step=111/20900 | loss=0.72418 | ploss=0.41644 | vloss=0.31245 | entropy=-4.81009 | reward=0.10562\n",
      "[INFO]  epoch/step=111/21000 | loss=0.71092 | ploss=0.41334 | vloss=0.30234 | entropy=-4.86498 | reward=0.10281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_111.ckpt\n",
      "[INFO]  epoch/step=112/21100 | loss=0.69039 | ploss=0.39550 | vloss=0.29958 | entropy=-4.79215 | reward=0.10156\n",
      "[INFO]  epoch/step=112/21200 | loss=0.72161 | ploss=0.41113 | vloss=0.31521 | entropy=-4.82769 | reward=0.10719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_112.ckpt\n",
      "[INFO]  epoch/step=113/21300 | loss=0.71974 | ploss=0.40739 | vloss=0.31704 | entropy=-4.78620 | reward=0.10719\n",
      "[INFO]  epoch/step=113/21400 | loss=0.72652 | ploss=0.41788 | vloss=0.31337 | entropy=-4.83270 | reward=0.10656\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_113.ckpt\n",
      "[INFO]  epoch/step=114/21500 | loss=0.75451 | ploss=0.42748 | vloss=0.33175 | entropy=-4.81321 | reward=0.11188\n",
      "[INFO]  epoch/step=114/21600 | loss=0.63361 | ploss=0.35800 | vloss=0.28029 | entropy=-4.78030 | reward=0.09531\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_114.ckpt\n",
      "[INFO]  epoch/step=115/21700 | loss=0.80575 | ploss=0.46676 | vloss=0.34369 | entropy=-4.80276 | reward=0.11563\n",
      "[INFO]  epoch/step=115/21800 | loss=0.68642 | ploss=0.39333 | vloss=0.29775 | entropy=-4.75951 | reward=0.10125\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_115.ckpt\n",
      "[INFO]  epoch/step=116/21900 | loss=0.72605 | ploss=0.41088 | vloss=0.31980 | entropy=-4.73622 | reward=0.10812\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_116.ckpt\n",
      "[INFO]  epoch/step=117/22000 | loss=0.78152 | ploss=0.44338 | vloss=0.34277 | entropy=-4.73847 | reward=0.11594\n",
      "[INFO]  epoch/step=117/22100 | loss=0.67709 | ploss=0.38122 | vloss=0.30050 | entropy=-4.73602 | reward=0.10219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_117.ckpt\n",
      "[INFO]  epoch/step=118/22200 | loss=0.63238 | ploss=0.35858 | vloss=0.27845 | entropy=-4.74412 | reward=0.09438\n",
      "[INFO]  epoch/step=118/22300 | loss=0.74545 | ploss=0.42295 | vloss=0.32715 | entropy=-4.75619 | reward=0.11125\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_118.ckpt\n",
      "[INFO]  epoch/step=119/22400 | loss=0.67932 | ploss=0.37518 | vloss=0.30877 | entropy=-4.73683 | reward=0.10437\n",
      "[INFO]  epoch/step=119/22500 | loss=0.69909 | ploss=0.39311 | vloss=0.31061 | entropy=-4.73082 | reward=0.10562\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_119.ckpt\n",
      "[INFO]  epoch/step=120/22600 | loss=0.72103 | ploss=0.40955 | vloss=0.31612 | entropy=-4.74596 | reward=0.10719\n",
      "[INFO]  epoch/step=120/22700 | loss=0.74745 | ploss=0.42129 | vloss=0.33083 | entropy=-4.76554 | reward=0.11250\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_120.ckpt\n",
      "[INFO]  epoch/step=121/22800 | loss=0.71351 | ploss=0.39648 | vloss=0.32164 | entropy=-4.71219 | reward=0.10906\n",
      "[INFO]  epoch/step=121/22900 | loss=0.68987 | ploss=0.38936 | vloss=0.30510 | entropy=-4.69534 | reward=0.10375\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_121.ckpt\n",
      "[INFO]  epoch/step=122/23000 | loss=0.77873 | ploss=0.43406 | vloss=0.34921 | entropy=-4.64383 | reward=0.11844\n",
      "[INFO]  epoch/step=122/23100 | loss=0.72862 | ploss=0.41346 | vloss=0.31980 | entropy=-4.74503 | reward=0.10875\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_122.ckpt\n",
      "[INFO]  epoch/step=123/23200 | loss=0.73982 | ploss=0.41722 | vloss=0.32715 | entropy=-4.65843 | reward=0.11031\n",
      "[INFO]  epoch/step=123/23300 | loss=0.76273 | ploss=0.43003 | vloss=0.33726 | entropy=-4.66642 | reward=0.11469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_123.ckpt\n",
      "[INFO]  epoch/step=124/23400 | loss=0.76908 | ploss=0.42261 | vloss=0.35105 | entropy=-4.68290 | reward=0.11906\n",
      "[INFO]  epoch/step=124/23500 | loss=0.77890 | ploss=0.44433 | vloss=0.33910 | entropy=-4.64195 | reward=0.11500\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_124.ckpt\n",
      "[INFO]  epoch/step=125/23600 | loss=0.75052 | ploss=0.42427 | vloss=0.33083 | entropy=-4.68073 | reward=0.11250\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_125.ckpt\n",
      "[INFO]  epoch/step=126/23700 | loss=0.73485 | ploss=0.40583 | vloss=0.33359 | entropy=-4.67261 | reward=0.11281\n",
      "[INFO]  epoch/step=126/23800 | loss=0.70875 | ploss=0.40547 | vloss=0.30785 | entropy=-4.68099 | reward=0.10469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_126.ckpt\n",
      "[INFO]  epoch/step=127/23900 | loss=0.67651 | ploss=0.37685 | vloss=0.30418 | entropy=-4.63007 | reward=0.10344\n",
      "[INFO]  epoch/step=127/24000 | loss=0.70631 | ploss=0.39567 | vloss=0.31521 | entropy=-4.67617 | reward=0.10719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_127.ckpt\n",
      "[INFO]  epoch/step=128/24100 | loss=0.79660 | ploss=0.45196 | vloss=0.34921 | entropy=-4.67095 | reward=0.11812\n",
      "[INFO]  epoch/step=128/24200 | loss=0.82513 | ploss=0.46206 | vloss=0.36759 | entropy=-4.62829 | reward=0.12500\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_128.ckpt\n",
      "[INFO]  epoch/step=129/24300 | loss=0.72726 | ploss=0.40554 | vloss=0.32623 | entropy=-4.62367 | reward=0.11094\n",
      "[INFO]  epoch/step=129/24400 | loss=0.71534 | ploss=0.39545 | vloss=0.32440 | entropy=-4.62042 | reward=0.11031\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_129.ckpt\n",
      "[INFO]  epoch/step=130/24500 | loss=0.71845 | ploss=0.40132 | vloss=0.32164 | entropy=-4.62251 | reward=0.10938\n",
      "[INFO]  epoch/step=130/24600 | loss=0.70770 | ploss=0.39056 | vloss=0.32164 | entropy=-4.60931 | reward=0.10938\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_130.ckpt\n",
      "[INFO]  epoch/step=131/24700 | loss=0.70281 | ploss=0.38564 | vloss=0.32164 | entropy=-4.58611 | reward=0.10719\n",
      "[INFO]  epoch/step=131/24800 | loss=0.78825 | ploss=0.43338 | vloss=0.35932 | entropy=-4.56110 | reward=0.12219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_131.ckpt\n",
      "[INFO]  epoch/step=132/24900 | loss=0.73409 | ploss=0.40594 | vloss=0.33267 | entropy=-4.62670 | reward=0.11281\n",
      "[INFO]  epoch/step=132/25000 | loss=0.72882 | ploss=0.40429 | vloss=0.32899 | entropy=-4.57607 | reward=0.11188\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_132.ckpt\n",
      "[INFO]  epoch/step=133/25100 | loss=0.79238 | ploss=0.43752 | vloss=0.35932 | entropy=-4.56668 | reward=0.12125\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_133.ckpt\n",
      "[INFO]  epoch/step=134/25200 | loss=0.74218 | ploss=0.40482 | vloss=0.34186 | entropy=-4.59863 | reward=0.11563\n",
      "[INFO]  epoch/step=134/25300 | loss=0.73731 | ploss=0.40451 | vloss=0.33726 | entropy=-4.57541 | reward=0.11469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_134.ckpt\n",
      "[INFO]  epoch/step=135/25400 | loss=0.81547 | ploss=0.45144 | vloss=0.36851 | entropy=-4.58631 | reward=0.12531\n",
      "[INFO]  epoch/step=135/25500 | loss=0.79290 | ploss=0.43158 | vloss=0.36575 | entropy=-4.53854 | reward=0.12437\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_135.ckpt\n",
      "[INFO]  epoch/step=136/25600 | loss=0.72000 | ploss=0.38902 | vloss=0.33542 | entropy=-4.54777 | reward=0.11375\n",
      "[INFO]  epoch/step=136/25700 | loss=0.75543 | ploss=0.41893 | vloss=0.34094 | entropy=-4.54856 | reward=0.11594\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_136.ckpt\n",
      "[INFO]  epoch/step=137/25800 | loss=0.78385 | ploss=0.42434 | vloss=0.36391 | entropy=-4.51308 | reward=0.12312\n",
      "[INFO]  epoch/step=137/25900 | loss=0.74561 | ploss=0.40355 | vloss=0.34645 | entropy=-4.50695 | reward=0.11781\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_137.ckpt\n",
      "[INFO]  epoch/step=138/26000 | loss=0.73988 | ploss=0.40339 | vloss=0.34094 | entropy=-4.56389 | reward=0.11594\n",
      "[INFO]  epoch/step=138/26100 | loss=0.70347 | ploss=0.37522 | vloss=0.33267 | entropy=-4.52767 | reward=0.11313\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_138.ckpt\n",
      "[INFO]  epoch/step=139/26200 | loss=0.72107 | ploss=0.39280 | vloss=0.33267 | entropy=-4.50894 | reward=0.11250\n",
      "[INFO]  epoch/step=139/26300 | loss=0.77068 | ploss=0.42129 | vloss=0.35380 | entropy=-4.52872 | reward=0.12031\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_139.ckpt\n",
      "[INFO]  epoch/step=140/26400 | loss=0.77808 | ploss=0.41668 | vloss=0.36575 | entropy=-4.46699 | reward=0.12406\n",
      "[INFO]  epoch/step=140/26500 | loss=0.79233 | ploss=0.43464 | vloss=0.36207 | entropy=-4.50490 | reward=0.12312\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_140.ckpt\n",
      "[INFO]  epoch/step=141/26600 | loss=0.72286 | ploss=0.39920 | vloss=0.32807 | entropy=-4.53385 | reward=0.11156\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_141.ckpt\n",
      "[INFO]  epoch/step=142/26700 | loss=0.73381 | ploss=0.39815 | vloss=0.34002 | entropy=-4.47531 | reward=0.11469\n",
      "[INFO]  epoch/step=142/26800 | loss=0.79512 | ploss=0.43740 | vloss=0.36207 | entropy=-4.47027 | reward=0.12312\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_142.ckpt\n",
      "[INFO]  epoch/step=143/26900 | loss=0.74050 | ploss=0.40486 | vloss=0.34002 | entropy=-4.49571 | reward=0.11469\n",
      "[INFO]  epoch/step=143/27000 | loss=0.77533 | ploss=0.42402 | vloss=0.35564 | entropy=-4.44280 | reward=0.12094\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_143.ckpt\n",
      "[INFO]  epoch/step=144/27100 | loss=0.76917 | ploss=0.40682 | vloss=0.36667 | entropy=-4.43477 | reward=0.12406\n",
      "[INFO]  epoch/step=144/27200 | loss=0.78775 | ploss=0.42634 | vloss=0.36575 | entropy=-4.45535 | reward=0.12437\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_144.ckpt\n",
      "[INFO]  epoch/step=145/27300 | loss=0.77917 | ploss=0.42419 | vloss=0.35932 | entropy=-4.45243 | reward=0.12187\n",
      "[INFO]  epoch/step=145/27400 | loss=0.73751 | ploss=0.39359 | vloss=0.34829 | entropy=-4.48089 | reward=0.11844\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_145.ckpt\n",
      "[INFO]  epoch/step=146/27500 | loss=0.72271 | ploss=0.39346 | vloss=0.33359 | entropy=-4.44620 | reward=0.11281\n",
      "[INFO]  epoch/step=146/27600 | loss=0.78415 | ploss=0.41997 | vloss=0.36851 | entropy=-4.44460 | reward=0.12531\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_146.ckpt\n",
      "[INFO]  epoch/step=147/27700 | loss=0.74685 | ploss=0.40562 | vloss=0.34553 | entropy=-4.42042 | reward=0.11656\n",
      "[INFO]  epoch/step=147/27800 | loss=0.75593 | ploss=0.40553 | vloss=0.35472 | entropy=-4.44107 | reward=0.12062\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_147.ckpt\n",
      "[INFO]  epoch/step=148/27900 | loss=0.76948 | ploss=0.41357 | vloss=0.36024 | entropy=-4.44717 | reward=0.12219\n",
      "[INFO]  epoch/step=148/28000 | loss=0.66920 | ploss=0.35832 | vloss=0.31521 | entropy=-4.43867 | reward=0.10719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_148.ckpt\n",
      "[INFO]  epoch/step=149/28100 | loss=0.72172 | ploss=0.38783 | vloss=0.33818 | entropy=-4.40809 | reward=0.11469\n",
      "[INFO]  epoch/step=149/28200 | loss=0.75147 | ploss=0.40656 | vloss=0.34921 | entropy=-4.41285 | reward=0.11844\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_149.ckpt\n",
      "[INFO]  epoch/step=150/28300 | loss=0.79489 | ploss=0.42697 | vloss=0.37218 | entropy=-4.39181 | reward=0.12656\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_150.ckpt\n",
      "[INFO]  epoch/step=151/28400 | loss=0.74373 | ploss=0.39697 | vloss=0.35105 | entropy=-4.41014 | reward=0.11875\n",
      "[INFO]  epoch/step=151/28500 | loss=0.73443 | ploss=0.39960 | vloss=0.33910 | entropy=-4.39903 | reward=0.11531\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_151.ckpt\n",
      "[INFO]  epoch/step=152/28600 | loss=0.74470 | ploss=0.39514 | vloss=0.35380 | entropy=-4.36402 | reward=0.12031\n",
      "[INFO]  epoch/step=152/28700 | loss=0.77209 | ploss=0.41339 | vloss=0.36299 | entropy=-4.42111 | reward=0.12344\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_152.ckpt\n",
      "[INFO]  epoch/step=153/28800 | loss=0.74804 | ploss=0.40124 | vloss=0.35105 | entropy=-4.37069 | reward=0.11875\n",
      "[INFO]  epoch/step=153/28900 | loss=0.77900 | ploss=0.42390 | vloss=0.35932 | entropy=-4.34201 | reward=0.12219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_153.ckpt\n",
      "[INFO]  epoch/step=154/29000 | loss=0.72861 | ploss=0.37997 | vloss=0.35288 | entropy=-4.36363 | reward=0.11906\n",
      "[INFO]  epoch/step=154/29100 | loss=0.74423 | ploss=0.39282 | vloss=0.35564 | entropy=-4.35424 | reward=0.12094\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_154.ckpt\n",
      "[INFO]  epoch/step=155/29200 | loss=0.81675 | ploss=0.44055 | vloss=0.38045 | entropy=-4.38265 | reward=0.12844\n",
      "[INFO]  epoch/step=155/29300 | loss=0.73857 | ploss=0.39727 | vloss=0.34553 | entropy=-4.35929 | reward=0.11750\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_155.ckpt\n",
      "[INFO]  epoch/step=156/29400 | loss=0.82361 | ploss=0.44369 | vloss=0.38413 | entropy=-4.33274 | reward=0.13031\n",
      "[INFO]  epoch/step=156/29500 | loss=0.82411 | ploss=0.43960 | vloss=0.38872 | entropy=-4.33289 | reward=0.13219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_156.ckpt\n",
      "[INFO]  epoch/step=157/29600 | loss=0.71753 | ploss=0.37621 | vloss=0.34553 | entropy=-4.33343 | reward=0.11750\n",
      "[INFO]  epoch/step=157/29700 | loss=0.76862 | ploss=0.40798 | vloss=0.36483 | entropy=-4.31595 | reward=0.12406\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_157.ckpt\n",
      "[INFO]  epoch/step=158/29800 | loss=0.82143 | ploss=0.44059 | vloss=0.38505 | entropy=-4.33094 | reward=0.13062\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_158.ckpt\n",
      "[INFO]  epoch/step=159/29900 | loss=0.81276 | ploss=0.43002 | vloss=0.38689 | entropy=-4.27530 | reward=0.13094\n",
      "[INFO]  epoch/step=159/30000 | loss=0.81786 | ploss=0.43511 | vloss=0.38689 | entropy=-4.26409 | reward=0.13156\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_159.ckpt\n",
      "[INFO]  epoch/step=160/30100 | loss=0.79307 | ploss=0.42507 | vloss=0.37218 | entropy=-4.31032 | reward=0.12562\n",
      "[INFO]  epoch/step=160/30200 | loss=0.70920 | ploss=0.37610 | vloss=0.33726 | entropy=-4.28923 | reward=0.11469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_160.ckpt\n",
      "[INFO]  epoch/step=161/30300 | loss=0.75035 | ploss=0.38413 | vloss=0.37034 | entropy=-4.25565 | reward=0.12500\n",
      "[INFO]  epoch/step=161/30400 | loss=0.83272 | ploss=0.44633 | vloss=0.39056 | entropy=-4.29787 | reward=0.13281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_161.ckpt\n",
      "[INFO]  epoch/step=162/30500 | loss=0.78709 | ploss=0.41078 | vloss=0.38045 | entropy=-4.27232 | reward=0.12906\n",
      "[INFO]  epoch/step=162/30600 | loss=0.77301 | ploss=0.40406 | vloss=0.37310 | entropy=-4.27102 | reward=0.12687\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_162.ckpt\n",
      "[INFO]  epoch/step=163/30700 | loss=0.80328 | ploss=0.41407 | vloss=0.39332 | entropy=-4.23565 | reward=0.13312\n",
      "[INFO]  epoch/step=163/30800 | loss=0.75501 | ploss=0.39800 | vloss=0.36115 | entropy=-4.27031 | reward=0.12281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_163.ckpt\n",
      "[INFO]  epoch/step=164/30900 | loss=0.75599 | ploss=0.39251 | vloss=0.36759 | entropy=-4.23076 | reward=0.12344\n",
      "[INFO]  epoch/step=164/31000 | loss=0.77302 | ploss=0.39022 | vloss=0.38689 | entropy=-4.21480 | reward=0.13156\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_164.ckpt\n",
      "[INFO]  epoch/step=165/31100 | loss=0.77499 | ploss=0.40689 | vloss=0.37218 | entropy=-4.20576 | reward=0.12625\n",
      "[INFO]  epoch/step=165/31200 | loss=0.82937 | ploss=0.43649 | vloss=0.39699 | entropy=-4.24328 | reward=0.13500\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_165.ckpt\n",
      "[INFO]  epoch/step=166/31300 | loss=0.81294 | ploss=0.43017 | vloss=0.38689 | entropy=-4.24752 | reward=0.13094\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_166.ckpt\n",
      "[INFO]  epoch/step=167/31400 | loss=0.87883 | ploss=0.45833 | vloss=0.42456 | entropy=-4.19585 | reward=0.14406\n",
      "[INFO]  epoch/step=167/31500 | loss=0.83919 | ploss=0.44074 | vloss=0.40251 | entropy=-4.19125 | reward=0.13687\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_167.ckpt\n",
      "[INFO]  epoch/step=168/31600 | loss=0.75023 | ploss=0.39038 | vloss=0.36391 | entropy=-4.19327 | reward=0.12344\n",
      "[INFO]  epoch/step=168/31700 | loss=0.81844 | ploss=0.42830 | vloss=0.39424 | entropy=-4.22306 | reward=0.13406\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_168.ckpt\n",
      "[INFO]  epoch/step=169/31800 | loss=0.80718 | ploss=0.42250 | vloss=0.38872 | entropy=-4.17544 | reward=0.13187\n",
      "[INFO]  epoch/step=169/31900 | loss=0.72577 | ploss=0.36684 | vloss=0.36299 | entropy=-4.19632 | reward=0.12344\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_169.ckpt\n",
      "[INFO]  epoch/step=170/32000 | loss=0.78990 | ploss=0.41992 | vloss=0.37402 | entropy=-4.17108 | reward=0.12687\n",
      "[INFO]  epoch/step=170/32100 | loss=0.81233 | ploss=0.43043 | vloss=0.38597 | entropy=-4.19525 | reward=0.13125\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_170.ckpt\n",
      "[INFO]  epoch/step=171/32200 | loss=0.74263 | ploss=0.38551 | vloss=0.36115 | entropy=-4.16677 | reward=0.12219\n",
      "[INFO]  epoch/step=171/32300 | loss=0.82076 | ploss=0.43144 | vloss=0.39332 | entropy=-4.12866 | reward=0.13375\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_171.ckpt\n",
      "[INFO]  epoch/step=172/32400 | loss=0.78560 | ploss=0.39995 | vloss=0.38964 | entropy=-4.12440 | reward=0.13219\n",
      "[INFO]  epoch/step=172/32500 | loss=0.77040 | ploss=0.39580 | vloss=0.37861 | entropy=-4.14341 | reward=0.12875\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_172.ckpt\n",
      "[INFO]  epoch/step=173/32600 | loss=0.79319 | ploss=0.40849 | vloss=0.38872 | entropy=-4.15953 | reward=0.13125\n",
      "[INFO]  epoch/step=173/32700 | loss=0.78865 | ploss=0.40210 | vloss=0.39056 | entropy=-4.15026 | reward=0.13281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_173.ckpt\n",
      "[INFO]  epoch/step=174/32800 | loss=0.83516 | ploss=0.42743 | vloss=0.41170 | entropy=-4.10167 | reward=0.13906\n",
      "[INFO]  epoch/step=174/32900 | loss=0.81016 | ploss=0.42544 | vloss=0.38872 | entropy=-4.13677 | reward=0.13156\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_174.ckpt\n",
      "[INFO]  epoch/step=175/33000 | loss=0.84973 | ploss=0.44292 | vloss=0.41078 | entropy=-4.10452 | reward=0.13969\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_175.ckpt\n",
      "[INFO]  epoch/step=176/33100 | loss=0.79364 | ploss=0.41530 | vloss=0.38229 | entropy=-4.08090 | reward=0.13000\n",
      "[INFO]  epoch/step=176/33200 | loss=0.78553 | ploss=0.40171 | vloss=0.38780 | entropy=-4.11786 | reward=0.13187\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_176.ckpt\n",
      "[INFO]  epoch/step=177/33300 | loss=0.84089 | ploss=0.44328 | vloss=0.40159 | entropy=-4.11564 | reward=0.13656\n",
      "[INFO]  epoch/step=177/33400 | loss=0.82524 | ploss=0.42854 | vloss=0.40067 | entropy=-4.10793 | reward=0.13625\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_177.ckpt\n",
      "[INFO]  epoch/step=178/33500 | loss=0.82169 | ploss=0.42219 | vloss=0.40343 | entropy=-4.06527 | reward=0.13687\n",
      "[INFO]  epoch/step=178/33600 | loss=0.78364 | ploss=0.38689 | vloss=0.40067 | entropy=-4.05778 | reward=0.13625\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_178.ckpt\n",
      "[INFO]  epoch/step=179/33700 | loss=0.80568 | ploss=0.41169 | vloss=0.39791 | entropy=-4.05317 | reward=0.13469\n",
      "[INFO]  epoch/step=179/33800 | loss=0.80603 | ploss=0.41578 | vloss=0.39424 | entropy=-4.12199 | reward=0.13406\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_179.ckpt\n",
      "[INFO]  epoch/step=180/33900 | loss=0.74648 | ploss=0.37549 | vloss=0.37494 | entropy=-4.08052 | reward=0.12687\n",
      "[INFO]  epoch/step=180/34000 | loss=0.80850 | ploss=0.41266 | vloss=0.39975 | entropy=-4.05416 | reward=0.13594\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_180.ckpt\n",
      "[INFO]  epoch/step=181/34100 | loss=0.80248 | ploss=0.41124 | vloss=0.39516 | entropy=-4.05387 | reward=0.13344\n",
      "[INFO]  epoch/step=181/34200 | loss=0.77034 | ploss=0.40392 | vloss=0.37034 | entropy=-4.06048 | reward=0.12594\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_181.ckpt\n",
      "[INFO]  epoch/step=182/34300 | loss=0.87071 | ploss=0.44082 | vloss=0.43375 | entropy=-4.00264 | reward=0.14625\n",
      "[INFO]  epoch/step=182/34400 | loss=0.81342 | ploss=0.41943 | vloss=0.39791 | entropy=-4.05666 | reward=0.13531\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_182.ckpt\n",
      "[INFO]  epoch/step=183/34500 | loss=0.79193 | ploss=0.39147 | vloss=0.40435 | entropy=-4.02396 | reward=0.13719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_183.ckpt\n",
      "[INFO]  epoch/step=184/34600 | loss=0.80353 | ploss=0.41507 | vloss=0.39240 | entropy=-4.07865 | reward=0.13250\n",
      "[INFO]  epoch/step=184/34700 | loss=0.80789 | ploss=0.40838 | vloss=0.40343 | entropy=-4.04945 | reward=0.13719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_184.ckpt\n",
      "[INFO]  epoch/step=185/34800 | loss=0.80892 | ploss=0.40662 | vloss=0.40618 | entropy=-4.02119 | reward=0.13781\n",
      "[INFO]  epoch/step=185/34900 | loss=0.84843 | ploss=0.42496 | vloss=0.42732 | entropy=-3.98429 | reward=0.14531\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_185.ckpt\n",
      "[INFO]  epoch/step=186/35000 | loss=0.81238 | ploss=0.40733 | vloss=0.40894 | entropy=-4.02796 | reward=0.13812\n",
      "[INFO]  epoch/step=186/35100 | loss=0.78521 | ploss=0.39208 | vloss=0.39699 | entropy=-4.00556 | reward=0.13500\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_186.ckpt\n",
      "[INFO]  epoch/step=187/35200 | loss=0.80243 | ploss=0.40648 | vloss=0.39975 | entropy=-3.94540 | reward=0.13500\n",
      "[INFO]  epoch/step=187/35300 | loss=0.91915 | ploss=0.47640 | vloss=0.44662 | entropy=-4.00435 | reward=0.15188\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_187.ckpt\n",
      "[INFO]  epoch/step=188/35400 | loss=0.83197 | ploss=0.41585 | vloss=0.41997 | entropy=-3.98104 | reward=0.14250\n",
      "[INFO]  epoch/step=188/35500 | loss=0.83644 | ploss=0.43504 | vloss=0.40526 | entropy=-4.00337 | reward=0.13781\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_188.ckpt\n",
      "[INFO]  epoch/step=189/35600 | loss=0.76967 | ploss=0.38662 | vloss=0.38689 | entropy=-3.97146 | reward=0.13094\n",
      "[INFO]  epoch/step=189/35700 | loss=0.72657 | ploss=0.36746 | vloss=0.36299 | entropy=-4.02844 | reward=0.12344\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_189.ckpt\n",
      "[INFO]  epoch/step=190/35800 | loss=0.88068 | ploss=0.44249 | vloss=0.44202 | entropy=-3.97084 | reward=0.14781\n",
      "[INFO]  epoch/step=190/35900 | loss=0.90130 | ploss=0.45944 | vloss=0.44570 | entropy=-3.98267 | reward=0.15156\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_190.ckpt\n",
      "[INFO]  epoch/step=191/36000 | loss=0.83606 | ploss=0.41992 | vloss=0.41997 | entropy=-3.96692 | reward=0.14219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_191.ckpt\n",
      "[INFO]  epoch/step=192/36100 | loss=0.83631 | ploss=0.42659 | vloss=0.41354 | entropy=-3.95735 | reward=0.13969\n",
      "[INFO]  epoch/step=192/36200 | loss=0.81532 | ploss=0.40373 | vloss=0.41537 | entropy=-3.92222 | reward=0.14125\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_192.ckpt\n",
      "[INFO]  epoch/step=193/36300 | loss=0.78000 | ploss=0.39323 | vloss=0.39056 | entropy=-3.93059 | reward=0.13187\n",
      "[INFO]  epoch/step=193/36400 | loss=0.88284 | ploss=0.44273 | vloss=0.44386 | entropy=-3.89555 | reward=0.15094\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_193.ckpt\n",
      "[INFO]  epoch/step=194/36500 | loss=0.78976 | ploss=0.39563 | vloss=0.39791 | entropy=-3.92573 | reward=0.13531\n",
      "[INFO]  epoch/step=194/36600 | loss=0.80462 | ploss=0.40222 | vloss=0.40618 | entropy=-3.92628 | reward=0.13812\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_194.ckpt\n",
      "[INFO]  epoch/step=195/36700 | loss=0.84997 | ploss=0.42276 | vloss=0.43100 | entropy=-3.92887 | reward=0.14563\n",
      "[INFO]  epoch/step=195/36800 | loss=0.84741 | ploss=0.42386 | vloss=0.42732 | entropy=-3.91844 | reward=0.14531\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_195.ckpt\n",
      "[INFO]  epoch/step=196/36900 | loss=0.81628 | ploss=0.40284 | vloss=0.41721 | entropy=-3.91714 | reward=0.14156\n",
      "[INFO]  epoch/step=196/37000 | loss=0.83802 | ploss=0.41812 | vloss=0.42364 | entropy=-3.89515 | reward=0.14406\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_196.ckpt\n",
      "[INFO]  epoch/step=197/37100 | loss=0.80076 | ploss=0.39559 | vloss=0.40894 | entropy=-3.91412 | reward=0.13875\n",
      "[INFO]  epoch/step=197/37200 | loss=0.83484 | ploss=0.40667 | vloss=0.43191 | entropy=-3.89228 | reward=0.14688\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_197.ckpt\n",
      "[INFO]  epoch/step=198/37300 | loss=0.70894 | ploss=0.34602 | vloss=0.36667 | entropy=-3.89898 | reward=0.12469\n",
      "[INFO]  epoch/step=198/37400 | loss=0.88156 | ploss=0.44233 | vloss=0.44294 | entropy=-3.85870 | reward=0.15063\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_198.ckpt\n",
      "[INFO]  epoch/step=199/37500 | loss=0.77628 | ploss=0.38303 | vloss=0.39699 | entropy=-3.89107 | reward=0.13469\n",
      "[INFO]  epoch/step=199/37600 | loss=0.90500 | ploss=0.44834 | vloss=0.46040 | entropy=-3.88232 | reward=0.15563\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_199.ckpt\n",
      "[INFO]  epoch/step=200/37700 | loss=0.79182 | ploss=0.38293 | vloss=0.41262 | entropy=-3.87569 | reward=0.14031\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_200.ckpt\n",
      "[INFO]  epoch/step=201/37800 | loss=0.80626 | ploss=0.39464 | vloss=0.41537 | entropy=-3.90713 | reward=0.14031\n",
      "[INFO]  epoch/step=201/37900 | loss=0.78223 | ploss=0.38438 | vloss=0.40159 | entropy=-3.88178 | reward=0.13656\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_201.ckpt\n",
      "[INFO]  epoch/step=202/38000 | loss=0.77854 | ploss=0.37605 | vloss=0.40618 | entropy=-3.83757 | reward=0.13750\n",
      "[INFO]  epoch/step=202/38100 | loss=0.81283 | ploss=0.40851 | vloss=0.40802 | entropy=-3.84404 | reward=0.13875\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_202.ckpt\n",
      "[INFO]  epoch/step=203/38200 | loss=0.77792 | ploss=0.36809 | vloss=0.41354 | entropy=-3.84561 | reward=0.14000\n",
      "[INFO]  epoch/step=203/38300 | loss=0.80717 | ploss=0.40101 | vloss=0.40986 | entropy=-3.84265 | reward=0.13937\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_203.ckpt\n",
      "[INFO]  epoch/step=204/38400 | loss=0.87234 | ploss=0.42203 | vloss=0.45397 | entropy=-3.80419 | reward=0.15344\n",
      "[INFO]  epoch/step=204/38500 | loss=0.83666 | ploss=0.41023 | vloss=0.43008 | entropy=-3.79370 | reward=0.14625\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_204.ckpt\n",
      "[INFO]  epoch/step=205/38600 | loss=0.89845 | ploss=0.44814 | vloss=0.45397 | entropy=-3.80821 | reward=0.15344\n",
      "[INFO]  epoch/step=205/38700 | loss=0.76819 | ploss=0.37853 | vloss=0.39332 | entropy=-3.80906 | reward=0.13375\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_205.ckpt\n",
      "[INFO]  epoch/step=206/38800 | loss=0.85410 | ploss=0.42214 | vloss=0.43559 | entropy=-3.78029 | reward=0.14750\n",
      "[INFO]  epoch/step=206/38900 | loss=0.77076 | ploss=0.37561 | vloss=0.39883 | entropy=-3.83743 | reward=0.13562\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_206.ckpt\n",
      "[INFO]  epoch/step=207/39000 | loss=0.78096 | ploss=0.37841 | vloss=0.40618 | entropy=-3.78273 | reward=0.13750\n",
      "[INFO]  epoch/step=207/39100 | loss=0.83015 | ploss=0.40101 | vloss=0.43283 | entropy=-3.84059 | reward=0.14719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_207.ckpt\n",
      "[INFO]  epoch/step=208/39200 | loss=0.78449 | ploss=0.38285 | vloss=0.40526 | entropy=-3.77878 | reward=0.13750\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_208.ckpt\n",
      "[INFO]  epoch/step=209/39300 | loss=0.85106 | ploss=0.42183 | vloss=0.43283 | entropy=-3.75541 | reward=0.14656\n",
      "[INFO]  epoch/step=209/39400 | loss=0.85280 | ploss=0.41346 | vloss=0.44294 | entropy=-3.75250 | reward=0.15063\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_209.ckpt\n",
      "[INFO]  epoch/step=210/39500 | loss=0.88236 | ploss=0.42373 | vloss=0.46224 | entropy=-3.75904 | reward=0.15687\n",
      "[INFO]  epoch/step=210/39600 | loss=0.84794 | ploss=0.40957 | vloss=0.44202 | entropy=-3.80472 | reward=0.15031\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_210.ckpt\n",
      "[INFO]  epoch/step=211/39700 | loss=0.81555 | ploss=0.39556 | vloss=0.42364 | entropy=-3.80862 | reward=0.14313\n",
      "[INFO]  epoch/step=211/39800 | loss=0.72368 | ploss=0.34318 | vloss=0.38413 | entropy=-3.77830 | reward=0.13062\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_211.ckpt\n",
      "[INFO]  epoch/step=212/39900 | loss=0.85203 | ploss=0.40991 | vloss=0.44570 | entropy=-3.73599 | reward=0.15094\n",
      "[INFO]  epoch/step=212/40000 | loss=0.84622 | ploss=0.40686 | vloss=0.44294 | entropy=-3.73519 | reward=0.15063\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_212.ckpt\n",
      "[INFO]  epoch/step=213/40100 | loss=0.81464 | ploss=0.39366 | vloss=0.42456 | entropy=-3.73606 | reward=0.14406\n",
      "[INFO]  epoch/step=213/40200 | loss=0.87921 | ploss=0.42329 | vloss=0.45948 | entropy=-3.72143 | reward=0.15625\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_213.ckpt\n",
      "[INFO]  epoch/step=214/40300 | loss=0.83325 | ploss=0.40490 | vloss=0.43191 | entropy=-3.72192 | reward=0.14688\n",
      "[INFO]  epoch/step=214/40400 | loss=0.84845 | ploss=0.40445 | vloss=0.44754 | entropy=-3.69946 | reward=0.15219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_214.ckpt\n",
      "[INFO]  epoch/step=215/40500 | loss=0.85605 | ploss=0.41946 | vloss=0.44019 | entropy=-3.74640 | reward=0.14906\n",
      "[INFO]  epoch/step=215/40600 | loss=0.83359 | ploss=0.39513 | vloss=0.44202 | entropy=-3.71525 | reward=0.15031\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_215.ckpt\n",
      "[INFO]  epoch/step=216/40700 | loss=0.83798 | ploss=0.40596 | vloss=0.43559 | entropy=-3.72222 | reward=0.14719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_216.ckpt\n",
      "[INFO]  epoch/step=217/40800 | loss=0.91317 | ploss=0.43887 | vloss=0.47786 | entropy=-3.71657 | reward=0.16219\n",
      "[INFO]  epoch/step=217/40900 | loss=0.85175 | ploss=0.40960 | vloss=0.44570 | entropy=-3.70485 | reward=0.15156\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_217.ckpt\n",
      "[INFO]  epoch/step=218/41000 | loss=0.78103 | ploss=0.37281 | vloss=0.41170 | entropy=-3.63411 | reward=0.13969\n",
      "[INFO]  epoch/step=218/41100 | loss=0.79843 | ploss=0.38199 | vloss=0.41997 | entropy=-3.68723 | reward=0.14281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_218.ckpt\n",
      "[INFO]  epoch/step=219/41200 | loss=0.88523 | ploss=0.42283 | vloss=0.46592 | entropy=-3.67109 | reward=0.15781\n",
      "[INFO]  epoch/step=219/41300 | loss=0.82157 | ploss=0.39499 | vloss=0.43008 | entropy=-3.66164 | reward=0.14625\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_219.ckpt\n",
      "[INFO]  epoch/step=220/41400 | loss=0.89136 | ploss=0.42895 | vloss=0.46592 | entropy=-3.66308 | reward=0.15750\n",
      "[INFO]  epoch/step=220/41500 | loss=0.85883 | ploss=0.40469 | vloss=0.45765 | entropy=-3.66705 | reward=0.15563\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_220.ckpt\n",
      "[INFO]  epoch/step=221/41600 | loss=0.89117 | ploss=0.42235 | vloss=0.47235 | entropy=-3.69068 | reward=0.15906\n",
      "[INFO]  epoch/step=221/41700 | loss=0.87236 | ploss=0.42561 | vloss=0.45029 | entropy=-3.69609 | reward=0.15313\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_221.ckpt\n",
      "[INFO]  epoch/step=222/41800 | loss=0.77469 | ploss=0.35730 | vloss=0.42089 | entropy=-3.65761 | reward=0.14250\n",
      "[INFO]  epoch/step=222/41900 | loss=0.82580 | ploss=0.38266 | vloss=0.44662 | entropy=-3.63297 | reward=0.15188\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_222.ckpt\n",
      "[INFO]  epoch/step=223/42000 | loss=0.95704 | ploss=0.45597 | vloss=0.50451 | entropy=-3.59844 | reward=0.17125\n",
      "[INFO]  epoch/step=223/42100 | loss=0.83067 | ploss=0.39396 | vloss=0.44019 | entropy=-3.63812 | reward=0.14969\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_223.ckpt\n",
      "[INFO]  epoch/step=224/42200 | loss=0.86765 | ploss=0.41810 | vloss=0.45305 | entropy=-3.65623 | reward=0.15313\n",
      "[INFO]  epoch/step=224/42300 | loss=0.78741 | ploss=0.36173 | vloss=0.42916 | entropy=-3.64467 | reward=0.14531\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_224.ckpt\n",
      "[INFO]  epoch/step=225/42400 | loss=0.90870 | ploss=0.43249 | vloss=0.47970 | entropy=-3.64733 | reward=0.16312\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_225.ckpt\n",
      "[INFO]  epoch/step=226/42500 | loss=0.84589 | ploss=0.40644 | vloss=0.44294 | entropy=-3.64906 | reward=0.14938\n",
      "[INFO]  epoch/step=226/42600 | loss=0.93024 | ploss=0.43378 | vloss=0.49992 | entropy=-3.61568 | reward=0.17000\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_226.ckpt\n",
      "[INFO]  epoch/step=227/42700 | loss=0.85966 | ploss=0.41195 | vloss=0.45121 | entropy=-3.65767 | reward=0.15313\n",
      "[INFO]  epoch/step=227/42800 | loss=0.84430 | ploss=0.39653 | vloss=0.45121 | entropy=-3.60510 | reward=0.15344\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_227.ckpt\n",
      "[INFO]  epoch/step=228/42900 | loss=0.86811 | ploss=0.42131 | vloss=0.45029 | entropy=-3.65394 | reward=0.15188\n",
      "[INFO]  epoch/step=228/43000 | loss=0.82944 | ploss=0.38166 | vloss=0.45121 | entropy=-3.59780 | reward=0.15344\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_228.ckpt\n",
      "[INFO]  epoch/step=229/43100 | loss=0.85671 | ploss=0.40156 | vloss=0.45856 | entropy=-3.57553 | reward=0.15531\n",
      "[INFO]  epoch/step=229/43200 | loss=0.90041 | ploss=0.42324 | vloss=0.48062 | entropy=-3.61076 | reward=0.16344\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_229.ckpt\n",
      "[INFO]  epoch/step=230/43300 | loss=0.84900 | ploss=0.39847 | vloss=0.45397 | entropy=-3.60275 | reward=0.15344\n",
      "[INFO]  epoch/step=230/43400 | loss=0.90495 | ploss=0.43327 | vloss=0.47511 | entropy=-3.58942 | reward=0.16156\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_230.ckpt\n",
      "[INFO]  epoch/step=231/43500 | loss=0.92072 | ploss=0.43892 | vloss=0.48521 | entropy=-3.58435 | reward=0.16344\n",
      "[INFO]  epoch/step=231/43600 | loss=0.82603 | ploss=0.38652 | vloss=0.44294 | entropy=-3.59860 | reward=0.15063\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_231.ckpt\n",
      "[INFO]  epoch/step=232/43700 | loss=0.86736 | ploss=0.39380 | vloss=0.47694 | entropy=-3.55015 | reward=0.16094\n",
      "[INFO]  epoch/step=232/43800 | loss=0.82637 | ploss=0.38406 | vloss=0.44570 | entropy=-3.55740 | reward=0.15156\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_232.ckpt\n",
      "[INFO]  epoch/step=233/43900 | loss=0.83452 | ploss=0.38114 | vloss=0.45673 | entropy=-3.50722 | reward=0.15469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_233.ckpt\n",
      "[INFO]  epoch/step=234/44000 | loss=0.85054 | ploss=0.40274 | vloss=0.45121 | entropy=-3.57746 | reward=0.15219\n",
      "[INFO]  epoch/step=234/44100 | loss=0.89120 | ploss=0.41488 | vloss=0.47970 | entropy=-3.54700 | reward=0.16312\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_234.ckpt\n",
      "[INFO]  epoch/step=235/44200 | loss=0.84777 | ploss=0.40366 | vloss=0.44754 | entropy=-3.59624 | reward=0.15156\n",
      "[INFO]  epoch/step=235/44300 | loss=0.86833 | ploss=0.40393 | vloss=0.46775 | entropy=-3.52311 | reward=0.15906\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_235.ckpt\n",
      "[INFO]  epoch/step=236/44400 | loss=0.85147 | ploss=0.39995 | vloss=0.45489 | entropy=-3.53203 | reward=0.15375\n",
      "[INFO]  epoch/step=236/44500 | loss=0.79930 | ploss=0.36982 | vloss=0.43283 | entropy=-3.52341 | reward=0.14719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_236.ckpt\n",
      "[INFO]  epoch/step=237/44600 | loss=0.83947 | ploss=0.39993 | vloss=0.44294 | entropy=-3.56309 | reward=0.14969\n",
      "[INFO]  epoch/step=237/44700 | loss=0.89210 | ploss=0.40748 | vloss=0.48797 | entropy=-3.51495 | reward=0.16594\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_237.ckpt\n",
      "[INFO]  epoch/step=238/44800 | loss=0.88425 | ploss=0.40053 | vloss=0.48705 | entropy=-3.50074 | reward=0.16500\n",
      "[INFO]  epoch/step=238/44900 | loss=0.83059 | ploss=0.37811 | vloss=0.45581 | entropy=-3.49356 | reward=0.15500\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_238.ckpt\n",
      "[INFO]  epoch/step=239/45000 | loss=0.88208 | ploss=0.41127 | vloss=0.47419 | entropy=-3.54170 | reward=0.16062\n",
      "[INFO]  epoch/step=239/45100 | loss=0.85929 | ploss=0.38747 | vloss=0.47511 | entropy=-3.45913 | reward=0.16156\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_239.ckpt\n",
      "[INFO]  epoch/step=240/45200 | loss=0.90403 | ploss=0.41478 | vloss=0.49257 | entropy=-3.48641 | reward=0.16719\n",
      "[INFO]  epoch/step=240/45300 | loss=0.85518 | ploss=0.39260 | vloss=0.46592 | entropy=-3.50775 | reward=0.15844\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_240.ckpt\n",
      "[INFO]  epoch/step=241/45400 | loss=0.79630 | ploss=0.36221 | vloss=0.43743 | entropy=-3.50249 | reward=0.14750\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_241.ckpt\n",
      "[INFO]  epoch/step=242/45500 | loss=0.90625 | ploss=0.41789 | vloss=0.49165 | entropy=-3.44680 | reward=0.16656\n",
      "[INFO]  epoch/step=242/45600 | loss=0.87690 | ploss=0.39772 | vloss=0.48246 | entropy=-3.44239 | reward=0.16406\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_242.ckpt\n",
      "[INFO]  epoch/step=243/45700 | loss=0.85572 | ploss=0.39862 | vloss=0.46040 | entropy=-3.47726 | reward=0.15500\n",
      "[INFO]  epoch/step=243/45800 | loss=0.86144 | ploss=0.40158 | vloss=0.46316 | entropy=-3.46591 | reward=0.15750\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_243.ckpt\n",
      "[INFO]  epoch/step=244/45900 | loss=0.83419 | ploss=0.38538 | vloss=0.45213 | entropy=-3.48373 | reward=0.15344\n",
      "[INFO]  epoch/step=244/46000 | loss=0.81689 | ploss=0.38276 | vloss=0.43743 | entropy=-3.46848 | reward=0.14875\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_244.ckpt\n",
      "[INFO]  epoch/step=245/46100 | loss=0.86105 | ploss=0.39381 | vloss=0.47051 | entropy=-3.44641 | reward=0.15969\n",
      "[INFO]  epoch/step=245/46200 | loss=0.90483 | ploss=0.41923 | vloss=0.48889 | entropy=-3.45919 | reward=0.16625\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_245.ckpt\n",
      "[INFO]  epoch/step=246/46300 | loss=0.93262 | ploss=0.42952 | vloss=0.50635 | entropy=-3.42496 | reward=0.17188\n",
      "[INFO]  epoch/step=246/46400 | loss=0.86397 | ploss=0.39765 | vloss=0.46959 | entropy=-3.44343 | reward=0.15969\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_246.ckpt\n",
      "[INFO]  epoch/step=247/46500 | loss=0.86006 | ploss=0.39648 | vloss=0.46684 | entropy=-3.42042 | reward=0.15812\n",
      "[INFO]  epoch/step=247/46600 | loss=0.86911 | ploss=0.39816 | vloss=0.47419 | entropy=-3.41036 | reward=0.16125\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_247.ckpt\n",
      "[INFO]  epoch/step=248/46700 | loss=0.79476 | ploss=0.35231 | vloss=0.44570 | entropy=-3.41788 | reward=0.15031\n",
      "[INFO]  epoch/step=248/46800 | loss=0.90299 | ploss=0.41641 | vloss=0.48981 | entropy=-3.40393 | reward=0.16656\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_248.ckpt\n",
      "[INFO]  epoch/step=249/46900 | loss=0.86901 | ploss=0.40082 | vloss=0.47143 | entropy=-3.41682 | reward=0.15937\n",
      "[INFO]  epoch/step=249/47000 | loss=0.89557 | ploss=0.41730 | vloss=0.48154 | entropy=-3.44660 | reward=0.16344\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_249.ckpt\n",
      "[INFO]  epoch/step=250/47100 | loss=0.78586 | ploss=0.35073 | vloss=0.43835 | entropy=-3.38861 | reward=0.14906\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_250.ckpt\n",
      "[INFO]  epoch/step=251/47200 | loss=0.87666 | ploss=0.40021 | vloss=0.47970 | entropy=-3.42595 | reward=0.16187\n",
      "[INFO]  epoch/step=251/47300 | loss=0.80723 | ploss=0.36292 | vloss=0.44754 | entropy=-3.39723 | reward=0.15219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_251.ckpt\n",
      "[INFO]  epoch/step=252/47400 | loss=0.83656 | ploss=0.38770 | vloss=0.45213 | entropy=-3.43903 | reward=0.15344\n",
      "[INFO]  epoch/step=252/47500 | loss=0.94283 | ploss=0.43603 | vloss=0.51003 | entropy=-3.39895 | reward=0.17344\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_252.ckpt\n",
      "[INFO]  epoch/step=253/47600 | loss=0.85367 | ploss=0.37996 | vloss=0.47694 | entropy=-3.40173 | reward=0.16187\n",
      "[INFO]  epoch/step=253/47700 | loss=0.89310 | ploss=0.40649 | vloss=0.48981 | entropy=-3.37815 | reward=0.16656\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_253.ckpt\n",
      "[INFO]  epoch/step=254/47800 | loss=0.83156 | ploss=0.37806 | vloss=0.45673 | entropy=-3.40633 | reward=0.15406\n",
      "[INFO]  epoch/step=254/47900 | loss=0.89704 | ploss=0.40770 | vloss=0.49257 | entropy=-3.40069 | reward=0.16750\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_254.ckpt\n",
      "[INFO]  epoch/step=255/48000 | loss=0.91633 | ploss=0.40859 | vloss=0.51095 | entropy=-3.37943 | reward=0.17219\n",
      "[INFO]  epoch/step=255/48100 | loss=0.88391 | ploss=0.39913 | vloss=0.48797 | entropy=-3.36331 | reward=0.16594\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_255.ckpt\n",
      "[INFO]  epoch/step=256/48200 | loss=0.89188 | ploss=0.40163 | vloss=0.49349 | entropy=-3.40613 | reward=0.16719\n",
      "[INFO]  epoch/step=256/48300 | loss=0.82037 | ploss=0.36041 | vloss=0.46316 | entropy=-3.37400 | reward=0.15750\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_256.ckpt\n",
      "[INFO]  epoch/step=257/48400 | loss=0.88019 | ploss=0.40090 | vloss=0.48246 | entropy=-3.34758 | reward=0.16344\n",
      "[INFO]  epoch/step=257/48500 | loss=0.81223 | ploss=0.36697 | vloss=0.44846 | entropy=-3.37530 | reward=0.15250\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_257.ckpt\n",
      "[INFO]  epoch/step=258/48600 | loss=0.83631 | ploss=0.37080 | vloss=0.46867 | entropy=-3.34726 | reward=0.15906\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_258.ckpt\n",
      "[INFO]  epoch/step=259/48700 | loss=0.94658 | ploss=0.43424 | vloss=0.51554 | entropy=-3.38227 | reward=0.17438\n",
      "[INFO]  epoch/step=259/48800 | loss=0.91522 | ploss=0.40836 | vloss=0.51003 | entropy=-3.33670 | reward=0.17344\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_259.ckpt\n",
      "[INFO]  epoch/step=260/48900 | loss=0.81210 | ploss=0.38153 | vloss=0.43375 | entropy=-3.35771 | reward=0.14625\n",
      "[INFO]  epoch/step=260/49000 | loss=0.88991 | ploss=0.40327 | vloss=0.48981 | entropy=-3.33970 | reward=0.16656\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_260.ckpt\n",
      "[INFO]  epoch/step=261/49100 | loss=0.90708 | ploss=0.40482 | vloss=0.50543 | entropy=-3.35525 | reward=0.17062\n",
      "[INFO]  epoch/step=261/49200 | loss=0.89699 | ploss=0.41219 | vloss=0.48797 | entropy=-3.34672 | reward=0.16594\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_261.ckpt\n",
      "[INFO]  epoch/step=262/49300 | loss=0.83025 | ploss=0.37117 | vloss=0.46224 | entropy=-3.33177 | reward=0.15594\n",
      "[INFO]  epoch/step=262/49400 | loss=0.87144 | ploss=0.39306 | vloss=0.48154 | entropy=-3.33425 | reward=0.16375\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_262.ckpt\n",
      "[INFO]  epoch/step=263/49500 | loss=0.91892 | ploss=0.42122 | vloss=0.50084 | entropy=-3.31103 | reward=0.16906\n",
      "[INFO]  epoch/step=263/49600 | loss=0.81132 | ploss=0.36048 | vloss=0.45397 | entropy=-3.31148 | reward=0.15438\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_263.ckpt\n",
      "[INFO]  epoch/step=264/49700 | loss=0.90078 | ploss=0.40585 | vloss=0.49808 | entropy=-3.32330 | reward=0.16750\n",
      "[INFO]  epoch/step=264/49800 | loss=0.88763 | ploss=0.39910 | vloss=0.49165 | entropy=-3.29967 | reward=0.16719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_264.ckpt\n",
      "[INFO]  epoch/step=265/49900 | loss=0.88379 | ploss=0.39437 | vloss=0.49257 | entropy=-3.33102 | reward=0.16719\n",
      "[INFO]  epoch/step=265/50000 | loss=0.87671 | ploss=0.38912 | vloss=0.49073 | entropy=-3.31593 | reward=0.16687\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_265.ckpt\n",
      "[INFO]  epoch/step=266/50100 | loss=0.91619 | ploss=0.40838 | vloss=0.51095 | entropy=-3.31571 | reward=0.17281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_266.ckpt\n",
      "[INFO]  epoch/step=267/50200 | loss=0.86825 | ploss=0.38159 | vloss=0.48981 | entropy=-3.32375 | reward=0.16594\n",
      "[INFO]  epoch/step=267/50300 | loss=0.81334 | ploss=0.34134 | vloss=0.47511 | entropy=-3.28613 | reward=0.16156\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_267.ckpt\n",
      "[INFO]  epoch/step=268/50400 | loss=0.89319 | ploss=0.40923 | vloss=0.48705 | entropy=-3.26620 | reward=0.16531\n",
      "[INFO]  epoch/step=268/50500 | loss=0.86497 | ploss=0.37364 | vloss=0.49440 | entropy=-3.25261 | reward=0.16812\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_268.ckpt\n",
      "[INFO]  epoch/step=269/50600 | loss=0.83664 | ploss=0.36551 | vloss=0.47419 | entropy=-3.23654 | reward=0.16000\n",
      "[INFO]  epoch/step=269/50700 | loss=0.85490 | ploss=0.37371 | vloss=0.48430 | entropy=-3.28778 | reward=0.16469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_269.ckpt\n",
      "[INFO]  epoch/step=270/50800 | loss=0.86933 | ploss=0.38354 | vloss=0.48889 | entropy=-3.27708 | reward=0.16594\n",
      "[INFO]  epoch/step=270/50900 | loss=0.88296 | ploss=0.39254 | vloss=0.49349 | entropy=-3.24745 | reward=0.16781\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_270.ckpt\n",
      "[INFO]  epoch/step=271/51000 | loss=0.89415 | ploss=0.39917 | vloss=0.49808 | entropy=-3.27638 | reward=0.16812\n",
      "[INFO]  epoch/step=271/51100 | loss=0.82767 | ploss=0.36023 | vloss=0.47051 | entropy=-3.25751 | reward=0.16000\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_271.ckpt\n",
      "[INFO]  epoch/step=272/51200 | loss=0.87634 | ploss=0.37951 | vloss=0.49992 | entropy=-3.26498 | reward=0.16812\n",
      "[INFO]  epoch/step=272/51300 | loss=0.87941 | ploss=0.39633 | vloss=0.48613 | entropy=-3.23374 | reward=0.16531\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_272.ckpt\n",
      "[INFO]  epoch/step=273/51400 | loss=0.92041 | ploss=0.40609 | vloss=0.51738 | entropy=-3.24765 | reward=0.17469\n",
      "[INFO]  epoch/step=273/51500 | loss=0.82635 | ploss=0.35796 | vloss=0.47143 | entropy=-3.22513 | reward=0.16031\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_273.ckpt\n",
      "[INFO]  epoch/step=274/51600 | loss=0.88103 | ploss=0.38692 | vloss=0.49716 | entropy=-3.24058 | reward=0.16844\n",
      "[INFO]  epoch/step=274/51700 | loss=0.84611 | ploss=0.36668 | vloss=0.48246 | entropy=-3.21330 | reward=0.16406\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_274.ckpt\n",
      "[INFO]  epoch/step=275/51800 | loss=0.84625 | ploss=0.37051 | vloss=0.47878 | entropy=-3.22738 | reward=0.16281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_275.ckpt\n",
      "[INFO]  epoch/step=276/51900 | loss=0.83737 | ploss=0.36162 | vloss=0.47878 | entropy=-3.21409 | reward=0.16187\n",
      "[INFO]  epoch/step=276/52000 | loss=0.93557 | ploss=0.42304 | vloss=0.51554 | entropy=-3.19836 | reward=0.17531\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_276.ckpt\n",
      "[INFO]  epoch/step=277/52100 | loss=0.93418 | ploss=0.41798 | vloss=0.51922 | entropy=-3.21024 | reward=0.17594\n",
      "[INFO]  epoch/step=277/52200 | loss=0.88389 | ploss=0.39067 | vloss=0.49624 | entropy=-3.20787 | reward=0.16875\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_277.ckpt\n",
      "[INFO]  epoch/step=278/52300 | loss=0.88831 | ploss=0.39510 | vloss=0.49624 | entropy=-3.21559 | reward=0.16750\n",
      "[INFO]  epoch/step=278/52400 | loss=0.92408 | ploss=0.39775 | vloss=0.52933 | entropy=-3.17839 | reward=0.18000\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_278.ckpt\n",
      "[INFO]  epoch/step=279/52500 | loss=0.91391 | ploss=0.40509 | vloss=0.51186 | entropy=-3.22909 | reward=0.17313\n",
      "[INFO]  epoch/step=279/52600 | loss=0.87101 | ploss=0.38235 | vloss=0.49165 | entropy=-3.17205 | reward=0.16719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_279.ckpt\n",
      "[INFO]  epoch/step=280/52700 | loss=0.84975 | ploss=0.36575 | vloss=0.48705 | entropy=-3.23509 | reward=0.16469\n",
      "[INFO]  epoch/step=280/52800 | loss=0.87906 | ploss=0.37752 | vloss=0.50451 | entropy=-3.16852 | reward=0.17156\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_280.ckpt\n",
      "[INFO]  epoch/step=281/52900 | loss=0.83681 | ploss=0.35921 | vloss=0.48062 | entropy=-3.20186 | reward=0.16250\n",
      "[INFO]  epoch/step=281/53000 | loss=0.85233 | ploss=0.37107 | vloss=0.48430 | entropy=-3.21629 | reward=0.16469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_281.ckpt\n",
      "[INFO]  epoch/step=282/53100 | loss=0.87673 | ploss=0.37983 | vloss=0.49992 | entropy=-3.20158 | reward=0.16906\n",
      "[INFO]  epoch/step=282/53200 | loss=0.85052 | ploss=0.36552 | vloss=0.48797 | entropy=-3.15628 | reward=0.16594\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_282.ckpt\n",
      "[INFO]  epoch/step=283/53300 | loss=0.94861 | ploss=0.41859 | vloss=0.53300 | entropy=-3.17588 | reward=0.18063\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_283.ckpt\n",
      "[INFO]  epoch/step=284/53400 | loss=0.95106 | ploss=0.41274 | vloss=0.54127 | entropy=-3.13892 | reward=0.18250\n",
      "[INFO]  epoch/step=284/53500 | loss=0.83764 | ploss=0.36737 | vloss=0.47327 | entropy=-3.18154 | reward=0.16094\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_284.ckpt\n",
      "[INFO]  epoch/step=285/53600 | loss=0.87043 | ploss=0.37439 | vloss=0.49900 | entropy=-3.14931 | reward=0.16906\n",
      "[INFO]  epoch/step=285/53700 | loss=0.86523 | ploss=0.37197 | vloss=0.49624 | entropy=-3.17223 | reward=0.16875\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_285.ckpt\n",
      "[INFO]  epoch/step=286/53800 | loss=0.93003 | ploss=0.40089 | vloss=0.53208 | entropy=-3.12846 | reward=0.18000\n",
      "[INFO]  epoch/step=286/53900 | loss=0.90617 | ploss=0.38808 | vloss=0.52105 | entropy=-3.15570 | reward=0.17719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_286.ckpt\n",
      "[INFO]  epoch/step=287/54000 | loss=0.85094 | ploss=0.37979 | vloss=0.47419 | entropy=-3.23372 | reward=0.16094\n",
      "[INFO]  epoch/step=287/54100 | loss=0.87146 | ploss=0.37175 | vloss=0.50268 | entropy=-3.15385 | reward=0.17094\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_287.ckpt\n",
      "[INFO]  epoch/step=288/54200 | loss=0.91086 | ploss=0.40013 | vloss=0.51370 | entropy=-3.16206 | reward=0.17375\n",
      "[INFO]  epoch/step=288/54300 | loss=0.88945 | ploss=0.39614 | vloss=0.49624 | entropy=-3.12550 | reward=0.16875\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_288.ckpt\n",
      "[INFO]  epoch/step=289/54400 | loss=0.90341 | ploss=0.38159 | vloss=0.52473 | entropy=-3.09776 | reward=0.17719\n",
      "[INFO]  epoch/step=289/54500 | loss=0.90203 | ploss=0.39587 | vloss=0.50911 | entropy=-3.13727 | reward=0.17313\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_289.ckpt\n",
      "[INFO]  epoch/step=290/54600 | loss=0.83231 | ploss=0.35276 | vloss=0.48246 | entropy=-3.09744 | reward=0.16375\n",
      "[INFO]  epoch/step=290/54700 | loss=0.93708 | ploss=0.41530 | vloss=0.52473 | entropy=-3.14886 | reward=0.17844\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_290.ckpt\n",
      "[INFO]  epoch/step=291/54800 | loss=0.88459 | ploss=0.37199 | vloss=0.51554 | entropy=-3.12765 | reward=0.17469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_291.ckpt\n",
      "[INFO]  epoch/step=292/54900 | loss=0.90316 | ploss=0.39697 | vloss=0.50911 | entropy=-3.11005 | reward=0.17313\n",
      "[INFO]  epoch/step=292/55000 | loss=0.87037 | ploss=0.37707 | vloss=0.49624 | entropy=-3.12794 | reward=0.16875\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_292.ckpt\n",
      "[INFO]  epoch/step=293/55100 | loss=0.87995 | ploss=0.38292 | vloss=0.49992 | entropy=-3.08017 | reward=0.16969\n",
      "[INFO]  epoch/step=293/55200 | loss=0.86073 | ploss=0.36743 | vloss=0.49624 | entropy=-3.13266 | reward=0.16875\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_293.ckpt\n",
      "[INFO]  epoch/step=294/55300 | loss=0.85529 | ploss=0.36198 | vloss=0.49624 | entropy=-3.12123 | reward=0.16812\n",
      "[INFO]  epoch/step=294/55400 | loss=0.89025 | ploss=0.39140 | vloss=0.50176 | entropy=-3.09697 | reward=0.17062\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_294.ckpt\n",
      "[INFO]  epoch/step=295/55500 | loss=0.89324 | ploss=0.38794 | vloss=0.50819 | entropy=-3.09060 | reward=0.17188\n",
      "[INFO]  epoch/step=295/55600 | loss=0.85894 | ploss=0.36743 | vloss=0.49440 | entropy=-3.09557 | reward=0.16812\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_295.ckpt\n",
      "[INFO]  epoch/step=296/55700 | loss=0.87178 | ploss=0.37474 | vloss=0.49992 | entropy=-3.07525 | reward=0.16937\n",
      "[INFO]  epoch/step=296/55800 | loss=0.94074 | ploss=0.40420 | vloss=0.53943 | entropy=-3.09141 | reward=0.18344\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_296.ckpt\n",
      "[INFO]  epoch/step=297/55900 | loss=0.87601 | ploss=0.37803 | vloss=0.50084 | entropy=-3.05942 | reward=0.16969\n",
      "[INFO]  epoch/step=297/56000 | loss=0.88580 | ploss=0.38050 | vloss=0.50819 | entropy=-3.08217 | reward=0.17281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_297.ckpt\n",
      "[INFO]  epoch/step=298/56100 | loss=0.92685 | ploss=0.40684 | vloss=0.52289 | entropy=-3.07512 | reward=0.17750\n",
      "[INFO]  epoch/step=298/56200 | loss=0.87167 | ploss=0.37186 | vloss=0.50268 | entropy=-3.06317 | reward=0.17094\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_298.ckpt\n",
      "[INFO]  epoch/step=299/56300 | loss=0.90152 | ploss=0.38151 | vloss=0.52289 | entropy=-3.07852 | reward=0.17719\n",
      "[INFO]  epoch/step=299/56400 | loss=0.84504 | ploss=0.33880 | vloss=0.50911 | entropy=-3.06327 | reward=0.17188\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_299.ckpt\n",
      "[INFO]  epoch/step=300/56500 | loss=0.92551 | ploss=0.39724 | vloss=0.53116 | entropy=-3.08327 | reward=0.18063\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_300.ckpt\n",
      "[INFO]  epoch/step=301/56600 | loss=0.86433 | ploss=0.36913 | vloss=0.49808 | entropy=-3.07486 | reward=0.16844\n",
      "[INFO]  epoch/step=301/56700 | loss=0.90721 | ploss=0.38811 | vloss=0.52197 | entropy=-3.07368 | reward=0.17750\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_301.ckpt\n",
      "[INFO]  epoch/step=302/56800 | loss=0.90645 | ploss=0.38458 | vloss=0.52473 | entropy=-3.05231 | reward=0.17719\n",
      "[INFO]  epoch/step=302/56900 | loss=0.90364 | ploss=0.38452 | vloss=0.52197 | entropy=-3.05959 | reward=0.17750\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_302.ckpt\n",
      "[INFO]  epoch/step=303/57000 | loss=0.85614 | ploss=0.36551 | vloss=0.49349 | entropy=-3.04911 | reward=0.16687\n",
      "[INFO]  epoch/step=303/57100 | loss=0.94785 | ploss=0.41309 | vloss=0.53760 | entropy=-3.03908 | reward=0.18281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_303.ckpt\n",
      "[INFO]  epoch/step=304/57200 | loss=0.85402 | ploss=0.35233 | vloss=0.50451 | entropy=-3.02082 | reward=0.17031\n",
      "[INFO]  epoch/step=304/57300 | loss=0.89376 | ploss=0.37830 | vloss=0.51830 | entropy=-3.03758 | reward=0.17625\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_304.ckpt\n",
      "[INFO]  epoch/step=305/57400 | loss=0.97806 | ploss=0.42030 | vloss=0.56057 | entropy=-3.00560 | reward=0.18969\n",
      "[INFO]  epoch/step=305/57500 | loss=0.88885 | ploss=0.37155 | vloss=0.52014 | entropy=-3.03048 | reward=0.17688\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_305.ckpt\n",
      "[INFO]  epoch/step=306/57600 | loss=0.82485 | ploss=0.33878 | vloss=0.48889 | entropy=-3.02152 | reward=0.16531\n",
      "[INFO]  epoch/step=306/57700 | loss=0.86728 | ploss=0.36375 | vloss=0.50635 | entropy=-3.02126 | reward=0.17219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_306.ckpt\n",
      "[INFO]  epoch/step=307/57800 | loss=0.86948 | ploss=0.37057 | vloss=0.50176 | entropy=-3.03931 | reward=0.17000\n",
      "[INFO]  epoch/step=307/57900 | loss=0.94049 | ploss=0.39373 | vloss=0.54954 | entropy=-2.97721 | reward=0.18688\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_307.ckpt\n",
      "[INFO]  epoch/step=308/58000 | loss=0.93838 | ploss=0.39990 | vloss=0.54127 | entropy=-2.98671 | reward=0.18313\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_308.ckpt\n",
      "[INFO]  epoch/step=309/58100 | loss=0.88101 | ploss=0.36734 | vloss=0.51646 | entropy=-2.99098 | reward=0.17563\n",
      "[INFO]  epoch/step=309/58200 | loss=0.94977 | ploss=0.40115 | vloss=0.55138 | entropy=-2.96143 | reward=0.18750\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_309.ckpt\n",
      "[INFO]  epoch/step=310/58300 | loss=0.91516 | ploss=0.38682 | vloss=0.53116 | entropy=-3.01925 | reward=0.18031\n",
      "[INFO]  epoch/step=310/58400 | loss=0.92535 | ploss=0.38687 | vloss=0.54127 | entropy=-2.99820 | reward=0.18406\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_310.ckpt\n",
      "[INFO]  epoch/step=311/58500 | loss=0.87491 | ploss=0.36675 | vloss=0.51095 | entropy=-2.98274 | reward=0.17313\n",
      "[INFO]  epoch/step=311/58600 | loss=0.86543 | ploss=0.34993 | vloss=0.51830 | entropy=-2.99501 | reward=0.17625\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_311.ckpt\n",
      "[INFO]  epoch/step=312/58700 | loss=0.87506 | ploss=0.37057 | vloss=0.50727 | entropy=-2.98394 | reward=0.17156\n",
      "[INFO]  epoch/step=312/58800 | loss=0.92349 | ploss=0.38499 | vloss=0.54127 | entropy=-2.97071 | reward=0.18406\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_312.ckpt\n",
      "[INFO]  epoch/step=313/58900 | loss=0.87898 | ploss=0.36250 | vloss=0.51922 | entropy=-2.93954 | reward=0.17563\n",
      "[INFO]  epoch/step=313/59000 | loss=0.85098 | ploss=0.35107 | vloss=0.50268 | entropy=-2.96063 | reward=0.17094\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_313.ckpt\n",
      "[INFO]  epoch/step=314/59100 | loss=0.97960 | ploss=0.41628 | vloss=0.56608 | entropy=-2.96572 | reward=0.19125\n",
      "[INFO]  epoch/step=314/59200 | loss=0.87448 | ploss=0.36446 | vloss=0.51278 | entropy=-2.95966 | reward=0.17438\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_314.ckpt\n",
      "[INFO]  epoch/step=315/59300 | loss=0.87007 | ploss=0.35084 | vloss=0.52197 | entropy=-2.94563 | reward=0.17688\n",
      "[INFO]  epoch/step=315/59400 | loss=0.92624 | ploss=0.38955 | vloss=0.53943 | entropy=-2.94712 | reward=0.18344\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_315.ckpt\n",
      "[INFO]  epoch/step=316/59500 | loss=0.92640 | ploss=0.37959 | vloss=0.54954 | entropy=-2.93059 | reward=0.18625\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_316.ckpt\n",
      "[INFO]  epoch/step=317/59600 | loss=0.94895 | ploss=0.39942 | vloss=0.55230 | entropy=-2.96800 | reward=0.18688\n",
      "[INFO]  epoch/step=317/59700 | loss=0.85469 | ploss=0.34187 | vloss=0.51554 | entropy=-2.91773 | reward=0.17531\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_317.ckpt\n",
      "[INFO]  epoch/step=318/59800 | loss=0.97771 | ploss=0.41433 | vloss=0.56608 | entropy=-2.91143 | reward=0.19156\n",
      "[INFO]  epoch/step=318/59900 | loss=0.83833 | ploss=0.34668 | vloss=0.49440 | entropy=-2.95884 | reward=0.16812\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_318.ckpt\n",
      "[INFO]  epoch/step=319/60000 | loss=0.87296 | ploss=0.35740 | vloss=0.51830 | entropy=-2.94497 | reward=0.17625\n",
      "[INFO]  epoch/step=319/60100 | loss=0.90186 | ploss=0.37065 | vloss=0.53392 | entropy=-2.91417 | reward=0.18156\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_319.ckpt\n",
      "[INFO]  epoch/step=320/60200 | loss=0.90632 | ploss=0.36963 | vloss=0.53943 | entropy=-2.95142 | reward=0.18219\n",
      "[INFO]  epoch/step=320/60300 | loss=0.91287 | ploss=0.37339 | vloss=0.54219 | entropy=-2.91318 | reward=0.18438\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_320.ckpt\n",
      "[INFO]  epoch/step=321/60400 | loss=0.88385 | ploss=0.35448 | vloss=0.53208 | entropy=-2.92120 | reward=0.18000\n",
      "[INFO]  epoch/step=321/60500 | loss=0.91536 | ploss=0.38046 | vloss=0.53760 | entropy=-2.90207 | reward=0.18281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_321.ckpt\n",
      "[INFO]  epoch/step=322/60600 | loss=0.92235 | ploss=0.37274 | vloss=0.55230 | entropy=-2.89741 | reward=0.18688\n",
      "[INFO]  epoch/step=322/60700 | loss=0.85981 | ploss=0.35156 | vloss=0.51095 | entropy=-2.90353 | reward=0.17375\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_322.ckpt\n",
      "[INFO]  epoch/step=323/60800 | loss=0.90448 | ploss=0.36774 | vloss=0.53943 | entropy=-2.89994 | reward=0.18250\n",
      "[INFO]  epoch/step=323/60900 | loss=0.87242 | ploss=0.36051 | vloss=0.51462 | entropy=-2.92078 | reward=0.17500\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_323.ckpt\n",
      "[INFO]  epoch/step=324/61000 | loss=0.89613 | ploss=0.36674 | vloss=0.53208 | entropy=-2.90795 | reward=0.17938\n",
      "[INFO]  epoch/step=324/61100 | loss=0.88224 | ploss=0.36663 | vloss=0.51830 | entropy=-2.89060 | reward=0.17563\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_324.ckpt\n",
      "[INFO]  epoch/step=325/61200 | loss=0.92307 | ploss=0.38081 | vloss=0.54495 | entropy=-2.89488 | reward=0.18531\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_325.ckpt\n",
      "[INFO]  epoch/step=326/61300 | loss=0.90337 | ploss=0.36846 | vloss=0.53760 | entropy=-2.88926 | reward=0.18250\n",
      "[INFO]  epoch/step=326/61400 | loss=0.85560 | ploss=0.33540 | vloss=0.52289 | entropy=-2.89742 | reward=0.17781\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_326.ckpt\n",
      "[INFO]  epoch/step=327/61500 | loss=0.91002 | ploss=0.38523 | vloss=0.52749 | entropy=-2.89812 | reward=0.17875\n",
      "[INFO]  epoch/step=327/61600 | loss=0.91620 | ploss=0.36565 | vloss=0.55322 | entropy=-2.87097 | reward=0.18812\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_327.ckpt\n",
      "[INFO]  epoch/step=328/61700 | loss=0.92133 | ploss=0.37998 | vloss=0.54403 | entropy=-2.88565 | reward=0.18406\n",
      "[INFO]  epoch/step=328/61800 | loss=0.90952 | ploss=0.37274 | vloss=0.53943 | entropy=-2.86494 | reward=0.18344\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_328.ckpt\n",
      "[INFO]  epoch/step=329/61900 | loss=0.97101 | ploss=0.40393 | vloss=0.56976 | entropy=-2.89028 | reward=0.19219\n",
      "[INFO]  epoch/step=329/62000 | loss=0.84426 | ploss=0.33598 | vloss=0.51095 | entropy=-2.87273 | reward=0.17375\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_329.ckpt\n",
      "[INFO]  epoch/step=330/62100 | loss=0.92307 | ploss=0.37711 | vloss=0.54862 | entropy=-2.86942 | reward=0.18531\n",
      "[INFO]  epoch/step=330/62200 | loss=0.88099 | ploss=0.36078 | vloss=0.52289 | entropy=-2.88669 | reward=0.17781\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_330.ckpt\n",
      "[INFO]  epoch/step=331/62300 | loss=0.90619 | ploss=0.37771 | vloss=0.53116 | entropy=-2.89797 | reward=0.17938\n",
      "[INFO]  epoch/step=331/62400 | loss=0.92014 | ploss=0.36955 | vloss=0.55322 | entropy=-2.84187 | reward=0.18812\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_331.ckpt\n",
      "[INFO]  epoch/step=332/62500 | loss=0.89350 | ploss=0.36957 | vloss=0.52657 | entropy=-2.85203 | reward=0.17813\n",
      "[INFO]  epoch/step=332/62600 | loss=0.90656 | ploss=0.36976 | vloss=0.53943 | entropy=-2.84620 | reward=0.18344\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_332.ckpt\n",
      "[INFO]  epoch/step=333/62700 | loss=0.88533 | ploss=0.36603 | vloss=0.52197 | entropy=-2.88656 | reward=0.17594\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_333.ckpt\n",
      "[INFO]  epoch/step=334/62800 | loss=0.87358 | ploss=0.35241 | vloss=0.52381 | entropy=-2.85639 | reward=0.17813\n",
      "[INFO]  epoch/step=334/62900 | loss=0.91398 | ploss=0.36800 | vloss=0.54862 | entropy=-2.86056 | reward=0.18656\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_334.ckpt\n",
      "[INFO]  epoch/step=335/63000 | loss=0.91756 | ploss=0.37064 | vloss=0.54954 | entropy=-2.83444 | reward=0.18594\n",
      "[INFO]  epoch/step=335/63100 | loss=0.89837 | ploss=0.36894 | vloss=0.53208 | entropy=-2.86419 | reward=0.18094\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_335.ckpt\n",
      "[INFO]  epoch/step=336/63200 | loss=0.93584 | ploss=0.38801 | vloss=0.55046 | entropy=-2.83747 | reward=0.18594\n",
      "[INFO]  epoch/step=336/63300 | loss=0.89546 | ploss=0.35408 | vloss=0.54403 | entropy=-2.85965 | reward=0.18500\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_336.ckpt\n",
      "[INFO]  epoch/step=337/63400 | loss=0.85544 | ploss=0.33332 | vloss=0.52473 | entropy=-2.83072 | reward=0.17813\n",
      "[INFO]  epoch/step=337/63500 | loss=0.90546 | ploss=0.37144 | vloss=0.53668 | entropy=-2.87090 | reward=0.18250\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_337.ckpt\n",
      "[INFO]  epoch/step=338/63600 | loss=0.82351 | ploss=0.32529 | vloss=0.50084 | entropy=-2.83144 | reward=0.17031\n",
      "[INFO]  epoch/step=338/63700 | loss=0.79336 | ploss=0.31167 | vloss=0.48430 | entropy=-2.82443 | reward=0.16469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_338.ckpt\n",
      "[INFO]  epoch/step=339/63800 | loss=0.88236 | ploss=0.35838 | vloss=0.52657 | entropy=-2.80970 | reward=0.17719\n",
      "[INFO]  epoch/step=339/63900 | loss=0.88124 | ploss=0.36094 | vloss=0.52289 | entropy=-2.80045 | reward=0.17781\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_339.ckpt\n",
      "[INFO]  epoch/step=340/64000 | loss=0.93794 | ploss=0.37908 | vloss=0.56149 | entropy=-2.84284 | reward=0.19031\n",
      "[INFO]  epoch/step=340/64100 | loss=0.94194 | ploss=0.38672 | vloss=0.55781 | entropy=-2.81068 | reward=0.18969\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_340.ckpt\n",
      "[INFO]  epoch/step=341/64200 | loss=0.84640 | ploss=0.33437 | vloss=0.51462 | entropy=-2.79716 | reward=0.17406\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_341.ckpt\n",
      "[INFO]  epoch/step=342/64300 | loss=0.94439 | ploss=0.38183 | vloss=0.56517 | entropy=-2.81937 | reward=0.19125\n",
      "[INFO]  epoch/step=342/64400 | loss=0.90568 | ploss=0.37804 | vloss=0.53024 | entropy=-2.81519 | reward=0.18031\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_342.ckpt\n",
      "[INFO]  epoch/step=343/64500 | loss=0.91686 | ploss=0.36995 | vloss=0.54954 | entropy=-2.83800 | reward=0.18500\n",
      "[INFO]  epoch/step=343/64600 | loss=0.86975 | ploss=0.35133 | vloss=0.52105 | entropy=-2.84216 | reward=0.17719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_343.ckpt\n",
      "[INFO]  epoch/step=344/64700 | loss=0.91441 | ploss=0.38125 | vloss=0.53576 | entropy=-2.81626 | reward=0.18125\n",
      "[INFO]  epoch/step=344/64800 | loss=0.88642 | ploss=0.34502 | vloss=0.54403 | entropy=-2.84826 | reward=0.18500\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_344.ckpt\n",
      "[INFO]  epoch/step=345/64900 | loss=0.90086 | ploss=0.36867 | vloss=0.53484 | entropy=-2.86507 | reward=0.18125\n",
      "[INFO]  epoch/step=345/65000 | loss=0.84338 | ploss=0.34055 | vloss=0.50543 | entropy=-2.81933 | reward=0.17188\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_345.ckpt\n",
      "[INFO]  epoch/step=346/65100 | loss=0.85238 | ploss=0.33762 | vloss=0.51738 | entropy=-2.83468 | reward=0.17500\n",
      "[INFO]  epoch/step=346/65200 | loss=0.93960 | ploss=0.37427 | vloss=0.56792 | entropy=-2.80596 | reward=0.19312\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_346.ckpt\n",
      "[INFO]  epoch/step=347/65300 | loss=0.88482 | ploss=0.36086 | vloss=0.52657 | entropy=-2.82906 | reward=0.17813\n",
      "[INFO]  epoch/step=347/65400 | loss=0.85841 | ploss=0.33715 | vloss=0.52381 | entropy=-2.77180 | reward=0.17813\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_347.ckpt\n",
      "[INFO]  epoch/step=348/65500 | loss=0.89635 | ploss=0.35956 | vloss=0.53943 | entropy=-2.86801 | reward=0.18250\n",
      "[INFO]  epoch/step=348/65600 | loss=0.85440 | ploss=0.33505 | vloss=0.52197 | entropy=-2.84008 | reward=0.17750\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_348.ckpt\n",
      "[INFO]  epoch/step=349/65700 | loss=0.90144 | ploss=0.37014 | vloss=0.53392 | entropy=-2.83349 | reward=0.18094\n",
      "[INFO]  epoch/step=349/65800 | loss=0.93983 | ploss=0.37906 | vloss=0.56333 | entropy=-2.78055 | reward=0.19062\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_349.ckpt\n",
      "[INFO]  epoch/step=350/65900 | loss=0.89964 | ploss=0.35268 | vloss=0.54954 | entropy=-2.79968 | reward=0.18688\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_350.ckpt\n",
      "[INFO]  epoch/step=351/66000 | loss=0.85997 | ploss=0.33968 | vloss=0.52289 | entropy=-2.82128 | reward=0.17688\n",
      "[INFO]  epoch/step=351/66100 | loss=0.85227 | ploss=0.33474 | vloss=0.52014 | entropy=-2.82384 | reward=0.17688\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_351.ckpt\n",
      "[INFO]  epoch/step=352/66200 | loss=0.89413 | ploss=0.34533 | vloss=0.55138 | entropy=-2.80255 | reward=0.18656\n",
      "[INFO]  epoch/step=352/66300 | loss=0.92245 | ploss=0.36904 | vloss=0.55598 | entropy=-2.78595 | reward=0.18906\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_352.ckpt\n",
      "[INFO]  epoch/step=353/66400 | loss=0.85734 | ploss=0.32322 | vloss=0.53668 | entropy=-2.77599 | reward=0.18188\n",
      "[INFO]  epoch/step=353/66500 | loss=0.85672 | ploss=0.34376 | vloss=0.51554 | entropy=-2.80751 | reward=0.17531\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_353.ckpt\n",
      "[INFO]  epoch/step=354/66600 | loss=0.91979 | ploss=0.35533 | vloss=0.56700 | entropy=-2.76466 | reward=0.19250\n",
      "[INFO]  epoch/step=354/66700 | loss=0.82069 | ploss=0.32147 | vloss=0.50176 | entropy=-2.75548 | reward=0.17062\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_354.ckpt\n",
      "[INFO]  epoch/step=355/66800 | loss=0.91655 | ploss=0.36494 | vloss=0.55414 | entropy=-2.75149 | reward=0.18688\n",
      "[INFO]  epoch/step=355/66900 | loss=0.87691 | ploss=0.34372 | vloss=0.53576 | entropy=-2.78805 | reward=0.18219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_355.ckpt\n",
      "[INFO]  epoch/step=356/67000 | loss=0.88533 | ploss=0.35580 | vloss=0.53208 | entropy=-2.77511 | reward=0.17969\n",
      "[INFO]  epoch/step=356/67100 | loss=0.83932 | ploss=0.32444 | vloss=0.51738 | entropy=-2.72629 | reward=0.17594\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_356.ckpt\n",
      "[INFO]  epoch/step=357/67200 | loss=0.94405 | ploss=0.36946 | vloss=0.57711 | entropy=-2.74855 | reward=0.19562\n",
      "[INFO]  epoch/step=357/67300 | loss=0.90856 | ploss=0.36066 | vloss=0.55046 | entropy=-2.78652 | reward=0.18719\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_357.ckpt\n",
      "[INFO]  epoch/step=358/67400 | loss=0.92662 | ploss=0.37777 | vloss=0.55138 | entropy=-2.75803 | reward=0.18594\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_358.ckpt\n",
      "[INFO]  epoch/step=359/67500 | loss=0.81924 | ploss=0.31636 | vloss=0.50543 | entropy=-2.77570 | reward=0.17125\n",
      "[INFO]  epoch/step=359/67600 | loss=0.90792 | ploss=0.35725 | vloss=0.55322 | entropy=-2.76574 | reward=0.18812\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_359.ckpt\n",
      "[INFO]  epoch/step=360/67700 | loss=0.92476 | ploss=0.36488 | vloss=0.56241 | entropy=-2.75255 | reward=0.19000\n",
      "[INFO]  epoch/step=360/67800 | loss=0.91664 | ploss=0.35954 | vloss=0.55965 | entropy=-2.77077 | reward=0.19031\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_360.ckpt\n",
      "[INFO]  epoch/step=361/67900 | loss=0.94972 | ploss=0.37786 | vloss=0.57435 | entropy=-2.72513 | reward=0.19437\n",
      "[INFO]  epoch/step=361/68000 | loss=0.93200 | ploss=0.36660 | vloss=0.56792 | entropy=-2.74703 | reward=0.19312\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_361.ckpt\n",
      "[INFO]  epoch/step=362/68100 | loss=0.86513 | ploss=0.34017 | vloss=0.52749 | entropy=-2.75785 | reward=0.17938\n",
      "[INFO]  epoch/step=362/68200 | loss=0.93811 | ploss=0.36808 | vloss=0.57252 | entropy=-2.71435 | reward=0.19469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_362.ckpt\n",
      "[INFO]  epoch/step=363/68300 | loss=0.93361 | ploss=0.36359 | vloss=0.57252 | entropy=-2.71793 | reward=0.19375\n",
      "[INFO]  epoch/step=363/68400 | loss=0.90205 | ploss=0.35134 | vloss=0.55322 | entropy=-2.73671 | reward=0.18812\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_363.ckpt\n",
      "[INFO]  epoch/step=364/68500 | loss=0.85707 | ploss=0.33119 | vloss=0.52841 | entropy=-2.75352 | reward=0.17906\n",
      "[INFO]  epoch/step=364/68600 | loss=0.89919 | ploss=0.34573 | vloss=0.55598 | entropy=-2.74366 | reward=0.18906\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_364.ckpt\n",
      "[INFO]  epoch/step=365/68700 | loss=0.90058 | ploss=0.36367 | vloss=0.53943 | entropy=-2.74733 | reward=0.18219\n",
      "[INFO]  epoch/step=365/68800 | loss=0.93272 | ploss=0.36177 | vloss=0.57344 | entropy=-2.70672 | reward=0.19500\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_365.ckpt\n",
      "[INFO]  epoch/step=366/68900 | loss=0.95882 | ploss=0.38517 | vloss=0.57619 | entropy=-2.76136 | reward=0.19500\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_366.ckpt\n",
      "[INFO]  epoch/step=367/69000 | loss=0.93455 | ploss=0.37559 | vloss=0.56149 | entropy=-2.75051 | reward=0.19031\n",
      "[INFO]  epoch/step=367/69100 | loss=0.85764 | ploss=0.33358 | vloss=0.52657 | entropy=-2.73740 | reward=0.17906\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_367.ckpt\n",
      "[INFO]  epoch/step=368/69200 | loss=0.95625 | ploss=0.38074 | vloss=0.57803 | entropy=-2.73737 | reward=0.19562\n",
      "[INFO]  epoch/step=368/69300 | loss=0.90817 | ploss=0.35655 | vloss=0.55414 | entropy=-2.75057 | reward=0.18844\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_368.ckpt\n",
      "[INFO]  epoch/step=369/69400 | loss=0.94263 | ploss=0.36250 | vloss=0.58263 | entropy=-2.71353 | reward=0.19656\n",
      "[INFO]  epoch/step=369/69500 | loss=0.91738 | ploss=0.35288 | vloss=0.56700 | entropy=-2.73391 | reward=0.19281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_369.ckpt\n",
      "[INFO]  epoch/step=370/69600 | loss=0.89082 | ploss=0.34746 | vloss=0.54587 | entropy=-2.73894 | reward=0.18469\n",
      "[INFO]  epoch/step=370/69700 | loss=0.89880 | ploss=0.34349 | vloss=0.55781 | entropy=-2.72716 | reward=0.18969\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_370.ckpt\n",
      "[INFO]  epoch/step=371/69800 | loss=0.94664 | ploss=0.37477 | vloss=0.57435 | entropy=-2.71713 | reward=0.19406\n",
      "[INFO]  epoch/step=371/69900 | loss=0.92608 | ploss=0.36617 | vloss=0.56241 | entropy=-2.71742 | reward=0.19125\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_371.ckpt\n",
      "[INFO]  epoch/step=372/70000 | loss=0.89862 | ploss=0.33778 | vloss=0.56333 | entropy=-2.70849 | reward=0.19031\n",
      "[INFO]  epoch/step=372/70100 | loss=0.85725 | ploss=0.32767 | vloss=0.53208 | entropy=-2.72889 | reward=0.18094\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_372.ckpt\n",
      "[INFO]  epoch/step=373/70200 | loss=0.93636 | ploss=0.35159 | vloss=0.58722 | entropy=-2.67818 | reward=0.19875\n",
      "[INFO]  epoch/step=373/70300 | loss=0.90260 | ploss=0.35096 | vloss=0.55414 | entropy=-2.72204 | reward=0.18844\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_373.ckpt\n",
      "[INFO]  epoch/step=374/70400 | loss=0.87471 | ploss=0.34512 | vloss=0.53208 | entropy=-2.72038 | reward=0.17906\n",
      "[INFO]  epoch/step=374/70500 | loss=0.87107 | ploss=0.33043 | vloss=0.54311 | entropy=-2.69907 | reward=0.18469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_374.ckpt\n",
      "[INFO]  epoch/step=375/70600 | loss=0.89966 | ploss=0.35809 | vloss=0.54403 | entropy=-2.68516 | reward=0.18500\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_375.ckpt\n",
      "[INFO]  epoch/step=376/70700 | loss=0.92901 | ploss=0.36265 | vloss=0.56884 | entropy=-2.71339 | reward=0.19219\n",
      "[INFO]  epoch/step=376/70800 | loss=0.88346 | ploss=0.34285 | vloss=0.54311 | entropy=-2.72882 | reward=0.18469\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_376.ckpt\n",
      "[INFO]  epoch/step=377/70900 | loss=0.94671 | ploss=0.36469 | vloss=0.58446 | entropy=-2.67599 | reward=0.19812\n",
      "[INFO]  epoch/step=377/71000 | loss=0.97205 | ploss=0.38084 | vloss=0.59365 | entropy=-2.67026 | reward=0.20187\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_377.ckpt\n",
      "[INFO]  epoch/step=378/71100 | loss=0.91149 | ploss=0.35245 | vloss=0.56149 | entropy=-2.67877 | reward=0.19000\n",
      "[INFO]  epoch/step=378/71200 | loss=0.95302 | ploss=0.37742 | vloss=0.57803 | entropy=-2.66087 | reward=0.19656\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_378.ckpt\n",
      "[INFO]  epoch/step=379/71300 | loss=0.91757 | ploss=0.35944 | vloss=0.56057 | entropy=-2.66869 | reward=0.18937\n",
      "[INFO]  epoch/step=379/71400 | loss=0.94649 | ploss=0.37547 | vloss=0.57344 | entropy=-2.64408 | reward=0.19500\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_379.ckpt\n",
      "[INFO]  epoch/step=380/71500 | loss=0.93541 | ploss=0.35801 | vloss=0.57987 | entropy=-2.69027 | reward=0.19625\n",
      "[INFO]  epoch/step=380/71600 | loss=0.89999 | ploss=0.34645 | vloss=0.55598 | entropy=-2.67521 | reward=0.18906\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_380.ckpt\n",
      "[INFO]  epoch/step=381/71700 | loss=0.91173 | ploss=0.35727 | vloss=0.55689 | entropy=-2.67027 | reward=0.18875\n",
      "[INFO]  epoch/step=381/71800 | loss=0.83851 | ploss=0.32360 | vloss=0.51738 | entropy=-2.69300 | reward=0.17594\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_381.ckpt\n",
      "[INFO]  epoch/step=382/71900 | loss=0.92389 | ploss=0.36025 | vloss=0.56608 | entropy=-2.67930 | reward=0.19156\n",
      "[INFO]  epoch/step=382/72000 | loss=0.90433 | ploss=0.34897 | vloss=0.55781 | entropy=-2.68182 | reward=0.18969\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_382.ckpt\n",
      "[INFO]  epoch/step=383/72100 | loss=0.93719 | ploss=0.36616 | vloss=0.57344 | entropy=-2.64223 | reward=0.19437\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_383.ckpt\n",
      "[INFO]  epoch/step=384/72200 | loss=0.94448 | ploss=0.37901 | vloss=0.56792 | entropy=-2.67588 | reward=0.19281\n",
      "[INFO]  epoch/step=384/72300 | loss=0.92265 | ploss=0.36083 | vloss=0.56425 | entropy=-2.65905 | reward=0.19187\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_384.ckpt\n",
      "[INFO]  epoch/step=385/72400 | loss=0.91683 | ploss=0.34854 | vloss=0.57068 | entropy=-2.62192 | reward=0.19312\n",
      "[INFO]  epoch/step=385/72500 | loss=0.88672 | ploss=0.32764 | vloss=0.56149 | entropy=-2.64478 | reward=0.19094\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_385.ckpt\n",
      "[INFO]  epoch/step=386/72600 | loss=0.86657 | ploss=0.32955 | vloss=0.53943 | entropy=-2.65200 | reward=0.18219\n",
      "[INFO]  epoch/step=386/72700 | loss=0.85833 | ploss=0.31579 | vloss=0.54495 | entropy=-2.63268 | reward=0.18531\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_386.ckpt\n",
      "[INFO]  epoch/step=387/72800 | loss=0.96852 | ploss=0.38372 | vloss=0.58722 | entropy=-2.65608 | reward=0.19937\n",
      "[INFO]  epoch/step=387/72900 | loss=0.88916 | ploss=0.32449 | vloss=0.56700 | entropy=-2.56585 | reward=0.19281\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_387.ckpt\n",
      "[INFO]  epoch/step=388/73000 | loss=0.95035 | ploss=0.38850 | vloss=0.56425 | entropy=-2.63026 | reward=0.19031\n",
      "[INFO]  epoch/step=388/73100 | loss=0.89502 | ploss=0.33225 | vloss=0.56517 | entropy=-2.62524 | reward=0.19219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_388.ckpt\n",
      "[INFO]  epoch/step=389/73200 | loss=0.92216 | ploss=0.35939 | vloss=0.56517 | entropy=-2.63278 | reward=0.19125\n",
      "[INFO]  epoch/step=389/73300 | loss=0.96132 | ploss=0.36639 | vloss=0.59733 | entropy=-2.63396 | reward=0.20312\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_389.ckpt\n",
      "[INFO]  epoch/step=390/73400 | loss=0.92971 | ploss=0.35683 | vloss=0.57527 | entropy=-2.62253 | reward=0.19469\n",
      "[INFO]  epoch/step=390/73500 | loss=0.96404 | ploss=0.37183 | vloss=0.59457 | entropy=-2.59795 | reward=0.20219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_390.ckpt\n",
      "[INFO]  epoch/step=391/73600 | loss=0.86472 | ploss=0.32862 | vloss=0.53851 | entropy=-2.64128 | reward=0.18156\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_391.ckpt\n",
      "[INFO]  epoch/step=392/73700 | loss=0.95809 | ploss=0.36587 | vloss=0.59457 | entropy=-2.59605 | reward=0.20187\n",
      "[INFO]  epoch/step=392/73800 | loss=0.91338 | ploss=0.36346 | vloss=0.55230 | entropy=-2.61512 | reward=0.18781\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_392.ckpt\n",
      "[INFO]  epoch/step=393/73900 | loss=0.95297 | ploss=0.36448 | vloss=0.59090 | entropy=-2.63786 | reward=0.20031\n",
      "[INFO]  epoch/step=393/74000 | loss=0.92041 | ploss=0.33742 | vloss=0.58538 | entropy=-2.62549 | reward=0.19906\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_393.ckpt\n",
      "[INFO]  epoch/step=394/74100 | loss=0.93838 | ploss=0.35811 | vloss=0.58263 | entropy=-2.59966 | reward=0.19781\n",
      "[INFO]  epoch/step=394/74200 | loss=0.96360 | ploss=0.36585 | vloss=0.60009 | entropy=-2.57801 | reward=0.20406\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_394.ckpt\n",
      "[INFO]  epoch/step=395/74300 | loss=0.95215 | ploss=0.36916 | vloss=0.58538 | entropy=-2.63568 | reward=0.19812\n",
      "[INFO]  epoch/step=395/74400 | loss=0.93782 | ploss=0.36395 | vloss=0.57619 | entropy=-2.55989 | reward=0.19594\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_395.ckpt\n",
      "[INFO]  epoch/step=396/74500 | loss=0.92338 | ploss=0.35231 | vloss=0.57344 | entropy=-2.60250 | reward=0.19406\n",
      "[INFO]  epoch/step=396/74600 | loss=0.93858 | ploss=0.36381 | vloss=0.57711 | entropy=-2.58052 | reward=0.19625\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_396.ckpt\n",
      "[INFO]  epoch/step=397/74700 | loss=0.95950 | ploss=0.36268 | vloss=0.59917 | entropy=-2.58777 | reward=0.20281\n",
      "[INFO]  epoch/step=397/74800 | loss=0.97756 | ploss=0.36968 | vloss=0.61019 | entropy=-2.55976 | reward=0.20750\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_397.ckpt\n",
      "[INFO]  epoch/step=398/74900 | loss=0.88506 | ploss=0.33515 | vloss=0.55230 | entropy=-2.62715 | reward=0.18719\n",
      "[INFO]  epoch/step=398/75000 | loss=0.87734 | ploss=0.32739 | vloss=0.55230 | entropy=-2.58369 | reward=0.18781\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_398.ckpt\n",
      "[INFO]  epoch/step=399/75100 | loss=0.93074 | ploss=0.35600 | vloss=0.57711 | entropy=-2.61030 | reward=0.19562\n",
      "[INFO]  epoch/step=399/75200 | loss=0.91707 | ploss=0.34873 | vloss=0.57068 | entropy=-2.57382 | reward=0.19219\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_399.ckpt\n",
      "[INFO]  epoch/step=400/75300 | loss=0.89375 | ploss=0.32724 | vloss=0.56884 | entropy=-2.57006 | reward=0.19344\n",
      "[INFO]  Save model to ../save_model/amazon-book_20core/lstm/note_ld0.2_rn3_h12_nmem64_em32_g_aiu_0_0_6000/policy_model_epoch_400.ckpt\n",
      "[INFO]  current time = 20210526-081202\n"
     ]
    }
   ],
   "source": [
    "command = f\"python3 ../src/{train_file} --reasoning_step {reasoning_step} \\\n",
    "                                         --batch_size {batch_size} \\\n",
    "                                         --name {exp_name} \\\n",
    "                                         --lr {lr} \\\n",
    "                                         --embed_size {embed_size} \\\n",
    "                                         --n_memory {n_memory} \\\n",
    "                                         --load_pretrain_model {load_pretrain_model}  \\\n",
    "                                         --gp_setting {gp_setting} \\\n",
    "                                         --epochs {epochs} \\\n",
    "                                         --KGE_pretrained {KGE_pretrained} \\\n",
    "                                         --lambda_num {lambda_num}  \\\n",
    "                                         --kg_emb_grad {kg_emb_grad} \\\n",
    "                                         --p_hop {p_hop}  \\\n",
    "                                         --reasoning_step {reasoning_step}  \\\n",
    "                                         --model lstm \\\n",
    "                                         --dataset {DATASET}\"\n",
    "print(\"Running Command:\")\n",
    "print(' '.join(command.split()))\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-label",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 ../src/test.py --name note_ld0.2_rn3_h12_nmem64_em32 --batch_size 32 --gp_setting 6000_800_15_500_50 --model lstm --dataset amazon-book_20core --lambda_num 0.2 --kg_emb_grad 1 --lr 0.0001 --p_hop 2 --reasoning_step 3 --embed_size 32 --save_pretrain_model 1 --n_memory 64\n",
      "args.gp_setting =  6000_800_15_500_50 args.att_core =  0 args.item_core =  0 args.user_core =  6000 args.kg_fre_upper =  500 args.max_acts =  50\n",
      "label_file =  ../data/amazon-book_20core/train_label.pkl\n",
      "label_file =  ../data/amazon-book_20core/test_label.pkl\n",
      "start predict\n",
      "Predicting paths...\n",
      "len(self.core_user_list) =  6000\n",
      "self.args.core_user_list =  6000\n",
      "self.user_triplet_list =  6000\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "et =  user 70585\n",
      "et =  product 95500\n",
      "et =  attribute 184072\n",
      " 13%|█████▎                                  | 784/5957 [00:51<05:35, 15.44it/s][INFO]  'batch_uids = ', 34211,34953,4199,5503,27305,12775,53891,11572,67424,1505,19636,37700,5367,3517,41518,7960, 800, 800\n",
      " 27%|██████████▎                            | 1584/5957 [01:44<04:58, 14.67it/s][INFO]  'batch_uids = ', 14489,68912,47860,38105,19430,9242,39814,7559,26744,17513,9969,8675,7965,42378,18143,673, 1600, 1600\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      " 27%|██████████▎                            | 1584/5957 [01:59<05:30, 13.23it/s]\n",
      "NDCG=4.934 |  Recall=3.944 | HR=30.938 | Precision=4.258 | Invalid users=0\n",
      "cum_k == 0  0\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=5.554 |  Recall=6.055 | HR=43.500 | Precision=3.780 | Invalid users=0\n",
      "cum_k == 0  0\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=5.809 |  Recall=6.746 | HR=47.125 | Precision=3.658 | Invalid users=0\n",
      "cum_k == 0  0\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=6.175 |  Recall=7.746 | HR=51.375 | Precision=3.468 | Invalid users=0\n",
      "cum_k == 0  0\n",
      "start predict\n",
      "Predicting paths...\n",
      "len(self.core_user_list) =  6000\n",
      "self.args.core_user_list =  6000\n",
      "self.user_triplet_list =  6000\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "et =  user 70585\n",
      "et =  product 95500\n",
      "et =  attribute 184072\n",
      " 13%|█████▎                                  | 784/5957 [00:44<04:49, 17.84it/s][INFO]  'batch_uids = ', 34211,34953,4199,5503,27305,12775,53891,11572,67424,1505,19636,37700,5367,3517,41518,7960, 800, 800\n",
      " 27%|██████████▎                            | 1584/5957 [01:30<04:19, 16.85it/s][INFO]  'batch_uids = ', 14489,68912,47860,38105,19430,9242,39814,7559,26744,17513,9969,8675,7965,42378,18143,673, 1600, 1600\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      " 27%|██████████▎                            | 1584/5957 [01:37<04:30, 16.19it/s]\n",
      "NDCG=6.413 |  Recall=4.829 | HR=37.125 | Precision=5.570 | Invalid users=0\n",
      "cum_k == 0  0\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=7.233 |  Recall=7.425 | HR=49.750 | Precision=5.132 | Invalid users=0\n",
      "cum_k == 0  0\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=7.438 |  Recall=8.030 | HR=52.062 | Precision=4.956 | Invalid users=0\n",
      "cum_k == 0  0\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=7.751 |  Recall=8.892 | HR=56.250 | Precision=4.780 | Invalid users=0\n",
      "cum_k == 0  0\n",
      "start predict\n",
      "Predicting paths...\n",
      "len(self.core_user_list) =  6000\n",
      "self.args.core_user_list =  6000\n",
      "self.user_triplet_list =  6000\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "et =  user 70585\n",
      "et =  product 95500\n",
      "et =  attribute 184072\n",
      " 13%|█████▎                                  | 784/5957 [00:44<04:54, 17.54it/s][INFO]  'batch_uids = ', 34211,34953,4199,5503,27305,12775,53891,11572,67424,1505,19636,37700,5367,3517,41518,7960, 800, 800\n",
      " 27%|██████████▎                            | 1584/5957 [01:30<04:21, 16.70it/s][INFO]  'batch_uids = ', 14489,68912,47860,38105,19430,9242,39814,7559,26744,17513,9969,8675,7965,42378,18143,673, 1600, 1600\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      " 27%|██████████▎                            | 1584/5957 [01:37<04:29, 16.24it/s]\n",
      "NDCG=7.292 |  Recall=5.442 | HR=39.812 | Precision=6.173 | Invalid users=0\n",
      "cum_k == 0  0\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=7.952 |  Recall=7.778 | HR=50.438 | Precision=5.504 | Invalid users=0\n",
      "cum_k == 0  0\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=8.104 |  Recall=8.233 | HR=52.438 | Precision=5.332 | Invalid users=0\n",
      "cum_k == 0  0\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=8.367 |  Recall=8.944 | HR=55.937 | Precision=5.181 | Invalid users=0\n",
      "cum_k == 0  0\n",
      "start predict\n",
      "Predicting paths...\n",
      "len(self.core_user_list) =  6000\n",
      "self.args.core_user_list =  6000\n",
      "self.user_triplet_list =  6000\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "et =  user 70585\n",
      "et =  product 95500\n",
      "et =  attribute 184072\n",
      " 13%|█████▎                                  | 784/5957 [00:44<04:57, 17.40it/s][INFO]  'batch_uids = ', 34211,34953,4199,5503,27305,12775,53891,11572,67424,1505,19636,37700,5367,3517,41518,7960, 800, 800\n",
      " 27%|██████████▎                            | 1584/5957 [01:32<04:30, 16.17it/s][INFO]  'batch_uids = ', 14489,68912,47860,38105,19430,9242,39814,7559,26744,17513,9969,8675,7965,42378,18143,673, 1600, 1600\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      " 27%|██████████▎                            | 1584/5957 [01:39<04:34, 15.93it/s]\n",
      "NDCG=7.668 |  Recall=5.765 | HR=41.312 | Precision=6.658 | Invalid users=0\n",
      "cum_k == 0  1\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=8.394 |  Recall=8.306 | HR=52.250 | Precision=5.947 | Invalid users=0\n",
      "cum_k == 0  1\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=8.538 |  Recall=8.737 | HR=54.000 | Precision=5.772 | Invalid users=0\n",
      "cum_k == 0  1\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=8.802 |  Recall=9.460 | HR=57.188 | Precision=5.637 | Invalid users=0\n",
      "cum_k == 0  1\n",
      "start predict\n",
      "Predicting paths...\n",
      "len(self.core_user_list) =  6000\n",
      "self.args.core_user_list =  6000\n",
      "self.user_triplet_list =  6000\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "et =  user 70585\n",
      "et =  product 95500\n",
      "et =  attribute 184072\n",
      " 13%|█████▎                                  | 784/5957 [00:44<04:59, 17.25it/s][INFO]  'batch_uids = ', 34211,34953,4199,5503,27305,12775,53891,11572,67424,1505,19636,37700,5367,3517,41518,7960, 800, 800\n",
      " 27%|██████████▎                            | 1584/5957 [01:32<04:27, 16.33it/s][INFO]  'batch_uids = ', 14489,68912,47860,38105,19430,9242,39814,7559,26744,17513,9969,8675,7965,42378,18143,673, 1600, 1600\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      " 27%|██████████▎                            | 1584/5957 [01:39<04:33, 15.96it/s]\n",
      "NDCG=7.956 |  Recall=5.862 | HR=43.062 | Precision=6.836 | Invalid users=0\n",
      "cum_k == 0  2\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=8.706 |  Recall=8.520 | HR=53.062 | Precision=6.132 | Invalid users=0\n",
      "cum_k == 0  2\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=8.833 |  Recall=8.886 | HR=54.688 | Precision=5.940 | Invalid users=0\n",
      "cum_k == 0  2\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=9.038 |  Recall=9.455 | HR=57.250 | Precision=5.780 | Invalid users=0\n",
      "cum_k == 0  2\n",
      "start predict\n",
      "Predicting paths...\n",
      "len(self.core_user_list) =  6000\n",
      "self.args.core_user_list =  6000\n",
      "self.user_triplet_list =  6000\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "et =  user 70585\n",
      "et =  product 95500\n",
      "et =  attribute 184072\n",
      " 13%|█████▎                                  | 784/5957 [00:45<04:57, 17.40it/s][INFO]  'batch_uids = ', 34211,34953,4199,5503,27305,12775,53891,11572,67424,1505,19636,37700,5367,3517,41518,7960, 800, 800\n",
      " 27%|██████████▎                            | 1584/5957 [01:32<04:22, 16.63it/s][INFO]  'batch_uids = ', 14489,68912,47860,38105,19430,9242,39814,7559,26744,17513,9969,8675,7965,42378,18143,673, 1600, 1600\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      " 27%|██████████▎                            | 1584/5957 [01:39<04:35, 15.88it/s]\n",
      "NDCG=8.234 |  Recall=5.918 | HR=42.938 | Precision=6.993 | Invalid users=0\n",
      "cum_k == 0  2\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=9.001 |  Recall=8.606 | HR=53.312 | Precision=6.304 | Invalid users=0\n",
      "cum_k == 0  2\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=9.166 |  Recall=9.060 | HR=55.125 | Precision=6.143 | Invalid users=0\n",
      "cum_k == 0  2\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=9.381 |  Recall=9.638 | HR=57.563 | Precision=5.992 | Invalid users=0\n",
      "cum_k == 0  2\n",
      "start predict\n",
      "Predicting paths...\n",
      "len(self.core_user_list) =  6000\n",
      "self.args.core_user_list =  6000\n",
      "self.user_triplet_list =  6000\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "et =  user 70585\n",
      "et =  product 95500\n",
      "et =  attribute 184072\n",
      " 13%|█████▎                                  | 784/5957 [00:44<04:59, 17.30it/s][INFO]  'batch_uids = ', 34211,34953,4199,5503,27305,12775,53891,11572,67424,1505,19636,37700,5367,3517,41518,7960, 800, 800\n",
      " 27%|██████████▎                            | 1584/5957 [01:31<04:23, 16.57it/s][INFO]  'batch_uids = ', 14489,68912,47860,38105,19430,9242,39814,7559,26744,17513,9969,8675,7965,42378,18143,673, 1600, 1600\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      " 27%|██████████▎                            | 1584/5957 [01:38<04:32, 16.06it/s]\n",
      "NDCG=8.583 |  Recall=6.199 | HR=45.000 | Precision=7.255 | Invalid users=0\n",
      "cum_k == 0  2\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=9.250 |  Recall=8.683 | HR=54.250 | Precision=6.496 | Invalid users=0\n",
      "cum_k == 0  2\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=9.369 |  Recall=9.024 | HR=55.750 | Precision=6.328 | Invalid users=0\n",
      "cum_k == 0  2\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=9.569 |  Recall=9.570 | HR=58.438 | Precision=6.198 | Invalid users=0\n",
      "cum_k == 0  2\n",
      "start predict\n",
      "Predicting paths...\n",
      "len(self.core_user_list) =  6000\n",
      "self.args.core_user_list =  6000\n",
      "self.user_triplet_list =  6000\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "et =  user 70585\n",
      "et =  product 95500\n",
      "et =  attribute 184072\n",
      " 13%|█████▎                                  | 784/5957 [00:44<04:56, 17.47it/s][INFO]  'batch_uids = ', 34211,34953,4199,5503,27305,12775,53891,11572,67424,1505,19636,37700,5367,3517,41518,7960, 800, 800\n",
      " 27%|██████████▎                            | 1584/5957 [01:31<04:20, 16.80it/s][INFO]  'batch_uids = ', 14489,68912,47860,38105,19430,9242,39814,7559,26744,17513,9969,8675,7965,42378,18143,673, 1600, 1600\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      " 27%|██████████▎                            | 1584/5957 [01:38<04:32, 16.07it/s]\n",
      "NDCG=8.734 |  Recall=6.362 | HR=45.875 | Precision=7.398 | Invalid users=0\n",
      "cum_k == 0  2\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=9.378 |  Recall=8.920 | HR=55.000 | Precision=6.535 | Invalid users=0\n",
      "cum_k == 0  2\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=9.505 |  Recall=9.293 | HR=56.750 | Precision=6.356 | Invalid users=0\n",
      "cum_k == 0  2\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "NDCG=9.726 |  Recall=9.880 | HR=59.375 | Precision=6.220 | Invalid users=0\n",
      "cum_k == 0  2\n",
      "start predict\n",
      "Predicting paths...\n",
      "len(self.core_user_list) =  6000\n",
      "self.args.core_user_list =  6000\n",
      "self.user_triplet_list =  6000\n",
      "Load embedding: ../data/amazon-book_20core/transe_embed.pkl\n",
      "et =  user 70585\n",
      "et =  product 95500\n",
      "et =  attribute 184072\n",
      " 13%|█████▎                                  | 784/5957 [00:43<04:53, 17.65it/s][INFO]  'batch_uids = ', 34211,34953,4199,5503,27305,12775,53891,11572,67424,1505,19636,37700,5367,3517,41518,7960, 800, 800\n",
      " 21%|████████                               | 1232/5957 [01:09<04:39, 16.89it/s]"
     ]
    }
   ],
   "source": [
    "save_pretrain_model = 1\n",
    "command = f\"python3 ../src/{test_file} --name {exp_name} \\\n",
    "                                        --batch_size {batch_size} \\\n",
    "                                        --gp_setting {gp_setting} \\\n",
    "                                        --model lstm \\\n",
    "                                        --dataset {DATASET} \\\n",
    "                                        --lambda_num {lambda_num} \\\n",
    "                                        --kg_emb_grad {kg_emb_grad} \\\n",
    "                                        --lr {lr} \\\n",
    "                                        --p_hop {p_hop} \\\n",
    "                                        --reasoning_step {reasoning_step} \\\n",
    "                                        --embed_size {embed_size} \\\n",
    "                                        --save_pretrain_model {save_pretrain_model} \\\n",
    "                                        --n_memory {n_memory}\"\n",
    "\n",
    "print(' '.join(command.split()))\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-marriage",
   "metadata": {},
   "source": [
    "# train UCPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pretrain_model=1\n",
    "\n",
    "command = f\"python3 ../src/{train_file} --reasoning_step {reasoning_step} \\\n",
    "                                    --batch_size {batch_size} \\\n",
    "                                    --name {exp_name} \\\n",
    "                                    --lr {lr} \\\n",
    "                                    --embed_size {embed_size} \\\n",
    "                                    --n_memory {n_memory} \\\n",
    "                                    --load_pretrain_model {load_pretrain_model} \\\n",
    "                                    --KGE_pretrained {KGE_pretrained} \\\n",
    "                                    --gp_setting {gp_setting} \\\n",
    "                                    --epochs {epochs} \\\n",
    "                                    --lambda_num {lambda_num} \\\n",
    "                                    --kg_emb_grad {kg_emb_grad}  \\\n",
    "                                    --p_hop {p_hop} \\\n",
    "                                    --reasoning_step {reasoning_step} \\\n",
    "                                    --model {model} \\\n",
    "                                    --dataset {DATASET}\"\n",
    "print(' '.join(command.split()))\n",
    "!{command}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f\"python3 ../src/${test_file} --name{exp_name} \\\n",
    "                                --batch_size{batch_size}\\\n",
    "                                --gp_setting{gp_setting}  \\\n",
    "                                --model{model} \\\n",
    "                                --dataset{DATASET} \\\n",
    "                                --lambda_num{lambda_num}   \\\n",
    "                                --kg_emb_grad{kg_emb_grad} \\\n",
    "                                --lr{lr} \\\n",
    "                                --p_hop{p_hop}  \\\n",
    "                                --reasoning_step{reasoning_step} \\\n",
    "                                --embed_size{embed_size} \\\n",
    "                                --n_memory{n_memory}\"\n",
    "\n",
    "\n",
    "print(' '.join(command.split()))\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-bidder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
