{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "obvious-alexander",
   "metadata": {},
   "source": [
    "# Running UCPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gorgeous-aging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/johnnyjana730/github/UCPR/', '/home/johnnyjana730/github/UCPR/bash', '/home/johnnyjana730/anaconda3_tmp/lib/python38.zip', '/home/johnnyjana730/anaconda3_tmp/lib/python3.8', '/home/johnnyjana730/anaconda3_tmp/lib/python3.8/lib-dynload', '', '/home/johnnyjana730/anaconda3_tmp/lib/python3.8/site-packages', '/home/johnnyjana730/anaconda3_tmp/lib/python3.8/site-packages/locket-0.2.1-py3.8.egg', '/home/johnnyjana730/anaconda3_tmp/lib/python3.8/site-packages/IPython/extensions', '/home/johnnyjana730/.ipython']\n",
      "dataset =  cloth_core\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'/home/johnnyjana730/github/UCPR/')\n",
    "print(sys.path)\n",
    "\n",
    "from config import get_hparams\n",
    "\n",
    "!export PYTHONPATH=\"./\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from config import get_hparams\n",
    "\n",
    "# cell_core, beauty_core, cloth_core, MovieLens-1M_core, amazon-book_20core\n",
    "\n",
    "DATASET = \"cloth_core\"\n",
    "\n",
    "locals().update(get_hparams(DATASET))\n",
    "\n",
    "\n",
    "\n",
    "epochs=100\n",
    "KGE_pretrained=1\n",
    "kg_emb_grad=0\n",
    "tri_wd_rm=1\n",
    "tri_pro_rm=0\n",
    "batch_size=32\n",
    "load_pretrain_model=0\n",
    "\n",
    "train_file=\"train.py\"\n",
    "test_file=\"test.py\"\n",
    "\n",
    "exp_name=f\"note_rm_w{tri_wd_rm}_p{tri_pro_rm}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-particle",
   "metadata": {},
   "source": [
    "# Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-cowboy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Command:\n",
      "python3 ../src/train.py --reasoning_step 2 --batch_size 32 --name note_rm_w1_p0 --lr 0.0001 --embed_size 32 --n_memory 32 --load_pretrain_model 0 --tri_wd_rm 1 --tri_pro_rm 0 --gp_setting 6_800_15_500_50 --epochs 100 --KGE_pretrained 1 --lambda_num 0.3 --kg_emb_grad 0 --p_hop 2 --reasoning_step 2 --model lstm --dataset cloth_core\n",
      "args.gp_setting =  6_800_15_500_50 args.att_core =  0 args.item_core =  0 args.user_core_th =  6 args.kg_fre_upper =  500 args.max_acts =  50\n",
      "len(self.core_user_list) =  10228\n",
      "self.args.core_user_list =  10228\n",
      "self.user_triplet_list =  10228\n",
      "Load embedding: ../data/Amazon_Clothing_Core/transe_embed.pkl\n",
      "env.output_valid_user() =  10228\n",
      "args.batch_size =  32\n",
      "Load embedding: ../data/Amazon_Clothing_Core/transe_embed.pkl\n",
      "self.embeds[key] =  (39387, 100)\n",
      "weight =  (39388, 32)\n",
      "key =  user\n",
      "self.embeds[key] =  torch.Size([39388, 32])\n",
      "vocab_size + 1 =  39388\n",
      "embed =  torch.Size([39388, 32])\n",
      "embed.requires_grad =  False\n",
      "self.embeds[key] =  (23033, 100)\n",
      "weight =  (23034, 32)\n",
      "key =  product\n",
      "self.embeds[key] =  torch.Size([23034, 32])\n",
      "vocab_size + 1 =  23034\n",
      "embed =  torch.Size([23034, 32])\n",
      "embed.requires_grad =  False\n",
      "self.embeds[key] =  (21366, 100)\n",
      "weight =  (21367, 32)\n",
      "key =  word\n",
      "self.embeds[key] =  torch.Size([21367, 32])\n",
      "vocab_size + 1 =  21367\n",
      "embed =  torch.Size([21367, 32])\n",
      "embed.requires_grad =  False\n",
      "self.embeds[key] =  (339367, 100)\n",
      "weight =  (339368, 32)\n",
      "key =  related_product\n",
      "self.embeds[key] =  torch.Size([339368, 32])\n",
      "vocab_size + 1 =  339368\n",
      "embed =  torch.Size([339368, 32])\n",
      "embed.requires_grad =  False\n",
      "self.embeds[key] =  (1182, 100)\n",
      "weight =  (1183, 32)\n",
      "key =  brand\n",
      "self.embeds[key] =  torch.Size([1183, 32])\n",
      "vocab_size + 1 =  1183\n",
      "embed =  torch.Size([1183, 32])\n",
      "embed.requires_grad =  False\n",
      "self.embeds[key] =  (1193, 100)\n",
      "weight =  (1194, 32)\n",
      "key =  category\n",
      "self.embeds[key] =  torch.Size([1194, 32])\n",
      "vocab_size + 1 =  1194\n",
      "embed =  torch.Size([1194, 32])\n",
      "embed.requires_grad =  False\n",
      "r =  setup self_loop\n",
      "key =  self_loop\n",
      "self_loop embed =  torch.Size([1, 32])\n",
      "r =  setup purchase\n",
      "key =  purchase\n",
      "purchase embed =  torch.Size([1, 32])\n",
      "r =  setup mentions\n",
      "key =  mentions\n",
      "mentions embed =  torch.Size([1, 32])\n",
      "r =  setup described_as\n",
      "key =  described_as\n",
      "described_as embed =  torch.Size([1, 32])\n",
      "r =  setup produced_by\n",
      "key =  produced_by\n",
      "produced_by embed =  torch.Size([1, 32])\n",
      "r =  setup belongs_to\n",
      "key =  belongs_to\n",
      "belongs_to embed =  torch.Size([1, 32])\n",
      "r =  setup also_bought\n",
      "key =  also_bought\n",
      "also_bought embed =  torch.Size([1, 32])\n",
      "r =  setup also_viewed\n",
      "key =  also_viewed\n",
      "also_viewed embed =  torch.Size([1, 32])\n",
      "r =  setup bought_together\n",
      "key =  bought_together\n",
      "bought_together embed =  torch.Size([1, 32])\n",
      "r =  setup padding\n",
      "key =  padding\n",
      "padding embed =  torch.Size([1, 32])\n",
      "[INFO]  Namespace(KGE_pretrained=True, act_dropout=0.5, add_products=False, att_core=0, att_evaluation=False, batch_size=32, best_model_epoch=0, best_save_model_dir='', core_user_list='', dataset='cloth_core', device=device(type='cuda', index=0), embed_size=32, ent_weight=0.001, envir='p1', epochs=100, eva_epochs=0, gamma=0.99, gp_setting='6_800_15_500_50', gpu='0', gradient_plot='gradient_plot/', h0_embbed=0, hidden=[64, 32], item_core=0, kg_emb_grad=False, kg_fre_dict='', kg_fre_lower=15, kg_fre_upper=500, kg_no_grad=False, l2_lambda=0, l2_weight=1e-06, lambda_num=0.3, load_pretrain_model=False, load_pt_emb_size=False, log_dir='../eva/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300', logger=<Logger ../eva/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/train_log.txt (DEBUG)>, lr=0.0001, max_acts=50, max_path_len=3, model='lstm', n_memory=32, name='note_rm_w1_p0', non_sampling=True, p_hop=2, pretest=False, pretrained_dir='../eva/Amazon_Clothing_Core/pretrained/note_rm_w1_p0_g_aiu_0_0_300', pretrained_st_epoch=0, reasoning_step=2, reward_hybrid=False, reward_rh='', run_eval=True, run_path=True, sam_type='alet', save_model_dir='../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300', seed=52, sort_by='score', state_history=1, state_rg=False, sub_batch_size=1, test_lstm_up=True, topk=[10, 10, 1], topk_list=[1, 10, 100, 100], topk_string='10, 10, 1', training=True, tri_pro_rm=False, tri_wd_rm=True, user_core=300, user_core_th=6)\n",
      "[INFO]  Parameters:['kg_emb.self_loop', 'kg_emb.purchase', 'kg_emb.mentions', 'kg_emb.described_as', 'kg_emb.produced_by', 'kg_emb.belongs_to', 'kg_emb.also_bought', 'kg_emb.also_viewed', 'kg_emb.bought_together', 'kg_emb.padding', 'kg_emb.user.weight', 'kg_emb.product.weight', 'kg_emb.word.weight', 'kg_emb.related_product.weight', 'kg_emb.brand.weight', 'kg_emb.category.weight', 'kg_emb.self_loop_bias.weight', 'kg_emb.purchase_bias.weight', 'kg_emb.mentions_bias.weight', 'kg_emb.described_as_bias.weight', 'kg_emb.produced_by_bias.weight', 'kg_emb.belongs_to_bias.weight', 'kg_emb.also_bought_bias.weight', 'kg_emb.also_viewed_bias.weight', 'kg_emb.bought_together_bias.weight', 'kg_emb.padding_bias.weight', 'state_lstm.policy_lstm.lstm.weight_ih_l0', 'state_lstm.policy_lstm.lstm.weight_hh_l0', 'state_lstm.policy_lstm.lstm.bias_ih_l0', 'state_lstm.policy_lstm.lstm.bias_hh_l0', 'transfor_state.weight', 'transfor_state.bias', 'state_tr_query.weight', 'state_tr_query.bias', 'l1.weight', 'l1.bias', 'l2.weight', 'l2.bias', 'actor.weight', 'actor.bias', 'critic.weight', 'critic.bias']\n",
      "[INFO]  epoch/step=0/100 | loss=0.03742 | ploss=0.03402 | vloss=0.01103 | entropy=-9.46632 | reward=0.00375\n",
      "[INFO]  epoch/step=0/200 | loss=0.03403 | ploss=0.03152 | vloss=0.01011 | entropy=-9.42955 | reward=0.00344\n",
      "[INFO]  epoch/step=0/300 | loss=0.05632 | ploss=0.04831 | vloss=0.01562 | entropy=-9.43103 | reward=0.00531\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_0.ckpt\n",
      "[INFO]  epoch/step=1/400 | loss=0.06785 | ploss=0.05611 | vloss=0.01930 | entropy=-9.37393 | reward=0.00656\n",
      "[INFO]  epoch/step=1/500 | loss=0.07571 | ploss=0.06209 | vloss=0.02114 | entropy=-9.32116 | reward=0.00719\n",
      "[INFO]  epoch/step=1/600 | loss=0.09792 | ploss=0.07871 | vloss=0.02665 | entropy=-9.23782 | reward=0.00906\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_1.ckpt\n",
      "[INFO]  epoch/step=2/700 | loss=0.06719 | ploss=0.05524 | vloss=0.01930 | entropy=-9.14727 | reward=0.00656\n",
      "[INFO]  epoch/step=2/800 | loss=0.07601 | ploss=0.06124 | vloss=0.02206 | entropy=-9.07183 | reward=0.00750\n",
      "[INFO]  epoch/step=2/900 | loss=0.15340 | ploss=0.11738 | vloss=0.04319 | entropy=-8.96028 | reward=0.01469\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_2.ckpt\n",
      "[INFO]  epoch/step=3/1000 | loss=0.13678 | ploss=0.10235 | vloss=0.04135 | entropy=-8.70920 | reward=0.01406\n",
      "[INFO]  epoch/step=3/1100 | loss=0.20062 | ploss=0.14665 | vloss=0.06065 | entropy=-8.46004 | reward=0.02063\n",
      "[INFO]  epoch/step=3/1200 | loss=0.26424 | ploss=0.18704 | vloss=0.08363 | entropy=-8.20354 | reward=0.02844\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_3.ckpt\n",
      "[INFO]  epoch/step=4/1300 | loss=0.48281 | ploss=0.32019 | vloss=0.16854 | entropy=-7.69042 | reward=0.05656\n",
      "[INFO]  epoch/step=4/1400 | loss=0.90581 | ploss=0.55331 | vloss=0.35748 | entropy=-6.73910 | reward=0.12156\n",
      "[INFO]  epoch/step=4/1500 | loss=1.37798 | ploss=0.77813 | vloss=0.60376 | entropy=-5.68074 | reward=0.20531\n",
      "[INFO]  epoch/step=4/1600 | loss=1.82884 | ploss=0.99994 | vloss=0.83222 | entropy=-5.07476 | reward=0.28187\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_4.ckpt\n",
      "[INFO]  epoch/step=5/1700 | loss=1.85800 | ploss=0.99167 | vloss=0.86934 | entropy=-4.76427 | reward=0.29563\n",
      "[INFO]  epoch/step=5/1800 | loss=1.94799 | ploss=1.03277 | vloss=0.91805 | entropy=-4.57886 | reward=0.31219\n",
      "[INFO]  epoch/step=5/1900 | loss=2.04259 | ploss=1.07303 | vloss=0.97227 | entropy=-4.46919 | reward=0.33063\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_5.ckpt\n",
      "[INFO]  epoch/step=6/2000 | loss=2.05622 | ploss=1.08148 | vloss=0.97741 | entropy=-4.42689 | reward=0.33125\n",
      "[INFO]  epoch/step=6/2100 | loss=2.15277 | ploss=1.12703 | vloss=1.02832 | entropy=-4.33615 | reward=0.34969\n",
      "[INFO]  epoch/step=6/2200 | loss=2.18251 | ploss=1.14113 | vloss=1.04395 | entropy=-4.31726 | reward=0.35500\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_6.ckpt\n",
      "[INFO]  epoch/step=7/2300 | loss=2.14236 | ploss=1.11618 | vloss=1.02869 | entropy=-4.26336 | reward=0.34813\n",
      "[INFO]  epoch/step=7/2400 | loss=2.23825 | ploss=1.16095 | vloss=1.07979 | entropy=-4.23936 | reward=0.36719\n",
      "[INFO]  epoch/step=7/2500 | loss=2.12233 | ploss=1.09834 | vloss=1.02649 | entropy=-4.23939 | reward=0.34906\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_7.ckpt\n",
      "[INFO]  epoch/step=8/2600 | loss=2.13009 | ploss=1.10444 | vloss=1.02814 | entropy=-4.23284 | reward=0.34813\n",
      "[INFO]  epoch/step=8/2700 | loss=2.16804 | ploss=1.12193 | vloss=1.04854 | entropy=-4.17019 | reward=0.35656\n",
      "[INFO]  epoch/step=8/2800 | loss=2.29866 | ploss=1.18638 | vloss=1.11471 | entropy=-4.16610 | reward=0.37906\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_8.ckpt\n",
      "[INFO]  epoch/step=9/2900 | loss=2.18846 | ploss=1.13388 | vloss=1.05700 | entropy=-4.15157 | reward=0.35813\n",
      "[INFO]  epoch/step=9/3000 | loss=2.20816 | ploss=1.14641 | vloss=1.06416 | entropy=-4.15063 | reward=0.36188\n",
      "[INFO]  epoch/step=9/3100 | loss=2.26087 | ploss=1.17525 | vloss=1.08806 | entropy=-4.16751 | reward=0.37000\n",
      "[INFO]  epoch/step=9/3200 | loss=2.15541 | ploss=1.11682 | vloss=1.04101 | entropy=-4.14838 | reward=0.35250\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_9.ckpt\n",
      "[INFO]  epoch/step=10/3300 | loss=2.22588 | ploss=1.14666 | vloss=1.08162 | entropy=-4.12593 | reward=0.36781\n",
      "[INFO]  epoch/step=10/3400 | loss=2.19699 | ploss=1.13615 | vloss=1.06325 | entropy=-4.12718 | reward=0.36156\n",
      "[INFO]  epoch/step=10/3500 | loss=2.21800 | ploss=1.13694 | vloss=1.08346 | entropy=-4.12298 | reward=0.36844\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_10.ckpt\n",
      "[INFO]  epoch/step=11/3600 | loss=2.19655 | ploss=1.13589 | vloss=1.06306 | entropy=-4.12624 | reward=0.36094\n",
      "[INFO]  epoch/step=11/3700 | loss=2.23223 | ploss=1.14654 | vloss=1.08806 | entropy=-4.08259 | reward=0.37000\n",
      "[INFO]  epoch/step=11/3800 | loss=2.16883 | ploss=1.11259 | vloss=1.05865 | entropy=-4.12240 | reward=0.36000\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_11.ckpt\n",
      "[INFO]  epoch/step=12/3900 | loss=2.27347 | ploss=1.16866 | vloss=1.10717 | entropy=-4.07098 | reward=0.37500\n",
      "[INFO]  epoch/step=12/4000 | loss=2.36757 | ploss=1.21014 | vloss=1.15974 | entropy=-4.02796 | reward=0.39437\n",
      "[INFO]  epoch/step=12/4100 | loss=2.27741 | ploss=1.15952 | vloss=1.12022 | entropy=-4.04036 | reward=0.38094\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_12.ckpt\n",
      "[INFO]  epoch/step=13/4200 | loss=2.26850 | ploss=1.16386 | vloss=1.10699 | entropy=-4.05295 | reward=0.37531\n",
      "[INFO]  epoch/step=13/4300 | loss=2.18677 | ploss=1.11298 | vloss=1.07611 | entropy=-4.03002 | reward=0.36594\n",
      "[INFO]  epoch/step=13/4400 | loss=2.27441 | ploss=1.16387 | vloss=1.11287 | entropy=-4.03610 | reward=0.37844\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_13.ckpt\n",
      "[INFO]  epoch/step=14/4500 | loss=2.31539 | ploss=1.18315 | vloss=1.13456 | entropy=-4.02916 | reward=0.38469\n",
      "[INFO]  epoch/step=14/4600 | loss=2.22622 | ploss=1.13500 | vloss=1.09357 | entropy=-4.05400 | reward=0.37188\n",
      "[INFO]  epoch/step=14/4700 | loss=2.22692 | ploss=1.13752 | vloss=1.09173 | entropy=-4.02879 | reward=0.37125\n",
      "[INFO]  epoch/step=14/4800 | loss=2.29901 | ploss=1.17356 | vloss=1.12776 | entropy=-4.01466 | reward=0.38219\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_14.ckpt\n",
      "[INFO]  epoch/step=15/4900 | loss=2.19748 | ploss=1.11082 | vloss=1.08898 | entropy=-4.01205 | reward=0.37031\n",
      "[INFO]  epoch/step=15/5000 | loss=2.34012 | ploss=1.18545 | vloss=1.15698 | entropy=-4.00157 | reward=0.39344\n",
      "[INFO]  epoch/step=15/5100 | loss=2.32710 | ploss=1.18068 | vloss=1.14871 | entropy=-3.98008 | reward=0.39062\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_15.ckpt\n",
      "[INFO]  epoch/step=16/5200 | loss=2.30824 | ploss=1.16769 | vloss=1.14283 | entropy=-3.96947 | reward=0.38750\n",
      "[INFO]  epoch/step=16/5300 | loss=2.31843 | ploss=1.17566 | vloss=1.14503 | entropy=-3.95287 | reward=0.38938\n",
      "[INFO]  epoch/step=16/5400 | loss=2.28196 | ploss=1.15205 | vloss=1.13217 | entropy=-3.94577 | reward=0.38500\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_16.ckpt\n",
      "[INFO]  epoch/step=17/5500 | loss=2.38236 | ploss=1.20447 | vloss=1.18014 | entropy=-3.92947 | reward=0.40000\n",
      "[INFO]  epoch/step=17/5600 | loss=2.35204 | ploss=1.19087 | vloss=1.16341 | entropy=-3.93676 | reward=0.39563\n",
      "[INFO]  epoch/step=17/5700 | loss=2.32006 | ploss=1.17363 | vloss=1.14871 | entropy=-3.96365 | reward=0.39062\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_17.ckpt\n",
      "[INFO]  epoch/step=18/5800 | loss=2.21686 | ploss=1.11217 | vloss=1.10699 | entropy=-3.97430 | reward=0.37531\n",
      "[INFO]  epoch/step=18/5900 | loss=2.22357 | ploss=1.12217 | vloss=1.10368 | entropy=-3.96607 | reward=0.37531\n",
      "[INFO]  epoch/step=18/6000 | loss=2.30035 | ploss=1.16402 | vloss=1.13860 | entropy=-3.94417 | reward=0.38719\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_18.ckpt\n",
      "[INFO]  epoch/step=19/6100 | loss=2.32389 | ploss=1.17228 | vloss=1.15386 | entropy=-3.92469 | reward=0.39125\n",
      "[INFO]  epoch/step=19/6200 | loss=2.31138 | ploss=1.16491 | vloss=1.14871 | entropy=-3.91201 | reward=0.39062\n",
      "[INFO]  epoch/step=19/6300 | loss=2.25979 | ploss=1.14090 | vloss=1.12114 | entropy=-3.92824 | reward=0.38125\n",
      "[INFO]  epoch/step=19/6400 | loss=2.30768 | ploss=1.16196 | vloss=1.14797 | entropy=-3.93209 | reward=0.38812\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_19.ckpt\n",
      "[INFO]  epoch/step=20/6500 | loss=2.35697 | ploss=1.17831 | vloss=1.18087 | entropy=-3.88671 | reward=0.40156\n",
      "[INFO]  epoch/step=20/6600 | loss=2.43114 | ploss=1.21665 | vloss=1.21671 | entropy=-3.88444 | reward=0.41375\n",
      "[INFO]  epoch/step=20/6700 | loss=2.31332 | ploss=1.16041 | vloss=1.15514 | entropy=-3.89657 | reward=0.39281\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_20.ckpt\n",
      "[INFO]  epoch/step=21/6800 | loss=2.26189 | ploss=1.13123 | vloss=1.13290 | entropy=-3.90534 | reward=0.38375\n",
      "[INFO]  epoch/step=21/6900 | loss=2.32535 | ploss=1.16691 | vloss=1.16066 | entropy=-3.87941 | reward=0.39469\n",
      "[INFO]  epoch/step=21/7000 | loss=2.40414 | ploss=1.20526 | vloss=1.20109 | entropy=-3.87033 | reward=0.40844\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_21.ckpt\n",
      "[INFO]  epoch/step=22/7100 | loss=2.30220 | ploss=1.14687 | vloss=1.15753 | entropy=-3.86184 | reward=0.39156\n",
      "[INFO]  epoch/step=22/7200 | loss=2.25008 | ploss=1.13116 | vloss=1.12114 | entropy=-3.87380 | reward=0.38125\n",
      "[INFO]  epoch/step=22/7300 | loss=2.31973 | ploss=1.16221 | vloss=1.15974 | entropy=-3.87045 | reward=0.39437\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_22.ckpt\n",
      "[INFO]  epoch/step=23/7400 | loss=2.36032 | ploss=1.17927 | vloss=1.18326 | entropy=-3.86536 | reward=0.40031\n",
      "[INFO]  epoch/step=23/7500 | loss=2.25757 | ploss=1.12763 | vloss=1.13217 | entropy=-3.87575 | reward=0.38500\n",
      "[INFO]  epoch/step=23/7600 | loss=2.29802 | ploss=1.14783 | vloss=1.15239 | entropy=-3.84793 | reward=0.39187\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_23.ckpt\n",
      "[INFO]  epoch/step=24/7700 | loss=2.30195 | ploss=1.14478 | vloss=1.15937 | entropy=-3.84814 | reward=0.39313\n",
      "[INFO]  epoch/step=24/7800 | loss=2.31386 | ploss=1.15999 | vloss=1.15606 | entropy=-3.84014 | reward=0.39313\n",
      "[INFO]  epoch/step=24/7900 | loss=2.36868 | ploss=1.18172 | vloss=1.18914 | entropy=-3.82659 | reward=0.40437\n",
      "[INFO]  epoch/step=24/8000 | loss=2.29251 | ploss=1.13569 | vloss=1.15900 | entropy=-3.82660 | reward=0.39281\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_24.ckpt\n",
      "[INFO]  epoch/step=25/8100 | loss=2.32686 | ploss=1.16103 | vloss=1.16801 | entropy=-3.81953 | reward=0.39719\n",
      "[INFO]  epoch/step=25/8200 | loss=2.33239 | ploss=1.16381 | vloss=1.17076 | entropy=-3.82601 | reward=0.39813\n",
      "[INFO]  epoch/step=25/8300 | loss=2.29670 | ploss=1.13732 | vloss=1.16157 | entropy=-3.83449 | reward=0.39500\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_25.ckpt\n",
      "[INFO]  epoch/step=26/8400 | loss=2.29387 | ploss=1.14699 | vloss=1.14908 | entropy=-3.83626 | reward=0.39000\n",
      "[INFO]  epoch/step=26/8500 | loss=2.35653 | ploss=1.17047 | vloss=1.18823 | entropy=-3.80203 | reward=0.40406\n",
      "[INFO]  epoch/step=26/8600 | loss=2.24095 | ploss=1.11466 | vloss=1.12849 | entropy=-3.82796 | reward=0.38375\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_26.ckpt\n",
      "[INFO]  epoch/step=27/8700 | loss=2.36189 | ploss=1.16886 | vloss=1.19521 | entropy=-3.81023 | reward=0.40531\n",
      "[INFO]  epoch/step=27/8800 | loss=2.33740 | ploss=1.16515 | vloss=1.17444 | entropy=-3.81652 | reward=0.39937\n",
      "[INFO]  epoch/step=27/8900 | loss=2.34765 | ploss=1.17170 | vloss=1.17812 | entropy=-3.80111 | reward=0.40063\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_27.ckpt\n",
      "[INFO]  epoch/step=28/9000 | loss=2.33451 | ploss=1.15951 | vloss=1.17720 | entropy=-3.82215 | reward=0.39937\n",
      "[INFO]  epoch/step=28/9100 | loss=2.35562 | ploss=1.16773 | vloss=1.19006 | entropy=-3.79753 | reward=0.40469\n",
      "[INFO]  epoch/step=28/9200 | loss=2.25781 | ploss=1.11678 | vloss=1.14320 | entropy=-3.78932 | reward=0.38875\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_28.ckpt\n",
      "[INFO]  epoch/step=29/9300 | loss=2.34904 | ploss=1.17183 | vloss=1.17940 | entropy=-3.80729 | reward=0.39937\n",
      "[INFO]  epoch/step=29/9400 | loss=2.23669 | ploss=1.10302 | vloss=1.13584 | entropy=-3.79190 | reward=0.38625\n",
      "[INFO]  epoch/step=29/9500 | loss=2.37487 | ploss=1.17413 | vloss=1.20293 | entropy=-3.80959 | reward=0.40906\n",
      "[INFO]  epoch/step=29/9600 | loss=2.46373 | ploss=1.22233 | vloss=1.24355 | entropy=-3.76911 | reward=0.42156\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_29.ckpt\n",
      "[INFO]  epoch/step=30/9700 | loss=2.19546 | ploss=1.08021 | vloss=1.11746 | entropy=-3.82850 | reward=0.38000\n",
      "[INFO]  epoch/step=30/9800 | loss=2.38502 | ploss=1.17876 | vloss=1.20844 | entropy=-3.79907 | reward=0.41094\n",
      "[INFO]  epoch/step=30/9900 | loss=2.30446 | ploss=1.13770 | vloss=1.16893 | entropy=-3.77828 | reward=0.39750\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_30.ckpt\n",
      "[INFO]  epoch/step=31/10000 | loss=2.32448 | ploss=1.14800 | vloss=1.17867 | entropy=-3.80068 | reward=0.39969\n",
      "[INFO]  epoch/step=31/10100 | loss=2.29304 | ploss=1.13365 | vloss=1.16157 | entropy=-3.79225 | reward=0.39500\n",
      "[INFO]  epoch/step=31/10200 | loss=2.37633 | ploss=1.17187 | vloss=1.20660 | entropy=-3.74949 | reward=0.41031\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_31.ckpt\n",
      "[INFO]  epoch/step=32/10300 | loss=2.22223 | ploss=1.09593 | vloss=1.12849 | entropy=-3.78897 | reward=0.38188\n",
      "[INFO]  epoch/step=32/10400 | loss=2.35398 | ploss=1.16147 | vloss=1.19466 | entropy=-3.74916 | reward=0.40625\n",
      "[INFO]  epoch/step=32/10500 | loss=2.33172 | ploss=1.14104 | vloss=1.19282 | entropy=-3.73869 | reward=0.40563\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_32.ckpt\n",
      "[INFO]  epoch/step=33/10600 | loss=2.26046 | ploss=1.11154 | vloss=1.15110 | entropy=-3.77629 | reward=0.38938\n",
      "[INFO]  epoch/step=33/10700 | loss=2.33766 | ploss=1.14517 | vloss=1.19466 | entropy=-3.76641 | reward=0.40625\n",
      "[INFO]  epoch/step=33/10800 | loss=2.31659 | ploss=1.13786 | vloss=1.18087 | entropy=-3.74278 | reward=0.40156\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_33.ckpt\n",
      "[INFO]  epoch/step=34/10900 | loss=2.27445 | ploss=1.11910 | vloss=1.15753 | entropy=-3.76996 | reward=0.39250\n",
      "[INFO]  epoch/step=34/11000 | loss=2.33301 | ploss=1.14234 | vloss=1.19282 | entropy=-3.73615 | reward=0.40563\n",
      "[INFO]  epoch/step=34/11100 | loss=2.43118 | ploss=1.18996 | vloss=1.24336 | entropy=-3.72383 | reward=0.42281\n",
      "[INFO]  epoch/step=34/11200 | loss=2.30519 | ploss=1.12424 | vloss=1.18308 | entropy=-3.72205 | reward=0.40063\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_34.ckpt\n",
      "[INFO]  epoch/step=35/11300 | loss=2.24833 | ploss=1.09626 | vloss=1.15422 | entropy=-3.74026 | reward=0.39250\n",
      "[INFO]  epoch/step=35/11400 | loss=2.25019 | ploss=1.09903 | vloss=1.15330 | entropy=-3.72542 | reward=0.39219\n",
      "[INFO]  epoch/step=35/11500 | loss=2.36928 | ploss=1.15838 | vloss=1.21304 | entropy=-3.72173 | reward=0.41250\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_35.ckpt\n",
      "[INFO]  epoch/step=36/11600 | loss=2.19408 | ploss=1.07141 | vloss=1.12482 | entropy=-3.72946 | reward=0.38156\n",
      "[INFO]  epoch/step=36/11700 | loss=2.31422 | ploss=1.12536 | vloss=1.19098 | entropy=-3.70813 | reward=0.40500\n",
      "[INFO]  epoch/step=36/11800 | loss=2.25695 | ploss=1.10395 | vloss=1.15514 | entropy=-3.72115 | reward=0.39281\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_36.ckpt\n",
      "[INFO]  epoch/step=37/11900 | loss=2.27996 | ploss=1.11485 | vloss=1.16727 | entropy=-3.73366 | reward=0.39469\n",
      "[INFO]  epoch/step=37/12000 | loss=2.28977 | ploss=1.12117 | vloss=1.17076 | entropy=-3.73307 | reward=0.39813\n",
      "[INFO]  epoch/step=37/12100 | loss=2.35994 | ploss=1.14351 | vloss=1.21855 | entropy=-3.68861 | reward=0.41437\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_37.ckpt\n",
      "[INFO]  epoch/step=38/12200 | loss=2.36225 | ploss=1.15961 | vloss=1.20477 | entropy=-3.70101 | reward=0.40781\n",
      "[INFO]  epoch/step=38/12300 | loss=2.29295 | ploss=1.11972 | vloss=1.17536 | entropy=-3.69237 | reward=0.39969\n",
      "[INFO]  epoch/step=38/12400 | loss=2.33720 | ploss=1.14373 | vloss=1.19558 | entropy=-3.66814 | reward=0.40656\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_38.ckpt\n",
      "[INFO]  epoch/step=39/12500 | loss=2.31535 | ploss=1.11989 | vloss=1.19760 | entropy=-3.70601 | reward=0.40594\n",
      "[INFO]  epoch/step=39/12600 | loss=2.27076 | ploss=1.10216 | vloss=1.17076 | entropy=-3.72851 | reward=0.39813\n",
      "[INFO]  epoch/step=39/12700 | loss=2.42376 | ploss=1.17513 | vloss=1.25071 | entropy=-3.65051 | reward=0.42531\n",
      "[INFO]  epoch/step=39/12800 | loss=2.41479 | ploss=1.17868 | vloss=1.23822 | entropy=-3.66215 | reward=0.41937\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_39.ckpt\n",
      "[INFO]  epoch/step=40/12900 | loss=2.40120 | ploss=1.15718 | vloss=1.24612 | entropy=-3.65481 | reward=0.42375\n",
      "[INFO]  epoch/step=40/13000 | loss=2.36307 | ploss=1.14939 | vloss=1.21579 | entropy=-3.67242 | reward=0.41344\n",
      "[INFO]  epoch/step=40/13100 | loss=2.35502 | ploss=1.14134 | vloss=1.21579 | entropy=-3.66033 | reward=0.41344\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_40.ckpt\n",
      "[INFO]  epoch/step=41/13200 | loss=2.32372 | ploss=1.12804 | vloss=1.19778 | entropy=-3.65825 | reward=0.40563\n",
      "[INFO]  epoch/step=41/13300 | loss=2.32683 | ploss=1.13429 | vloss=1.19466 | entropy=-3.66811 | reward=0.40625\n",
      "[INFO]  epoch/step=41/13400 | loss=2.34396 | ploss=1.13486 | vloss=1.21120 | entropy=-3.64870 | reward=0.41187\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_41.ckpt\n",
      "[INFO]  epoch/step=42/13500 | loss=2.39436 | ploss=1.16923 | vloss=1.22719 | entropy=-3.61504 | reward=0.41656\n",
      "[INFO]  epoch/step=42/13600 | loss=2.27019 | ploss=1.09603 | vloss=1.17628 | entropy=-3.65958 | reward=0.40000\n",
      "[INFO]  epoch/step=42/13700 | loss=2.42408 | ploss=1.17822 | vloss=1.24796 | entropy=-3.64249 | reward=0.42438\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_42.ckpt\n",
      "[INFO]  epoch/step=43/13800 | loss=2.21744 | ploss=1.07011 | vloss=1.14944 | entropy=-3.65497 | reward=0.38938\n",
      "[INFO]  epoch/step=43/13900 | loss=2.28390 | ploss=1.10791 | vloss=1.17812 | entropy=-3.66269 | reward=0.40063\n",
      "[INFO]  epoch/step=43/14000 | loss=2.38134 | ploss=1.15295 | vloss=1.23050 | entropy=-3.64432 | reward=0.41844\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_43.ckpt\n",
      "[INFO]  epoch/step=44/14100 | loss=2.35363 | ploss=1.13587 | vloss=1.21984 | entropy=-3.60788 | reward=0.41406\n",
      "[INFO]  epoch/step=44/14200 | loss=2.28594 | ploss=1.09522 | vloss=1.19282 | entropy=-3.63905 | reward=0.40563\n",
      "[INFO]  epoch/step=44/14300 | loss=2.37575 | ploss=1.15011 | vloss=1.22774 | entropy=-3.63950 | reward=0.41750\n",
      "[INFO]  epoch/step=44/14400 | loss=2.25721 | ploss=1.08322 | vloss=1.17609 | entropy=-3.62973 | reward=0.39844\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_44.ckpt\n",
      "[INFO]  epoch/step=45/14500 | loss=2.38832 | ploss=1.14890 | vloss=1.24153 | entropy=-3.63084 | reward=0.42219\n",
      "[INFO]  epoch/step=45/14600 | loss=2.32788 | ploss=1.12062 | vloss=1.20936 | entropy=-3.62469 | reward=0.41125\n",
      "[INFO]  epoch/step=45/14700 | loss=2.33208 | ploss=1.12296 | vloss=1.21120 | entropy=-3.60377 | reward=0.41187\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_45.ckpt\n",
      "[INFO]  epoch/step=46/14800 | loss=2.38051 | ploss=1.15190 | vloss=1.23068 | entropy=-3.59834 | reward=0.41719\n",
      "[INFO]  epoch/step=46/14900 | loss=2.41132 | ploss=1.15533 | vloss=1.25807 | entropy=-3.60168 | reward=0.42781\n",
      "[INFO]  epoch/step=46/15000 | loss=2.40392 | ploss=1.16175 | vloss=1.24428 | entropy=-3.63331 | reward=0.42312\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_46.ckpt\n",
      "[INFO]  epoch/step=47/15100 | loss=2.25371 | ploss=1.07955 | vloss=1.17628 | entropy=-3.63598 | reward=0.39813\n",
      "[INFO]  epoch/step=47/15200 | loss=2.33252 | ploss=1.11788 | vloss=1.21671 | entropy=-3.59553 | reward=0.41375\n",
      "[INFO]  epoch/step=47/15300 | loss=2.37345 | ploss=1.14871 | vloss=1.22682 | entropy=-3.60395 | reward=0.41719\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_47.ckpt\n",
      "[INFO]  epoch/step=48/15400 | loss=2.36502 | ploss=1.14323 | vloss=1.22388 | entropy=-3.61062 | reward=0.41469\n",
      "[INFO]  epoch/step=48/15500 | loss=2.33201 | ploss=1.12382 | vloss=1.21028 | entropy=-3.61017 | reward=0.41156\n",
      "[INFO]  epoch/step=48/15600 | loss=2.47088 | ploss=1.19190 | vloss=1.28104 | entropy=-3.57729 | reward=0.43562\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_48.ckpt\n",
      "[INFO]  epoch/step=49/15700 | loss=2.29245 | ploss=1.09730 | vloss=1.19723 | entropy=-3.59079 | reward=0.40563\n",
      "[INFO]  epoch/step=49/15800 | loss=2.39098 | ploss=1.14419 | vloss=1.24888 | entropy=-3.58944 | reward=0.42469\n",
      "[INFO]  epoch/step=49/15900 | loss=2.26533 | ploss=1.08839 | vloss=1.17904 | entropy=-3.59684 | reward=0.40094\n",
      "[INFO]  epoch/step=49/16000 | loss=2.32128 | ploss=1.11623 | vloss=1.20716 | entropy=-3.61691 | reward=0.40844\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_49.ckpt\n",
      "[INFO]  epoch/step=50/16100 | loss=2.25966 | ploss=1.08179 | vloss=1.17995 | entropy=-3.58667 | reward=0.40125\n",
      "[INFO]  epoch/step=50/16200 | loss=2.29609 | ploss=1.09433 | vloss=1.20385 | entropy=-3.59032 | reward=0.40937\n",
      "[INFO]  epoch/step=50/16300 | loss=2.36765 | ploss=1.13280 | vloss=1.23693 | entropy=-3.57875 | reward=0.42063\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_50.ckpt\n",
      "[INFO]  epoch/step=51/16400 | loss=2.36931 | ploss=1.13556 | vloss=1.23583 | entropy=-3.58684 | reward=0.41875\n",
      "[INFO]  epoch/step=51/16500 | loss=2.36433 | ploss=1.13406 | vloss=1.23234 | entropy=-3.56415 | reward=0.41906\n",
      "[INFO]  epoch/step=51/16600 | loss=2.34237 | ploss=1.12682 | vloss=1.21763 | entropy=-3.57021 | reward=0.41406\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_51.ckpt\n",
      "[INFO]  epoch/step=52/16700 | loss=2.35371 | ploss=1.13171 | vloss=1.22406 | entropy=-3.56182 | reward=0.41437\n",
      "[INFO]  epoch/step=52/16800 | loss=2.34189 | ploss=1.12728 | vloss=1.21671 | entropy=-3.59523 | reward=0.41375\n",
      "[INFO]  epoch/step=52/16900 | loss=2.31091 | ploss=1.10363 | vloss=1.20936 | entropy=-3.57476 | reward=0.41125\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_52.ckpt\n",
      "[INFO]  epoch/step=53/17000 | loss=2.38782 | ploss=1.14781 | vloss=1.24208 | entropy=-3.56376 | reward=0.42031\n",
      "[INFO]  epoch/step=53/17100 | loss=2.32987 | ploss=1.11522 | vloss=1.21671 | entropy=-3.55462 | reward=0.41375\n",
      "[INFO]  epoch/step=53/17200 | loss=2.23293 | ploss=1.05413 | vloss=1.18087 | entropy=-3.56548 | reward=0.40156\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_53.ckpt\n",
      "[INFO]  epoch/step=54/17300 | loss=2.32357 | ploss=1.09677 | vloss=1.22884 | entropy=-3.53623 | reward=0.41563\n",
      "[INFO]  epoch/step=54/17400 | loss=2.43390 | ploss=1.15767 | vloss=1.27828 | entropy=-3.53769 | reward=0.43469\n",
      "[INFO]  epoch/step=54/17500 | loss=2.29709 | ploss=1.09808 | vloss=1.20109 | entropy=-3.56181 | reward=0.40844\n",
      "[INFO]  epoch/step=54/17600 | loss=2.26816 | ploss=1.09176 | vloss=1.17848 | entropy=-3.56167 | reward=0.39813\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_54.ckpt\n",
      "[INFO]  epoch/step=55/17700 | loss=2.27629 | ploss=1.09015 | vloss=1.18823 | entropy=-3.56179 | reward=0.40406\n",
      "[INFO]  epoch/step=55/17800 | loss=2.30932 | ploss=1.10661 | vloss=1.20477 | entropy=-3.52895 | reward=0.40969\n",
      "[INFO]  epoch/step=55/17900 | loss=2.34021 | ploss=1.11638 | vloss=1.22590 | entropy=-3.55345 | reward=0.41687\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_55.ckpt\n",
      "[INFO]  epoch/step=56/18000 | loss=2.42171 | ploss=1.16258 | vloss=1.26119 | entropy=-3.53949 | reward=0.42719\n",
      "[INFO]  epoch/step=56/18100 | loss=2.30283 | ploss=1.10107 | vloss=1.20385 | entropy=-3.55990 | reward=0.40937\n",
      "[INFO]  epoch/step=56/18200 | loss=2.34823 | ploss=1.11336 | vloss=1.23693 | entropy=-3.54135 | reward=0.42063\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_56.ckpt\n",
      "[INFO]  epoch/step=57/18300 | loss=2.32609 | ploss=1.10684 | vloss=1.22131 | entropy=-3.53096 | reward=0.41437\n",
      "[INFO]  epoch/step=57/18400 | loss=2.38930 | ploss=1.13420 | vloss=1.25715 | entropy=-3.52399 | reward=0.42750\n",
      "[INFO]  epoch/step=57/18500 | loss=2.39133 | ploss=1.13532 | vloss=1.25807 | entropy=-3.52705 | reward=0.42781\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_57.ckpt\n",
      "[INFO]  epoch/step=58/18600 | loss=2.33464 | ploss=1.10972 | vloss=1.22701 | entropy=-3.55141 | reward=0.41594\n",
      "[INFO]  epoch/step=58/18700 | loss=2.36869 | ploss=1.13069 | vloss=1.24061 | entropy=-4.07521 | reward=0.42188\n",
      "[INFO]  epoch/step=58/18800 | loss=2.36792 | ploss=1.12245 | vloss=1.24796 | entropy=-3.95538 | reward=0.42438\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_58.ckpt\n",
      "[INFO]  epoch/step=59/18900 | loss=2.31551 | ploss=1.10298 | vloss=1.21506 | entropy=-3.99735 | reward=0.41187\n",
      "[INFO]  epoch/step=59/19000 | loss=2.38303 | ploss=1.14211 | vloss=1.24336 | entropy=-3.90648 | reward=0.42281\n",
      "[INFO]  epoch/step=59/19100 | loss=2.38001 | ploss=1.12802 | vloss=1.25439 | entropy=-3.86568 | reward=0.42656\n",
      "[INFO]  epoch/step=59/19200 | loss=2.39692 | ploss=1.14547 | vloss=1.25384 | entropy=-3.84834 | reward=0.42469\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_59.ckpt\n",
      "[INFO]  epoch/step=60/19300 | loss=2.43052 | ploss=1.15370 | vloss=1.27920 | entropy=-3.83880 | reward=0.43500\n",
      "[INFO]  epoch/step=60/19400 | loss=2.27169 | ploss=1.09324 | vloss=1.18087 | entropy=-3.88039 | reward=0.40156\n",
      "[INFO]  epoch/step=60/19500 | loss=2.37873 | ploss=1.12574 | vloss=1.25531 | entropy=-3.77668 | reward=0.42688\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_60.ckpt\n",
      "[INFO]  epoch/step=61/19600 | loss=2.35126 | ploss=1.11232 | vloss=1.24134 | entropy=-3.85762 | reward=0.42063\n",
      "[INFO]  epoch/step=61/19700 | loss=2.40766 | ploss=1.14641 | vloss=1.26358 | entropy=-3.78351 | reward=0.42969\n",
      "[INFO]  epoch/step=61/19800 | loss=2.40054 | ploss=1.14024 | vloss=1.26266 | entropy=-3.81398 | reward=0.42938\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_61.ckpt\n",
      "[INFO]  epoch/step=62/19900 | loss=2.44760 | ploss=1.17775 | vloss=1.27222 | entropy=-3.82575 | reward=0.43094\n",
      "[INFO]  epoch/step=62/20000 | loss=2.36580 | ploss=1.11654 | vloss=1.25163 | entropy=-3.82409 | reward=0.42562\n",
      "[INFO]  epoch/step=62/20100 | loss=2.31291 | ploss=1.09669 | vloss=1.21855 | entropy=-3.77927 | reward=0.41437\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_62.ckpt\n",
      "[INFO]  epoch/step=63/20200 | loss=2.43894 | ploss=1.16260 | vloss=1.27865 | entropy=-3.75878 | reward=0.43312\n",
      "[INFO]  epoch/step=63/20300 | loss=2.35527 | ploss=1.13269 | vloss=1.22498 | entropy=-3.84345 | reward=0.41656\n",
      "[INFO]  epoch/step=63/20400 | loss=2.39970 | ploss=1.13848 | vloss=1.26358 | entropy=-3.80320 | reward=0.42969\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_63.ckpt\n",
      "[INFO]  epoch/step=64/20500 | loss=2.39570 | ploss=1.13760 | vloss=1.26046 | entropy=-3.80184 | reward=0.42656\n",
      "[INFO]  epoch/step=64/20600 | loss=2.45564 | ploss=1.16767 | vloss=1.29023 | entropy=-3.69922 | reward=0.43875\n",
      "[INFO]  epoch/step=64/20700 | loss=2.45783 | ploss=1.17271 | vloss=1.28747 | entropy=-3.79484 | reward=0.43781\n",
      "[INFO]  epoch/step=64/20800 | loss=2.37032 | ploss=1.11976 | vloss=1.25292 | entropy=-3.79934 | reward=0.42438\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_64.ckpt\n",
      "[INFO]  epoch/step=65/20900 | loss=2.44974 | ploss=1.17009 | vloss=1.28196 | entropy=-3.74842 | reward=0.43594\n",
      "[INFO]  epoch/step=65/21000 | loss=2.36274 | ploss=1.12078 | vloss=1.24428 | entropy=-3.76049 | reward=0.42312\n",
      "[INFO]  epoch/step=65/21100 | loss=2.33609 | ploss=1.10058 | vloss=1.23785 | entropy=-3.77414 | reward=0.42094\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_65.ckpt\n",
      "[INFO]  epoch/step=66/21200 | loss=2.41720 | ploss=1.14398 | vloss=1.27553 | entropy=-3.74484 | reward=0.43188\n",
      "[INFO]  epoch/step=66/21300 | loss=2.49399 | ploss=1.18584 | vloss=1.31045 | entropy=-3.73089 | reward=0.44562\n",
      "[INFO]  epoch/step=66/21400 | loss=2.39648 | ploss=1.13612 | vloss=1.26266 | entropy=-3.73666 | reward=0.42938\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_66.ckpt\n",
      "[INFO]  epoch/step=67/21500 | loss=2.37040 | ploss=1.13048 | vloss=1.24226 | entropy=-3.77892 | reward=0.42000\n",
      "[INFO]  epoch/step=67/21600 | loss=2.36263 | ploss=1.11797 | vloss=1.24704 | entropy=-3.81485 | reward=0.42406\n",
      "[INFO]  epoch/step=67/21700 | loss=2.35623 | ploss=1.12066 | vloss=1.23785 | entropy=-3.71205 | reward=0.42094\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_67.ckpt\n",
      "[INFO]  epoch/step=68/21800 | loss=2.42383 | ploss=1.15556 | vloss=1.27056 | entropy=-3.72326 | reward=0.43094\n",
      "[INFO]  epoch/step=68/21900 | loss=2.39809 | ploss=1.13224 | vloss=1.26818 | entropy=-3.75869 | reward=0.43125\n",
      "[INFO]  epoch/step=68/22000 | loss=2.43801 | ploss=1.15200 | vloss=1.28839 | entropy=-3.80608 | reward=0.43812\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_68.ckpt\n",
      "[INFO]  epoch/step=69/22100 | loss=2.41688 | ploss=1.14901 | vloss=1.27020 | entropy=-3.75996 | reward=0.43062\n",
      "[INFO]  epoch/step=69/22200 | loss=2.43897 | ploss=1.15373 | vloss=1.28747 | entropy=-3.66238 | reward=0.43781\n",
      "[INFO]  epoch/step=69/22300 | loss=2.38869 | ploss=1.13202 | vloss=1.25899 | entropy=-3.73859 | reward=0.42812\n",
      "[INFO]  epoch/step=69/22400 | loss=2.37773 | ploss=1.11833 | vloss=1.26174 | entropy=-3.75899 | reward=0.42719\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_69.ckpt\n",
      "[INFO]  epoch/step=70/22500 | loss=2.40264 | ploss=1.13586 | vloss=1.26909 | entropy=-3.73626 | reward=0.43156\n",
      "[INFO]  epoch/step=70/22600 | loss=2.37875 | ploss=1.12759 | vloss=1.25347 | entropy=-3.72599 | reward=0.42625\n",
      "[INFO]  epoch/step=70/22700 | loss=2.42399 | ploss=1.14709 | vloss=1.27920 | entropy=-3.72521 | reward=0.43500\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_70.ckpt\n",
      "[INFO]  epoch/step=71/22800 | loss=2.46076 | ploss=1.16878 | vloss=1.29427 | entropy=-3.70997 | reward=0.43844\n",
      "[INFO]  epoch/step=71/22900 | loss=2.34384 | ploss=1.10460 | vloss=1.24153 | entropy=-3.71062 | reward=0.42219\n",
      "[INFO]  epoch/step=71/23000 | loss=2.41368 | ploss=1.13400 | vloss=1.28196 | entropy=-3.68844 | reward=0.43594\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_71.ckpt\n",
      "[INFO]  epoch/step=72/23100 | loss=2.38944 | ploss=1.12354 | vloss=1.26818 | entropy=-3.69155 | reward=0.42844\n",
      "[INFO]  epoch/step=72/23200 | loss=2.33793 | ploss=1.10333 | vloss=1.23693 | entropy=-3.74667 | reward=0.42063\n",
      "[INFO]  epoch/step=72/23300 | loss=2.43658 | ploss=1.13948 | vloss=1.29942 | entropy=-3.73213 | reward=0.44188\n",
      "[INFO]  Save model to ../save_mmodel/Amazon_Clothing_Core/lstm/note_rm_w1_p0_g_aiu_0_0_300/policy_model_epoch_72.ckpt\n",
      "[INFO]  epoch/step=73/23400 | loss=2.33351 | ploss=1.09908 | vloss=1.23675 | entropy=-3.72579 | reward=0.41906\n",
      "[INFO]  epoch/step=73/23500 | loss=2.37830 | ploss=1.11242 | vloss=1.26818 | entropy=-3.70478 | reward=0.43125\n"
     ]
    }
   ],
   "source": [
    "command = f\"python3 ../src/{train_file} --reasoning_step {reasoning_step} \\\n",
    "                                         --batch_size {batch_size} \\\n",
    "                                         --name {exp_name} \\\n",
    "                                         --lr {lr} \\\n",
    "                                         --embed_size {embed_size} \\\n",
    "                                         --n_memory {n_memory} \\\n",
    "                                         --load_pretrain_model {load_pretrain_model}  \\\n",
    "                                         --tri_wd_rm {tri_wd_rm} \\\n",
    "                                         --tri_pro_rm {tri_pro_rm} \\\n",
    "                                         --gp_setting {gp_setting} \\\n",
    "                                         --epochs {epochs} \\\n",
    "                                         --KGE_pretrained {KGE_pretrained} \\\n",
    "                                         --lambda_num {lambda_num}  \\\n",
    "                                         --kg_emb_grad {kg_emb_grad} \\\n",
    "                                         --p_hop {p_hop}  \\\n",
    "                                         --reasoning_step {reasoning_step}  \\\n",
    "                                         --model lstm \\\n",
    "                                         --dataset {DATASET}\"\n",
    "print(\"Running Command:\")\n",
    "print(' '.join(command.split()))\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pretrain_model = 1\n",
    "\n",
    "command = f\"python3 ../src/{test_file} --name {exp_name} \\\n",
    "                                        --batch_size {batch_size} \\\n",
    "                                        --gp_setting {gp_setting} \\\n",
    "                                        --model lstm \\\n",
    "                                        --dataset {DATASET} \\\n",
    "                                        --lambda_num {lambda_num} \\\n",
    "                                        --kg_emb_grad {kg_emb_grad} \\\n",
    "                                        --lr {lr} \\\n",
    "                                         --tri_wd_rm {tri_wd_rm} \\\n",
    "                                         --tri_pro_rm {tri_pro_rm} \\\n",
    "                                        --p_hop {p_hop} \\\n",
    "                                        --reasoning_step {reasoning_step} \\\n",
    "                                        --embed_size {embed_size} \\ \n",
    "                                        --save_pretrain_model {save_pretrain_model}\\\n",
    "                                        --n_memory {n_memory}\"\n",
    "\n",
    "print(' '.join(command.split()))\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-cigarette",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-illness",
   "metadata": {},
   "source": [
    "# train UCPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pretrain_model=1\n",
    "\n",
    "tri_wd_rm=0\n",
    "tri_pro_rm=0\n",
    "exp_name=f\"note_rm_w{tri_wd_rm}_p{tri_pro_rm}\"\n",
    "\n",
    "command = f\"python3 ../src/{train_file} --reasoning_step {reasoning_step} \\\n",
    "                                         --batch_size {batch_size} \\\n",
    "                                         --name {exp_name} \\\n",
    "                                         --lr {lr} \\\n",
    "                                         --embed_size {embed_size} \\\n",
    "                                         --n_memory {n_memory} \\\n",
    "                                         --load_pretrain_model {load_pretrain_model}  \\\n",
    "                                         --KGE_pretrained {KGE_pretrained} \\\n",
    "                                         --tri_wd_rm {tri_wd_rm} \\\n",
    "                                         --tri_pro_rm {tri_pro_rm} \\\n",
    "                                         --gp_setting {gp_setting} \\\n",
    "                                         --epochs {epochs} \\\n",
    "                                         --KGE_pretrained {KGE_pretrained} \\\n",
    "                                         --lambda_num {lambda_num}  \\\n",
    "                                         --kg_emb_grad {kg_emb_grad} \\\n",
    "                                         --p_hop {p_hop}  \\\n",
    "                                         --reasoning_step {reasoning_step}  \\\n",
    "                                         --model {model} \\\n",
    "                                         --dataset {DATASET}\"\n",
    "print(\"Running Command:\")\n",
    "print(' '.join(command.split()))\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f\"python3 ../src/{test_file} --name {exp_name} \\\n",
    "                                        --batch_size {batch_size} \\\n",
    "                                        --gp_setting {gp_setting} \\\n",
    "                                        --model {model} \\\n",
    "                                        --dataset {DATASET} \\\n",
    "                                        --lambda_num {lambda_num} \\\n",
    "                                        --kg_emb_grad {kg_emb_grad} \\\n",
    "                                        --lr {lr} \\\n",
    "                                         --tri_wd_rm {tri_wd_rm} \\\n",
    "                                         --tri_pro_rm {tri_pro_rm} \\\n",
    "                                        --p_hop {p_hop} \\\n",
    "                                        --reasoning_step {reasoning_step} \\\n",
    "                                        --embed_size {embed_size} \\\n",
    "                                        --n_memory {n_memory}\"\n",
    "\n",
    "print(' '.join(command.split()))\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-physiology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-snapshot",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-article",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
